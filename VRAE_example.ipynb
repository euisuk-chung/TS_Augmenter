{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Contents\n",
    "\n",
    "0. [Load data and preprocess](#Load-data-and-preprocess)\n",
    "1. [Initialize VRAE object](#Initialize-VRAE-object)\n",
    "2. [Fit the model onto dataset](#Fit-the-model-onto-dataset)\n",
    "3. [Transform the input timeseries to encoded latent vectors](#Transform-the-input-timeseries-to-encoded-latent-vectors)\n",
    "4. [Save the model to be fetched later](#Save-the-model-to-be-fetched-later)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "def fix_seed(seed: int) -> None:\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "fix_seed(555)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import required modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.vrae import VRAE\n",
    "\n",
    "from model.utils import *\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from tqdm.notebook import trange\n",
    "import tqdm\n",
    "\n",
    "import pickle\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "dload = './save_model' #download directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### utils.load_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_gen_data(file_name, scale_type = 'Standard', cols_to_remove = None):\n",
    "    \"\"\"\n",
    "    folder: folder where data is located\n",
    "    \"\"\"\n",
    "    \n",
    "    # define path(must be in pkl file)\n",
    "    data_loc = f'./data/netis/{file_name}.pkl'    \n",
    "    \n",
    "    # get data\n",
    "    with open(data_loc, 'rb') as f:\n",
    "        df = pickle.load(f)\n",
    "    \n",
    "    # if needed remove columns that is not necessary\n",
    "    if cols_to_remove != None:\n",
    "        df = df_total.drop(cols_to_remove, axis=1)\n",
    "    \n",
    "    df = df.dropna()\n",
    "    \n",
    "    # TRAIN TEST SPLIT\n",
    "    # TRAIN\n",
    "    TRAIN_DF = df.query('Time < 20211103184400 or Time > 20211106084400 and label==0')\n",
    "    \n",
    "    # TEST(GET ONLY 정상)\n",
    "    TEST_DF = df.query('Time >= 20211103184400 and Time <= 20211106084400 and label==0')\n",
    "\n",
    "    TOTAL_DF = df.to_numpy()\n",
    "    \n",
    "    # REMOVE TIME & LABEL\n",
    "    TRAIN_DF = TRAIN_DF.iloc[:,1:-1]\n",
    "    cols = TRAIN_DF.columns\n",
    "    TRAIN_DF = TRAIN_DF.to_numpy()\n",
    "    TEST_DF = TEST_DF.iloc[:,1:-1].to_numpy()\n",
    "    \n",
    "    if scale_type == 'MinMax':\n",
    "        scaler = MinMaxScaler()\n",
    "    elif scale_type == 'Standard':\n",
    "        scaler = StandardScaler()\n",
    "    else:\n",
    "        pass\n",
    "    \n",
    "    TRAIN_SCALED = scaler.fit(TRAIN_DF).transform(TRAIN_DF)\n",
    "    TEST_SCALED = scaler.transform(TEST_DF)\n",
    "    \n",
    "    return TOTAL_DF, TRAIN_DF, TEST_DF, TRAIN_SCALED, TEST_SCALED, cols, scaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyper parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data and preprocess\n",
    "- `file_name` : pkl file_name\n",
    "- `cols_to_remove` : generation 수행하지 않을 column 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(26002, 94)\n",
      "(22363, 92)\n",
      "(3627, 92)\n"
     ]
    }
   ],
   "source": [
    "# params\n",
    "file_name = 'netis'\n",
    "\n",
    "# load data\n",
    "TOTAL_DF, TRAIN_DF, TEST_DF, TRAIN_SCALED, TEST_SCALED, cols, scaler = load_gen_data(file_name)\n",
    "\n",
    "# shape\n",
    "print(TOTAL_DF.shape)\n",
    "print(TRAIN_SCALED.shape)\n",
    "print(TEST_SCALED.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GenerationDataset(Dataset):\n",
    "    def __init__(self, data, window):\n",
    "        self.data = torch.Tensor(data)\n",
    "        self.window = window\n",
    " \n",
    "    def __len__(self):\n",
    "        return len(self.data) // self.window # -1\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "#         x = self.data[index*self.window:index*(self.window+1)]\n",
    "        x = self.data[index*self.window:(index+1)*(self.window)]\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "window = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.GenerationDataset at 0x7faaf47789e8>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset = GenerationDataset(TRAIN_SCALED, window)\n",
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.GenerationDataset at 0x7faa14b9fa90>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset = GenerationDataset(TEST_SCALED, window)\n",
    "test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([30, 92])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Fetch `sequence_length` from dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequence_length = train_dataset[0].shape[0]\n",
    "sequence_length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Fetch `number_of_features` from dataset**\n",
    "\n",
    "This config corresponds to number of input features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "92"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "number_of_features = train_dataset[0].shape[1]\n",
    "number_of_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 100\n",
    "hidden_size = 90\n",
    "# hidden_layer_depth = 2\n",
    "hidden_layer_depth = 1\n",
    "latent_length = 30\n",
    "batch_size = 1\n",
    "learning_rate = 0.0002\n",
    "dropout_rate = 0.2\n",
    "optimizer = 'Adam' # options: ADAM, SGD\n",
    "cuda = True # options: True, False\n",
    "print_every=50\n",
    "clip = True # options: True, False\n",
    "max_grad_norm=5\n",
    "loss = 'MSELoss' # options: SmoothL1Loss, MSELoss\n",
    "block = 'LSTM' # options: LSTM, GRU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize VRAE object\n",
    "\n",
    "VRAE inherits from `sklearn.base.BaseEstimator` and overrides `fit`, `transform` and `fit_transform` functions, similar to sklearn modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "vrae = VRAE(sequence_length=sequence_length,\n",
    "            number_of_features = number_of_features,\n",
    "            hidden_size = hidden_size, \n",
    "            hidden_layer_depth = hidden_layer_depth,\n",
    "            latent_length = latent_length,\n",
    "            batch_size = batch_size,\n",
    "            learning_rate = learning_rate,\n",
    "            n_epochs = n_epochs,\n",
    "            dropout_rate = dropout_rate,\n",
    "            optimizer = optimizer, \n",
    "            cuda = cuda,\n",
    "            print_every=print_every, \n",
    "            clip=clip, \n",
    "            max_grad_norm=max_grad_norm,\n",
    "            loss = loss,\n",
    "            block = block,\n",
    "            dload = dload)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit the model onto dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90f780eb45854602953ce6204bc24d84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "Batch 50, loss = 60888.2305, recon_loss = 60887.9141, kl_loss = 0.3177\n",
      "Batch 100, loss = 1344.4454, recon_loss = 1344.4333, kl_loss = 0.0121\n",
      "Batch 150, loss = 250.0608, recon_loss = 250.0525, kl_loss = 0.0083\n",
      "Batch 200, loss = 304029.8438, recon_loss = 304029.8125, kl_loss = 0.0167\n",
      "Batch 250, loss = 425.3893, recon_loss = 425.3769, kl_loss = 0.0124\n",
      "Batch 300, loss = 847.1760, recon_loss = 847.1647, kl_loss = 0.0113\n",
      "Batch 350, loss = 740.6201, recon_loss = 740.6078, kl_loss = 0.0123\n",
      "Batch 400, loss = 3139.8110, recon_loss = 3139.3525, kl_loss = 0.4585\n",
      "Batch 450, loss = 210991.9375, recon_loss = 210991.1250, kl_loss = 0.8152\n",
      "Batch 500, loss = 28867.4785, recon_loss = 28866.9355, kl_loss = 0.5422\n",
      "Batch 550, loss = 46832.6484, recon_loss = 46830.3047, kl_loss = 2.3433\n",
      "Batch 600, loss = 41230296.0000, recon_loss = 41230296.0000, kl_loss = 0.9753\n",
      "Batch 650, loss = 390601807757312.0000, recon_loss = 390601807757312.0000, kl_loss = 0.2661\n",
      "Batch 700, loss = 5848206785118208.0000, recon_loss = 5848206785118208.0000, kl_loss = 0.4917\n",
      "Average loss: 36437538578434928.0000\n",
      "Epoch: 1\n",
      "Batch 50, loss = 59174.5469, recon_loss = 59172.9102, kl_loss = 1.6366\n",
      "Batch 100, loss = 6420.4243, recon_loss = 6419.3623, kl_loss = 1.0621\n",
      "Batch 150, loss = 3460.4607, recon_loss = 3460.4221, kl_loss = 0.0385\n",
      "Batch 200, loss = 304798.9688, recon_loss = 304798.5938, kl_loss = 0.3736\n",
      "Batch 250, loss = 397.1216, recon_loss = 396.6614, kl_loss = 0.4602\n",
      "Batch 300, loss = 836.8630, recon_loss = 836.5280, kl_loss = 0.3350\n",
      "Batch 350, loss = 740.4649, recon_loss = 740.1218, kl_loss = 0.3431\n",
      "Batch 400, loss = 3176.5742, recon_loss = 3176.3813, kl_loss = 0.1930\n",
      "Batch 450, loss = 210559.9844, recon_loss = 210559.2188, kl_loss = 0.7628\n",
      "Batch 500, loss = 22923.3633, recon_loss = 22921.1836, kl_loss = 2.1804\n",
      "Batch 550, loss = 43085.4102, recon_loss = 43082.8203, kl_loss = 2.5898\n",
      "Batch 600, loss = 41226824.0000, recon_loss = 41226824.0000, kl_loss = 1.4147\n",
      "Batch 650, loss = 390601505767424.0000, recon_loss = 390601505767424.0000, kl_loss = 0.6567\n",
      "Batch 700, loss = 5848206785118208.0000, recon_loss = 5848206785118208.0000, kl_loss = 0.8149\n",
      "Average loss: 36437538524919144.0000\n",
      "Epoch: 2\n",
      "Batch 50, loss = 55262.1523, recon_loss = 55260.6992, kl_loss = 1.4550\n",
      "Batch 100, loss = 5582.1846, recon_loss = 5581.7051, kl_loss = 0.4796\n",
      "Batch 150, loss = 846.5761, recon_loss = 846.2726, kl_loss = 0.3034\n",
      "Batch 200, loss = 303961.4375, recon_loss = 303961.2500, kl_loss = 0.1892\n",
      "Batch 250, loss = 383.4584, recon_loss = 383.3308, kl_loss = 0.1276\n",
      "Batch 300, loss = 826.6311, recon_loss = 826.4746, kl_loss = 0.1565\n",
      "Batch 350, loss = 740.3407, recon_loss = 740.0944, kl_loss = 0.2463\n",
      "Batch 400, loss = 3163.0769, recon_loss = 3162.5830, kl_loss = 0.4940\n",
      "Batch 450, loss = 210148.3281, recon_loss = 210147.0625, kl_loss = 1.2711\n",
      "Batch 500, loss = 20537.8887, recon_loss = 20534.8086, kl_loss = 3.0798\n",
      "Batch 550, loss = 41184.7656, recon_loss = 41181.6055, kl_loss = 3.1609\n",
      "Batch 600, loss = 41180132.0000, recon_loss = 41180132.0000, kl_loss = 1.9597\n",
      "Batch 650, loss = 390600767569920.0000, recon_loss = 390600767569920.0000, kl_loss = 1.0266\n",
      "Batch 700, loss = 5848206785118208.0000, recon_loss = 5848206785118208.0000, kl_loss = 1.1618\n",
      "Average loss: 36437538419119320.0000\n",
      "Epoch: 3\n",
      "Batch 50, loss = 51695.0234, recon_loss = 51693.2656, kl_loss = 1.7595\n",
      "Batch 100, loss = 7745.5127, recon_loss = 7745.0708, kl_loss = 0.4418\n",
      "Batch 150, loss = 261.8082, recon_loss = 261.4811, kl_loss = 0.3271\n",
      "Batch 200, loss = 303988.6562, recon_loss = 303988.4688, kl_loss = 0.1932\n",
      "Batch 250, loss = 379.9333, recon_loss = 379.7330, kl_loss = 0.2003\n",
      "Batch 300, loss = 827.8693, recon_loss = 827.6240, kl_loss = 0.2453\n",
      "Batch 350, loss = 740.1581, recon_loss = 739.9370, kl_loss = 0.2211\n",
      "Batch 400, loss = 3192.3438, recon_loss = 3191.3511, kl_loss = 0.9927\n",
      "Batch 450, loss = 209466.0156, recon_loss = 209464.2500, kl_loss = 1.7597\n",
      "Batch 500, loss = 21436.6504, recon_loss = 21433.4648, kl_loss = 3.1864\n",
      "Batch 550, loss = 41236.2695, recon_loss = 41232.9258, kl_loss = 3.3422\n",
      "Batch 600, loss = 41162992.0000, recon_loss = 41162988.0000, kl_loss = 2.1436\n",
      "Batch 650, loss = 390600230699008.0000, recon_loss = 390600230699008.0000, kl_loss = 1.2566\n",
      "Batch 700, loss = 5848205711376384.0000, recon_loss = 5848205711376384.0000, kl_loss = 1.4134\n",
      "Average loss: 36437538315465400.0000\n",
      "Epoch: 4\n",
      "Batch 50, loss = 50078.4141, recon_loss = 50076.9023, kl_loss = 1.5115\n",
      "Batch 100, loss = 1354.3171, recon_loss = 1353.9995, kl_loss = 0.3177\n",
      "Batch 150, loss = 219.2844, recon_loss = 218.9701, kl_loss = 0.3142\n",
      "Batch 200, loss = 303998.8438, recon_loss = 303998.6250, kl_loss = 0.2097\n",
      "Batch 250, loss = 362.0005, recon_loss = 361.7903, kl_loss = 0.2102\n",
      "Batch 300, loss = 823.7087, recon_loss = 823.3929, kl_loss = 0.3157\n",
      "Batch 350, loss = 740.7667, recon_loss = 740.5198, kl_loss = 0.2470\n",
      "Batch 400, loss = 2681.0847, recon_loss = 2679.3037, kl_loss = 1.7809\n",
      "Batch 450, loss = 207062.9375, recon_loss = 207061.0938, kl_loss = 1.8381\n",
      "Batch 500, loss = 23812.5000, recon_loss = 23809.0391, kl_loss = 3.4617\n",
      "Batch 550, loss = 41939.6797, recon_loss = 41936.0625, kl_loss = 3.6155\n",
      "Batch 600, loss = 41112292.0000, recon_loss = 41112288.0000, kl_loss = 2.5872\n",
      "Batch 650, loss = 390599693828096.0000, recon_loss = 390599693828096.0000, kl_loss = 1.5085\n",
      "Batch 700, loss = 5848204637634560.0000, recon_loss = 5848204637634560.0000, kl_loss = 1.6349\n",
      "Average loss: 36437538238003088.0000\n",
      "Epoch: 5\n",
      "Batch 50, loss = 47156.7617, recon_loss = 47154.4688, kl_loss = 2.2924\n",
      "Batch 100, loss = 1288.8534, recon_loss = 1288.5258, kl_loss = 0.3276\n",
      "Batch 150, loss = 202.7643, recon_loss = 202.4364, kl_loss = 0.3279\n",
      "Batch 200, loss = 304237.1562, recon_loss = 304236.6875, kl_loss = 0.4796\n",
      "Batch 250, loss = 359.9684, recon_loss = 359.6871, kl_loss = 0.2813\n",
      "Batch 300, loss = 821.9035, recon_loss = 821.6573, kl_loss = 0.2462\n",
      "Batch 350, loss = 740.4788, recon_loss = 740.2220, kl_loss = 0.2568\n",
      "Batch 400, loss = 2403.9507, recon_loss = 2401.9839, kl_loss = 1.9667\n",
      "Batch 450, loss = 206427.9531, recon_loss = 206425.8125, kl_loss = 2.1470\n",
      "Batch 500, loss = 22817.1621, recon_loss = 22813.3203, kl_loss = 3.8428\n",
      "Batch 550, loss = 40400.7461, recon_loss = 40396.6406, kl_loss = 4.1048\n",
      "Batch 600, loss = 41033044.0000, recon_loss = 41033040.0000, kl_loss = 2.7130\n",
      "Batch 650, loss = 390598821412864.0000, recon_loss = 390598821412864.0000, kl_loss = 1.7832\n",
      "Batch 700, loss = 5848204637634560.0000, recon_loss = 5848204637634560.0000, kl_loss = 1.9141\n",
      "Average loss: 36437538084278728.0000\n",
      "Epoch: 6\n",
      "Batch 50, loss = 43357.5117, recon_loss = 43355.2266, kl_loss = 2.2859\n",
      "Batch 100, loss = 1294.9288, recon_loss = 1294.6003, kl_loss = 0.3285\n",
      "Batch 150, loss = 206.3645, recon_loss = 206.0320, kl_loss = 0.3325\n",
      "Batch 200, loss = 303988.6250, recon_loss = 303988.2812, kl_loss = 0.3431\n",
      "Batch 250, loss = 358.8528, recon_loss = 358.4733, kl_loss = 0.3795\n",
      "Batch 300, loss = 820.6694, recon_loss = 820.3226, kl_loss = 0.3468\n",
      "Batch 350, loss = 740.9747, recon_loss = 740.6786, kl_loss = 0.2960\n",
      "Batch 400, loss = 2245.8721, recon_loss = 2243.7979, kl_loss = 2.0743\n",
      "Batch 450, loss = 206146.4375, recon_loss = 206143.9062, kl_loss = 2.5304\n",
      "Batch 500, loss = 15657.2998, recon_loss = 15653.2246, kl_loss = 4.0755\n",
      "Batch 550, loss = 37255.0859, recon_loss = 37250.7656, kl_loss = 4.3188\n",
      "Batch 600, loss = 41012396.0000, recon_loss = 41012392.0000, kl_loss = 2.9602\n",
      "Batch 650, loss = 390597881888768.0000, recon_loss = 390597881888768.0000, kl_loss = 1.9078\n",
      "Batch 700, loss = 5848203563892736.0000, recon_loss = 5848203563892736.0000, kl_loss = 2.0508\n",
      "Average loss: 36437537928227560.0000\n",
      "Epoch: 7\n",
      "Batch 50, loss = 38884.1211, recon_loss = 38881.6641, kl_loss = 2.4566\n",
      "Batch 100, loss = 1289.0739, recon_loss = 1288.6888, kl_loss = 0.3851\n",
      "Batch 150, loss = 205.8538, recon_loss = 205.4397, kl_loss = 0.4141\n",
      "Batch 200, loss = 304017.2812, recon_loss = 304016.9375, kl_loss = 0.3562\n",
      "Batch 250, loss = 358.9135, recon_loss = 358.5979, kl_loss = 0.3157\n",
      "Batch 300, loss = 820.1581, recon_loss = 819.8281, kl_loss = 0.3300\n",
      "Batch 350, loss = 740.4837, recon_loss = 740.1765, kl_loss = 0.3072\n",
      "Batch 400, loss = 2165.5957, recon_loss = 2163.3948, kl_loss = 2.2008\n",
      "Batch 450, loss = 205796.4062, recon_loss = 205793.2188, kl_loss = 3.1877\n",
      "Batch 500, loss = 11102.0703, recon_loss = 11097.7188, kl_loss = 4.3517\n",
      "Batch 550, loss = 34100.2930, recon_loss = 34095.7930, kl_loss = 4.4992\n",
      "Batch 600, loss = 41038204.0000, recon_loss = 41038200.0000, kl_loss = 2.8541\n",
      "Batch 650, loss = 390596975919104.0000, recon_loss = 390596975919104.0000, kl_loss = 2.0608\n",
      "Batch 700, loss = 5848203027021824.0000, recon_loss = 5848203027021824.0000, kl_loss = 2.2168\n",
      "Average loss: 36437537773675296.0000\n",
      "Epoch: 8\n",
      "Batch 50, loss = 32010.4844, recon_loss = 32007.7480, kl_loss = 2.7362\n",
      "Batch 100, loss = 1296.5815, recon_loss = 1296.2477, kl_loss = 0.3339\n",
      "Batch 150, loss = 207.1787, recon_loss = 206.8826, kl_loss = 0.2961\n",
      "Batch 200, loss = 304017.1875, recon_loss = 304016.8438, kl_loss = 0.3363\n",
      "Batch 250, loss = 354.7840, recon_loss = 354.4590, kl_loss = 0.3250\n",
      "Batch 300, loss = 818.8196, recon_loss = 818.4744, kl_loss = 0.3452\n",
      "Batch 350, loss = 740.6789, recon_loss = 740.3240, kl_loss = 0.3549\n",
      "Batch 400, loss = 2119.2288, recon_loss = 2116.9033, kl_loss = 2.3254\n",
      "Batch 450, loss = 204592.1094, recon_loss = 204588.5312, kl_loss = 3.5787\n",
      "Batch 500, loss = 7088.4033, recon_loss = 7083.9419, kl_loss = 4.4615\n",
      "Batch 550, loss = 31357.3672, recon_loss = 31352.7676, kl_loss = 4.5999\n",
      "Batch 600, loss = 41020356.0000, recon_loss = 41020352.0000, kl_loss = 2.8504\n",
      "Batch 650, loss = 390596103503872.0000, recon_loss = 390596103503872.0000, kl_loss = 2.1759\n",
      "Batch 700, loss = 5848201416409088.0000, recon_loss = 5848201416409088.0000, kl_loss = 2.3506\n",
      "Average loss: 36437537619511408.0000\n",
      "Epoch: 9\n",
      "Batch 50, loss = 26346.5176, recon_loss = 26343.5430, kl_loss = 2.9751\n",
      "Batch 100, loss = 1288.9000, recon_loss = 1288.5409, kl_loss = 0.3592\n",
      "Batch 150, loss = 206.3469, recon_loss = 205.9612, kl_loss = 0.3857\n",
      "Batch 200, loss = 304000.4062, recon_loss = 304000.0312, kl_loss = 0.3754\n",
      "Batch 250, loss = 359.8140, recon_loss = 359.4818, kl_loss = 0.3322\n",
      "Batch 300, loss = 814.7043, recon_loss = 814.3203, kl_loss = 0.3840\n",
      "Batch 350, loss = 740.0006, recon_loss = 739.6360, kl_loss = 0.3645\n",
      "Batch 400, loss = 2119.1785, recon_loss = 2116.6807, kl_loss = 2.4978\n",
      "Batch 450, loss = 204172.1250, recon_loss = 204168.4062, kl_loss = 3.7164\n",
      "Batch 500, loss = 4467.6250, recon_loss = 4463.3457, kl_loss = 4.2794\n",
      "Batch 550, loss = 29528.5117, recon_loss = 29524.1328, kl_loss = 4.3782\n",
      "Batch 600, loss = 40986716.0000, recon_loss = 40986712.0000, kl_loss = 2.8887\n",
      "Batch 650, loss = 390595197534208.0000, recon_loss = 390595197534208.0000, kl_loss = 2.2443\n",
      "Batch 700, loss = 5848201416409088.0000, recon_loss = 5848201416409088.0000, kl_loss = 2.4270\n",
      "Average loss: 36437533786782984.0000\n",
      "Epoch: 10\n",
      "Batch 50, loss = 20940.0664, recon_loss = 20937.0000, kl_loss = 3.0662\n",
      "Batch 100, loss = 1278.7120, recon_loss = 1278.3412, kl_loss = 0.3708\n",
      "Batch 150, loss = 206.3950, recon_loss = 206.0328, kl_loss = 0.3622\n",
      "Batch 200, loss = 304001.1250, recon_loss = 304000.6250, kl_loss = 0.5031\n",
      "Batch 250, loss = 357.0282, recon_loss = 356.6019, kl_loss = 0.4263\n",
      "Batch 300, loss = 811.1962, recon_loss = 810.7340, kl_loss = 0.4622\n",
      "Batch 350, loss = 739.6353, recon_loss = 739.1963, kl_loss = 0.4389\n",
      "Batch 400, loss = 2248.7043, recon_loss = 2245.9614, kl_loss = 2.7430\n",
      "Batch 450, loss = 204049.3906, recon_loss = 204045.6719, kl_loss = 3.7155\n",
      "Batch 500, loss = 2708.8398, recon_loss = 2704.4534, kl_loss = 4.3864\n",
      "Batch 550, loss = 28623.1055, recon_loss = 28618.7344, kl_loss = 4.3710\n",
      "Batch 600, loss = 40930208.0000, recon_loss = 40930204.0000, kl_loss = 3.0175\n",
      "Batch 650, loss = 390594325118976.0000, recon_loss = 390594325118976.0000, kl_loss = 2.3214\n",
      "Batch 700, loss = 5848199805796352.0000, recon_loss = 5848199805796352.0000, kl_loss = 2.5148\n",
      "Average loss: 36437533261173688.0000\n",
      "Epoch: 11\n",
      "Batch 50, loss = 17042.8730, recon_loss = 17039.6816, kl_loss = 3.1907\n",
      "Batch 100, loss = 1268.5742, recon_loss = 1268.1449, kl_loss = 0.4293\n",
      "Batch 150, loss = 204.1883, recon_loss = 203.7413, kl_loss = 0.4471\n",
      "Batch 200, loss = 303993.6562, recon_loss = 303993.1562, kl_loss = 0.4980\n",
      "Batch 250, loss = 357.9207, recon_loss = 357.5241, kl_loss = 0.3965\n",
      "Batch 300, loss = 803.5812, recon_loss = 803.1659, kl_loss = 0.4153\n",
      "Batch 350, loss = 739.9747, recon_loss = 739.5312, kl_loss = 0.4435\n",
      "Batch 400, loss = 2259.8020, recon_loss = 2256.7739, kl_loss = 3.0281\n",
      "Batch 450, loss = 202525.0938, recon_loss = 202521.3750, kl_loss = 3.7231\n",
      "Batch 500, loss = 2029.5267, recon_loss = 2025.3004, kl_loss = 4.2264\n",
      "Batch 550, loss = 28421.9414, recon_loss = 28417.9629, kl_loss = 3.9786\n",
      "Batch 600, loss = 40864980.0000, recon_loss = 40864976.0000, kl_loss = 3.1337\n",
      "Batch 650, loss = 390593385594880.0000, recon_loss = 390593385594880.0000, kl_loss = 2.3705\n",
      "Batch 700, loss = 5848199268925440.0000, recon_loss = 5848199268925440.0000, kl_loss = 2.5934\n",
      "Average loss: 36437533096072456.0000\n",
      "Epoch: 12\n",
      "Batch 50, loss = 13950.5615, recon_loss = 13947.2988, kl_loss = 3.2624\n",
      "Batch 100, loss = 1268.3290, recon_loss = 1267.8672, kl_loss = 0.4618\n",
      "Batch 150, loss = 202.9845, recon_loss = 202.5358, kl_loss = 0.4487\n",
      "Batch 200, loss = 303997.3125, recon_loss = 303996.7812, kl_loss = 0.5304\n",
      "Batch 250, loss = 352.7799, recon_loss = 352.3048, kl_loss = 0.4751\n",
      "Batch 300, loss = 790.3428, recon_loss = 789.8195, kl_loss = 0.5232\n",
      "Batch 350, loss = 740.7313, recon_loss = 740.1442, kl_loss = 0.5871\n",
      "Batch 400, loss = 2183.1301, recon_loss = 2179.8833, kl_loss = 3.2468\n",
      "Batch 450, loss = 201667.3906, recon_loss = 201663.2656, kl_loss = 4.1293\n",
      "Batch 500, loss = 1923.3368, recon_loss = 1919.5659, kl_loss = 3.7708\n",
      "Batch 550, loss = 28405.7832, recon_loss = 28402.4746, kl_loss = 3.3095\n",
      "Batch 600, loss = 40792100.0000, recon_loss = 40792096.0000, kl_loss = 2.6844\n",
      "Batch 650, loss = 390592446070784.0000, recon_loss = 390592446070784.0000, kl_loss = 2.4591\n",
      "Batch 700, loss = 5848197658312704.0000, recon_loss = 5848197658312704.0000, kl_loss = 2.6847\n",
      "Average loss: 36437532936921800.0000\n",
      "Epoch: 13\n",
      "Batch 50, loss = 11645.1396, recon_loss = 11641.7266, kl_loss = 3.4135\n",
      "Batch 100, loss = 1236.5957, recon_loss = 1235.9812, kl_loss = 0.6145\n",
      "Batch 150, loss = 200.3441, recon_loss = 199.8518, kl_loss = 0.4924\n",
      "Batch 200, loss = 303993.0625, recon_loss = 303992.3125, kl_loss = 0.7632\n",
      "Batch 250, loss = 349.9762, recon_loss = 349.3859, kl_loss = 0.5903\n",
      "Batch 300, loss = 763.3613, recon_loss = 762.5152, kl_loss = 0.8461\n",
      "Batch 350, loss = 752.9540, recon_loss = 752.0189, kl_loss = 0.9351\n",
      "Batch 400, loss = 2076.5010, recon_loss = 2072.9644, kl_loss = 3.5366\n",
      "Batch 450, loss = 200803.6875, recon_loss = 200799.2812, kl_loss = 4.4003\n",
      "Batch 500, loss = 1918.1724, recon_loss = 1914.8054, kl_loss = 3.3670\n",
      "Batch 550, loss = 28404.5742, recon_loss = 28401.5312, kl_loss = 3.0424\n",
      "Batch 600, loss = 40723332.0000, recon_loss = 40723328.0000, kl_loss = 2.8302\n",
      "Batch 650, loss = 390591405883392.0000, recon_loss = 390591405883392.0000, kl_loss = 2.5234\n",
      "Batch 700, loss = 5848196584570880.0000, recon_loss = 5848196584570880.0000, kl_loss = 2.7590\n",
      "Average loss: 36437532391607168.0000\n",
      "Epoch: 14\n",
      "Batch 50, loss = 9835.2236, recon_loss = 9831.7100, kl_loss = 3.5142\n",
      "Batch 100, loss = 1203.4388, recon_loss = 1202.4929, kl_loss = 0.9459\n",
      "Batch 150, loss = 197.2340, recon_loss = 196.6700, kl_loss = 0.5640\n",
      "Batch 200, loss = 303981.0938, recon_loss = 303980.1875, kl_loss = 0.9043\n",
      "Batch 250, loss = 351.1132, recon_loss = 350.4940, kl_loss = 0.6192\n",
      "Batch 300, loss = 719.9163, recon_loss = 718.7962, kl_loss = 1.1201\n",
      "Batch 350, loss = 758.2148, recon_loss = 757.2997, kl_loss = 0.9151\n",
      "Batch 400, loss = 1993.5704, recon_loss = 1989.7811, kl_loss = 3.7893\n",
      "Batch 450, loss = 199723.7500, recon_loss = 199719.3750, kl_loss = 4.3697\n",
      "Batch 500, loss = 1911.4512, recon_loss = 1908.5219, kl_loss = 2.9293\n",
      "Batch 550, loss = 28400.2031, recon_loss = 28397.2949, kl_loss = 2.9077\n",
      "Batch 600, loss = 40654420.0000, recon_loss = 40654416.0000, kl_loss = 2.6651\n",
      "Batch 650, loss = 390590399250432.0000, recon_loss = 390590399250432.0000, kl_loss = 2.5755\n",
      "Batch 700, loss = 5848196047699968.0000, recon_loss = 5848196047699968.0000, kl_loss = 2.8167\n",
      "Average loss: 36437532230862968.0000\n",
      "Epoch: 15\n",
      "Batch 50, loss = 8223.0537, recon_loss = 8219.4111, kl_loss = 3.6428\n",
      "Batch 100, loss = 1171.4078, recon_loss = 1170.4492, kl_loss = 0.9586\n",
      "Batch 150, loss = 197.4200, recon_loss = 196.8667, kl_loss = 0.5533\n",
      "Batch 200, loss = 303971.4688, recon_loss = 303970.5000, kl_loss = 0.9618\n",
      "Batch 250, loss = 353.2824, recon_loss = 352.7029, kl_loss = 0.5796\n",
      "Batch 300, loss = 691.6194, recon_loss = 690.4601, kl_loss = 1.1593\n",
      "Batch 350, loss = 744.1572, recon_loss = 743.3600, kl_loss = 0.7971\n",
      "Batch 400, loss = 1920.9127, recon_loss = 1916.9524, kl_loss = 3.9603\n",
      "Batch 450, loss = 199078.5312, recon_loss = 199073.9062, kl_loss = 4.6281\n",
      "Batch 500, loss = 1910.6973, recon_loss = 1907.9315, kl_loss = 2.7658\n",
      "Batch 550, loss = 28397.1738, recon_loss = 28394.4297, kl_loss = 2.7445\n",
      "Batch 600, loss = 40582144.0000, recon_loss = 40582140.0000, kl_loss = 2.8071\n",
      "Batch 650, loss = 390589359063040.0000, recon_loss = 390589359063040.0000, kl_loss = 2.5819\n",
      "Batch 700, loss = 5848194973958144.0000, recon_loss = 5848194973958144.0000, kl_loss = 2.8433\n",
      "Average loss: 36437532035973672.0000\n",
      "Epoch: 16\n",
      "Batch 50, loss = 7134.8247, recon_loss = 7131.1206, kl_loss = 3.7040\n",
      "Batch 100, loss = 1127.5287, recon_loss = 1126.4238, kl_loss = 1.1049\n",
      "Batch 150, loss = 194.7124, recon_loss = 194.0405, kl_loss = 0.6719\n",
      "Batch 200, loss = 303963.1562, recon_loss = 303961.8438, kl_loss = 1.3150\n",
      "Batch 250, loss = 353.0587, recon_loss = 352.3853, kl_loss = 0.6734\n",
      "Batch 300, loss = 658.0389, recon_loss = 656.7249, kl_loss = 1.3140\n",
      "Batch 350, loss = 746.2731, recon_loss = 745.4545, kl_loss = 0.8186\n",
      "Batch 400, loss = 1856.6917, recon_loss = 1852.6310, kl_loss = 4.0606\n",
      "Batch 450, loss = 198276.4375, recon_loss = 198271.8125, kl_loss = 4.6320\n",
      "Batch 500, loss = 1905.9541, recon_loss = 1903.3896, kl_loss = 2.5644\n",
      "Batch 550, loss = 28392.2773, recon_loss = 28389.6758, kl_loss = 2.6007\n",
      "Batch 600, loss = 40501236.0000, recon_loss = 40501232.0000, kl_loss = 2.7074\n",
      "Batch 650, loss = 390588352430080.0000, recon_loss = 390588352430080.0000, kl_loss = 2.5503\n",
      "Batch 700, loss = 5848194437087232.0000, recon_loss = 5848194437087232.0000, kl_loss = 2.8131\n",
      "Average loss: 36437531872301216.0000\n",
      "Epoch: 17\n",
      "Batch 50, loss = 7133.1216, recon_loss = 7129.3867, kl_loss = 3.7349\n",
      "Batch 100, loss = 1146.6449, recon_loss = 1145.6458, kl_loss = 0.9991\n",
      "Batch 150, loss = 198.3129, recon_loss = 197.6147, kl_loss = 0.6983\n",
      "Batch 200, loss = 303974.5312, recon_loss = 303973.2500, kl_loss = 1.2932\n",
      "Batch 250, loss = 349.7180, recon_loss = 349.0614, kl_loss = 0.6566\n",
      "Batch 300, loss = 626.6381, recon_loss = 625.2700, kl_loss = 1.3681\n",
      "Batch 350, loss = 750.0042, recon_loss = 749.1478, kl_loss = 0.8564\n",
      "Batch 400, loss = 1721.1224, recon_loss = 1717.0336, kl_loss = 4.0889\n",
      "Batch 450, loss = 198074.7188, recon_loss = 198070.0938, kl_loss = 4.6288\n",
      "Batch 500, loss = 1901.4316, recon_loss = 1898.9219, kl_loss = 2.5097\n",
      "Batch 550, loss = 28387.6895, recon_loss = 28385.2383, kl_loss = 2.4516\n",
      "Batch 600, loss = 40421388.0000, recon_loss = 40421384.0000, kl_loss = 3.1053\n",
      "Batch 650, loss = 390587345797120.0000, recon_loss = 390587345797120.0000, kl_loss = 2.6139\n",
      "Batch 700, loss = 5848192826474496.0000, recon_loss = 5848192826474496.0000, kl_loss = 2.8770\n",
      "Average loss: 36437531695878856.0000\n",
      "Epoch: 18\n",
      "Batch 50, loss = 6158.1338, recon_loss = 6154.3604, kl_loss = 3.7735\n",
      "Batch 100, loss = 1170.1221, recon_loss = 1169.0411, kl_loss = 1.0809\n",
      "Batch 150, loss = 194.7720, recon_loss = 194.0430, kl_loss = 0.7290\n",
      "Batch 200, loss = 303989.6562, recon_loss = 303988.3125, kl_loss = 1.3434\n",
      "Batch 250, loss = 350.6441, recon_loss = 349.9061, kl_loss = 0.7380\n",
      "Batch 300, loss = 605.7923, recon_loss = 604.2342, kl_loss = 1.5581\n",
      "Batch 350, loss = 733.3451, recon_loss = 732.4947, kl_loss = 0.8504\n",
      "Batch 400, loss = 1641.0450, recon_loss = 1636.8591, kl_loss = 4.1859\n",
      "Batch 450, loss = 197602.0781, recon_loss = 197597.1875, kl_loss = 4.8846\n",
      "Batch 500, loss = 1895.2949, recon_loss = 1892.7094, kl_loss = 2.5856\n",
      "Batch 550, loss = 28384.2168, recon_loss = 28381.7168, kl_loss = 2.5006\n",
      "Batch 600, loss = 40346148.0000, recon_loss = 40346144.0000, kl_loss = 3.3234\n",
      "Batch 650, loss = 390586272055296.0000, recon_loss = 390586272055296.0000, kl_loss = 2.6174\n",
      "Batch 700, loss = 5848191752732672.0000, recon_loss = 5848191752732672.0000, kl_loss = 2.8908\n",
      "Average loss: 36437531520150784.0000\n",
      "Epoch: 19\n",
      "Batch 50, loss = 44116.1445, recon_loss = 44112.8125, kl_loss = 3.3302\n",
      "Batch 100, loss = 1081.6549, recon_loss = 1080.3588, kl_loss = 1.2961\n",
      "Batch 150, loss = 193.9501, recon_loss = 193.1925, kl_loss = 0.7576\n",
      "Batch 200, loss = 303969.8438, recon_loss = 303968.8125, kl_loss = 1.0426\n",
      "Batch 250, loss = 352.9782, recon_loss = 352.3733, kl_loss = 0.6049\n",
      "Batch 300, loss = 568.3875, recon_loss = 566.8461, kl_loss = 1.5414\n",
      "Batch 350, loss = 736.9795, recon_loss = 736.0706, kl_loss = 0.9089\n",
      "Batch 400, loss = 1576.5410, recon_loss = 1572.3599, kl_loss = 4.1812\n",
      "Batch 450, loss = 197596.6719, recon_loss = 197591.9062, kl_loss = 4.7687\n",
      "Batch 500, loss = 1891.8134, recon_loss = 1889.4888, kl_loss = 2.3245\n",
      "Batch 550, loss = 28383.4512, recon_loss = 28381.0879, kl_loss = 2.3634\n",
      "Batch 600, loss = 40268764.0000, recon_loss = 40268760.0000, kl_loss = 3.4013\n",
      "Batch 650, loss = 390585198313472.0000, recon_loss = 390585198313472.0000, kl_loss = 2.7010\n",
      "Batch 700, loss = 5848190142119936.0000, recon_loss = 5848190142119936.0000, kl_loss = 2.9797\n",
      "Average loss: 36437531330760776.0000\n",
      "Epoch: 20\n",
      "Batch 50, loss = 6007.7158, recon_loss = 6003.9893, kl_loss = 3.7266\n",
      "Batch 100, loss = 1153.4066, recon_loss = 1152.1508, kl_loss = 1.2559\n",
      "Batch 150, loss = 194.2554, recon_loss = 193.4448, kl_loss = 0.8107\n",
      "Batch 200, loss = 303973.5000, recon_loss = 303972.5000, kl_loss = 0.9991\n",
      "Batch 250, loss = 345.1162, recon_loss = 344.3183, kl_loss = 0.7979\n",
      "Batch 300, loss = 555.7722, recon_loss = 554.1375, kl_loss = 1.6348\n",
      "Batch 350, loss = 729.3113, recon_loss = 728.4129, kl_loss = 0.8984\n",
      "Batch 400, loss = 1569.3882, recon_loss = 1565.0242, kl_loss = 4.3640\n",
      "Batch 450, loss = 197997.7188, recon_loss = 197992.8750, kl_loss = 4.8399\n",
      "Batch 500, loss = 1886.4208, recon_loss = 1884.1119, kl_loss = 2.3088\n",
      "Batch 550, loss = 28381.1172, recon_loss = 28378.7051, kl_loss = 2.4113\n",
      "Batch 600, loss = 40192396.0000, recon_loss = 40192392.0000, kl_loss = 3.5231\n",
      "Batch 650, loss = 390584124571648.0000, recon_loss = 390584124571648.0000, kl_loss = 2.7451\n",
      "Batch 700, loss = 5848188531507200.0000, recon_loss = 5848188531507200.0000, kl_loss = 3.0209\n",
      "Average loss: 36437531136043672.0000\n",
      "Epoch: 21\n",
      "Batch 50, loss = 6085.0234, recon_loss = 6081.1763, kl_loss = 3.8473\n",
      "Batch 100, loss = 1007.4710, recon_loss = 1005.8356, kl_loss = 1.6354\n",
      "Batch 150, loss = 197.3154, recon_loss = 196.5063, kl_loss = 0.8091\n",
      "Batch 200, loss = 303970.4062, recon_loss = 303969.2188, kl_loss = 1.1739\n",
      "Batch 250, loss = 346.0899, recon_loss = 345.2411, kl_loss = 0.8488\n",
      "Batch 300, loss = 541.1691, recon_loss = 539.4744, kl_loss = 1.6947\n",
      "Batch 350, loss = 727.3583, recon_loss = 726.4478, kl_loss = 0.9106\n",
      "Batch 400, loss = 1542.7439, recon_loss = 1538.3257, kl_loss = 4.4182\n",
      "Batch 450, loss = 198739.1875, recon_loss = 198734.2188, kl_loss = 4.9697\n",
      "Batch 500, loss = 1883.9161, recon_loss = 1881.6400, kl_loss = 2.2761\n",
      "Batch 550, loss = 28379.6641, recon_loss = 28377.4316, kl_loss = 2.2320\n",
      "Batch 600, loss = 40117364.0000, recon_loss = 40117360.0000, kl_loss = 3.5528\n",
      "Batch 650, loss = 390582983720960.0000, recon_loss = 390582983720960.0000, kl_loss = 2.7390\n",
      "Batch 700, loss = 5848187457765376.0000, recon_loss = 5848187457765376.0000, kl_loss = 3.0193\n",
      "Average loss: 36437530949815872.0000\n",
      "Epoch: 22\n",
      "Batch 50, loss = 6108.2725, recon_loss = 6104.4082, kl_loss = 3.8641\n",
      "Batch 100, loss = 984.4946, recon_loss = 982.7991, kl_loss = 1.6955\n",
      "Batch 150, loss = 192.6044, recon_loss = 191.7370, kl_loss = 0.8673\n",
      "Batch 200, loss = 303964.8125, recon_loss = 303963.7188, kl_loss = 1.0943\n",
      "Batch 250, loss = 345.9759, recon_loss = 345.1730, kl_loss = 0.8029\n",
      "Batch 300, loss = 522.8954, recon_loss = 521.2664, kl_loss = 1.6291\n",
      "Batch 350, loss = 726.5148, recon_loss = 725.5844, kl_loss = 0.9304\n",
      "Batch 400, loss = 1531.4510, recon_loss = 1527.2026, kl_loss = 4.2484\n",
      "Batch 450, loss = 197388.4375, recon_loss = 197383.7812, kl_loss = 4.6532\n",
      "Batch 500, loss = 1884.9073, recon_loss = 1882.7727, kl_loss = 2.1347\n",
      "Batch 550, loss = 28377.9062, recon_loss = 28375.7500, kl_loss = 2.1557\n",
      "Batch 600, loss = 40043100.0000, recon_loss = 40043096.0000, kl_loss = 3.6234\n",
      "Batch 650, loss = 390581909979136.0000, recon_loss = 390581909979136.0000, kl_loss = 2.7959\n",
      "Batch 700, loss = 5848187457765376.0000, recon_loss = 5848187457765376.0000, kl_loss = 3.0791\n",
      "Average loss: 36437527069566624.0000\n",
      "Epoch: 23\n",
      "Batch 50, loss = 6082.2490, recon_loss = 6078.5166, kl_loss = 3.7322\n",
      "Batch 100, loss = 985.5239, recon_loss = 983.9592, kl_loss = 1.5647\n",
      "Batch 150, loss = 190.8292, recon_loss = 189.9660, kl_loss = 0.8632\n",
      "Batch 200, loss = 303964.4688, recon_loss = 303963.3750, kl_loss = 1.0986\n",
      "Batch 250, loss = 341.9170, recon_loss = 341.0753, kl_loss = 0.8417\n",
      "Batch 300, loss = 540.8996, recon_loss = 539.1633, kl_loss = 1.7362\n",
      "Batch 350, loss = 729.9888, recon_loss = 729.0167, kl_loss = 0.9721\n",
      "Batch 400, loss = 1530.4009, recon_loss = 1526.3694, kl_loss = 4.0315\n",
      "Batch 450, loss = 203849.6562, recon_loss = 203845.0312, kl_loss = 4.6317\n",
      "Batch 500, loss = 1882.1687, recon_loss = 1880.0083, kl_loss = 2.1604\n",
      "Batch 550, loss = 28376.0020, recon_loss = 28373.8516, kl_loss = 2.1496\n",
      "Batch 600, loss = 39970260.0000, recon_loss = 39970256.0000, kl_loss = 3.6357\n",
      "Batch 650, loss = 390580735574016.0000, recon_loss = 390580735574016.0000, kl_loss = 2.8275\n",
      "Batch 700, loss = 5848185847152640.0000, recon_loss = 5848185847152640.0000, kl_loss = 3.1169\n",
      "Average loss: 36437526882451056.0000\n",
      "Epoch: 24\n",
      "Batch 50, loss = 6436.8887, recon_loss = 6433.0864, kl_loss = 3.8025\n",
      "Batch 100, loss = 1009.6111, recon_loss = 1007.9138, kl_loss = 1.6974\n",
      "Batch 150, loss = 191.0779, recon_loss = 190.1296, kl_loss = 0.9483\n",
      "Batch 200, loss = 303969.6875, recon_loss = 303968.5625, kl_loss = 1.1381\n",
      "Batch 250, loss = 349.2296, recon_loss = 348.4838, kl_loss = 0.7459\n",
      "Batch 300, loss = 514.5363, recon_loss = 512.8272, kl_loss = 1.7091\n",
      "Batch 350, loss = 722.8710, recon_loss = 721.9050, kl_loss = 0.9660\n",
      "Batch 400, loss = 1527.6179, recon_loss = 1523.4023, kl_loss = 4.2156\n",
      "Batch 450, loss = 198624.4531, recon_loss = 198619.9531, kl_loss = 4.5075\n",
      "Batch 500, loss = 1880.9940, recon_loss = 1878.8387, kl_loss = 2.1553\n",
      "Batch 550, loss = 28376.4609, recon_loss = 28374.3574, kl_loss = 2.1043\n",
      "Batch 600, loss = 39898320.0000, recon_loss = 39898316.0000, kl_loss = 3.8059\n",
      "Batch 650, loss = 390579594723328.0000, recon_loss = 390579594723328.0000, kl_loss = 2.8307\n",
      "Batch 700, loss = 5848184236539904.0000, recon_loss = 5848184236539904.0000, kl_loss = 3.1301\n",
      "Average loss: 36437526683378632.0000\n",
      "Epoch: 25\n",
      "Batch 50, loss = 6124.8613, recon_loss = 6121.0303, kl_loss = 3.8313\n",
      "Batch 100, loss = 974.4260, recon_loss = 972.7159, kl_loss = 1.7101\n",
      "Batch 150, loss = 191.3420, recon_loss = 190.4109, kl_loss = 0.9311\n",
      "Batch 200, loss = 303960.1250, recon_loss = 303958.9375, kl_loss = 1.1736\n",
      "Batch 250, loss = 345.6401, recon_loss = 344.6958, kl_loss = 0.9443\n",
      "Batch 300, loss = 543.7754, recon_loss = 541.9345, kl_loss = 1.8409\n",
      "Batch 350, loss = 720.8236, recon_loss = 719.8824, kl_loss = 0.9412\n",
      "Batch 400, loss = 1525.2202, recon_loss = 1521.1111, kl_loss = 4.1091\n",
      "Batch 450, loss = 201652.9844, recon_loss = 201648.5625, kl_loss = 4.4166\n",
      "Batch 500, loss = 1881.7343, recon_loss = 1879.5969, kl_loss = 2.1373\n",
      "Batch 550, loss = 28373.6152, recon_loss = 28371.6094, kl_loss = 2.0068\n",
      "Batch 600, loss = 39826968.0000, recon_loss = 39826964.0000, kl_loss = 3.9046\n",
      "Batch 650, loss = 390578487427072.0000, recon_loss = 390578487427072.0000, kl_loss = 2.8538\n",
      "Batch 700, loss = 5848183699668992.0000, recon_loss = 5848183699668992.0000, kl_loss = 3.1438\n",
      "Average loss: 36437526495924904.0000\n",
      "Epoch: 26\n",
      "Batch 50, loss = 6139.6826, recon_loss = 6135.8765, kl_loss = 3.8063\n",
      "Batch 100, loss = 990.6912, recon_loss = 989.0369, kl_loss = 1.6543\n",
      "Batch 150, loss = 187.2376, recon_loss = 186.3035, kl_loss = 0.9341\n",
      "Batch 200, loss = 303961.3750, recon_loss = 303960.2500, kl_loss = 1.1397\n",
      "Batch 250, loss = 342.7810, recon_loss = 341.8920, kl_loss = 0.8890\n",
      "Batch 300, loss = 528.3725, recon_loss = 526.6023, kl_loss = 1.7702\n",
      "Batch 350, loss = 719.3719, recon_loss = 718.4586, kl_loss = 0.9133\n",
      "Batch 400, loss = 1525.2552, recon_loss = 1521.0944, kl_loss = 4.1609\n",
      "Batch 450, loss = 197385.3281, recon_loss = 197380.8750, kl_loss = 4.4458\n",
      "Batch 500, loss = 1880.4539, recon_loss = 1878.4368, kl_loss = 2.0171\n",
      "Batch 550, loss = 28373.4844, recon_loss = 28371.5840, kl_loss = 1.9010\n",
      "Batch 600, loss = 39756236.0000, recon_loss = 39756232.0000, kl_loss = 3.7224\n",
      "Batch 650, loss = 390577346576384.0000, recon_loss = 390577346576384.0000, kl_loss = 2.8748\n",
      "Batch 700, loss = 5848182625927168.0000, recon_loss = 5848182625927168.0000, kl_loss = 3.1684\n",
      "Average loss: 36437526299876912.0000\n",
      "Epoch: 27\n",
      "Batch 50, loss = 6144.4458, recon_loss = 6140.5957, kl_loss = 3.8501\n",
      "Batch 100, loss = 958.8896, recon_loss = 957.1646, kl_loss = 1.7250\n",
      "Batch 150, loss = 188.6370, recon_loss = 187.7630, kl_loss = 0.8740\n",
      "Batch 200, loss = 303960.7188, recon_loss = 303959.7812, kl_loss = 0.9329\n",
      "Batch 250, loss = 342.0704, recon_loss = 341.2004, kl_loss = 0.8701\n",
      "Batch 300, loss = 515.1109, recon_loss = 513.2819, kl_loss = 1.8290\n",
      "Batch 350, loss = 718.4702, recon_loss = 717.4941, kl_loss = 0.9761\n",
      "Batch 400, loss = 1525.1511, recon_loss = 1520.9026, kl_loss = 4.2485\n",
      "Batch 450, loss = 196647.5156, recon_loss = 196643.1719, kl_loss = 4.3373\n",
      "Batch 500, loss = 1879.6572, recon_loss = 1877.8049, kl_loss = 1.8523\n",
      "Batch 550, loss = 28373.5625, recon_loss = 28371.7402, kl_loss = 1.8228\n",
      "Batch 600, loss = 39685700.0000, recon_loss = 39685696.0000, kl_loss = 3.7431\n",
      "Batch 650, loss = 390576239280128.0000, recon_loss = 390576239280128.0000, kl_loss = 2.9346\n",
      "Batch 700, loss = 5848181552185344.0000, recon_loss = 5848181552185344.0000, kl_loss = 3.2348\n",
      "Average loss: 36437526102193296.0000\n",
      "Epoch: 28\n",
      "Batch 50, loss = 6168.7036, recon_loss = 6164.8320, kl_loss = 3.8718\n",
      "Batch 100, loss = 970.1536, recon_loss = 968.3246, kl_loss = 1.8290\n",
      "Batch 150, loss = 186.7665, recon_loss = 185.8100, kl_loss = 0.9565\n",
      "Batch 200, loss = 303953.0938, recon_loss = 303952.0625, kl_loss = 1.0239\n",
      "Batch 250, loss = 340.9291, recon_loss = 339.9808, kl_loss = 0.9483\n",
      "Batch 300, loss = 515.8525, recon_loss = 514.0847, kl_loss = 1.7679\n",
      "Batch 350, loss = 718.1009, recon_loss = 717.0970, kl_loss = 1.0038\n",
      "Batch 400, loss = 1522.1079, recon_loss = 1518.2371, kl_loss = 3.8708\n",
      "Batch 450, loss = 197031.7188, recon_loss = 197027.5156, kl_loss = 4.2015\n",
      "Batch 500, loss = 1879.6813, recon_loss = 1877.8687, kl_loss = 1.8126\n",
      "Batch 550, loss = 28373.9160, recon_loss = 28372.1855, kl_loss = 1.7304\n",
      "Batch 600, loss = 39614372.0000, recon_loss = 39614368.0000, kl_loss = 3.7019\n",
      "Batch 650, loss = 390575131983872.0000, recon_loss = 390575131983872.0000, kl_loss = 2.9496\n",
      "Batch 700, loss = 5848179941572608.0000, recon_loss = 5848179941572608.0000, kl_loss = 3.2533\n",
      "Average loss: 36437525908089688.0000\n",
      "Epoch: 29\n",
      "Batch 50, loss = 6193.3218, recon_loss = 6189.3252, kl_loss = 3.9964\n",
      "Batch 100, loss = 966.0828, recon_loss = 964.2927, kl_loss = 1.7901\n",
      "Batch 150, loss = 186.4095, recon_loss = 185.4087, kl_loss = 1.0008\n",
      "Batch 200, loss = 303951.3750, recon_loss = 303950.3125, kl_loss = 1.0630\n",
      "Batch 250, loss = 344.1414, recon_loss = 343.1883, kl_loss = 0.9530\n",
      "Batch 300, loss = 528.4188, recon_loss = 526.6634, kl_loss = 1.7554\n",
      "Batch 350, loss = 717.9150, recon_loss = 716.9658, kl_loss = 0.9492\n",
      "Batch 400, loss = 1519.1569, recon_loss = 1515.4236, kl_loss = 3.7333\n",
      "Batch 450, loss = 201735.5000, recon_loss = 201731.2812, kl_loss = 4.2222\n",
      "Batch 500, loss = 1879.4242, recon_loss = 1877.7556, kl_loss = 1.6685\n",
      "Batch 550, loss = 28375.6289, recon_loss = 28374.0176, kl_loss = 1.6114\n",
      "Batch 600, loss = 39536556.0000, recon_loss = 39536552.0000, kl_loss = 3.9629\n",
      "Batch 650, loss = 390573991133184.0000, recon_loss = 390573991133184.0000, kl_loss = 3.0652\n",
      "Batch 700, loss = 5848178330959872.0000, recon_loss = 5848178330959872.0000, kl_loss = 3.3688\n",
      "Average loss: 36437525713543600.0000\n",
      "Epoch: 30\n",
      "Batch 50, loss = 6213.1177, recon_loss = 6209.2900, kl_loss = 3.8278\n",
      "Batch 100, loss = 977.8287, recon_loss = 976.1948, kl_loss = 1.6338\n",
      "Batch 150, loss = 183.5789, recon_loss = 182.6432, kl_loss = 0.9356\n",
      "Batch 200, loss = 303949.3125, recon_loss = 303948.3438, kl_loss = 0.9770\n",
      "Batch 250, loss = 338.5655, recon_loss = 337.6107, kl_loss = 0.9548\n",
      "Batch 300, loss = 529.7641, recon_loss = 527.9301, kl_loss = 1.8340\n",
      "Batch 350, loss = 715.3470, recon_loss = 714.3793, kl_loss = 0.9677\n",
      "Batch 400, loss = 1520.2988, recon_loss = 1516.5640, kl_loss = 3.7349\n",
      "Batch 450, loss = 201303.4531, recon_loss = 201299.4375, kl_loss = 4.0093\n",
      "Batch 500, loss = 1879.1998, recon_loss = 1877.6116, kl_loss = 1.5882\n",
      "Batch 550, loss = 28375.8125, recon_loss = 28374.0977, kl_loss = 1.7149\n",
      "Batch 600, loss = 39466240.0000, recon_loss = 39466236.0000, kl_loss = 3.9242\n",
      "Batch 650, loss = 390572850282496.0000, recon_loss = 390572850282496.0000, kl_loss = 3.0683\n",
      "Batch 700, loss = 5848177794088960.0000, recon_loss = 5848177794088960.0000, kl_loss = 3.4017\n",
      "Average loss: 36437522567135912.0000\n",
      "Epoch: 31\n",
      "Batch 50, loss = 6201.4180, recon_loss = 6197.4492, kl_loss = 3.9689\n",
      "Batch 100, loss = 954.0979, recon_loss = 952.4017, kl_loss = 1.6962\n",
      "Batch 150, loss = 185.5025, recon_loss = 184.5724, kl_loss = 0.9301\n",
      "Batch 200, loss = 303943.5312, recon_loss = 303942.6562, kl_loss = 0.8744\n",
      "Batch 250, loss = 354.4922, recon_loss = 353.7772, kl_loss = 0.7150\n",
      "Batch 300, loss = 529.3302, recon_loss = 527.6713, kl_loss = 1.6589\n",
      "Batch 350, loss = 714.9366, recon_loss = 714.0493, kl_loss = 0.8873\n",
      "Batch 400, loss = 1518.0336, recon_loss = 1514.3292, kl_loss = 3.7043\n",
      "Batch 450, loss = 196525.2500, recon_loss = 196521.1875, kl_loss = 4.0550\n",
      "Batch 500, loss = 1880.6029, recon_loss = 1878.9082, kl_loss = 1.6947\n",
      "Batch 550, loss = 28379.1914, recon_loss = 28377.5703, kl_loss = 1.6202\n",
      "Batch 600, loss = 39395452.0000, recon_loss = 39395448.0000, kl_loss = 3.8006\n",
      "Batch 650, loss = 390571709431808.0000, recon_loss = 390571709431808.0000, kl_loss = 3.1289\n",
      "Batch 700, loss = 5848176720347136.0000, recon_loss = 5848176720347136.0000, kl_loss = 3.4338\n",
      "Average loss: 36437522374793192.0000\n",
      "Epoch: 32\n",
      "Batch 50, loss = 6212.6807, recon_loss = 6208.8584, kl_loss = 3.8225\n",
      "Batch 100, loss = 1044.2026, recon_loss = 1042.5745, kl_loss = 1.6281\n",
      "Batch 150, loss = 188.3072, recon_loss = 187.2896, kl_loss = 1.0175\n",
      "Batch 200, loss = 303942.4375, recon_loss = 303941.4688, kl_loss = 0.9596\n",
      "Batch 250, loss = 336.6207, recon_loss = 335.6936, kl_loss = 0.9271\n",
      "Batch 300, loss = 533.8848, recon_loss = 532.2098, kl_loss = 1.6750\n",
      "Batch 350, loss = 714.0218, recon_loss = 712.9869, kl_loss = 1.0348\n",
      "Batch 400, loss = 1518.8212, recon_loss = 1515.0707, kl_loss = 3.7505\n",
      "Batch 450, loss = 199217.8125, recon_loss = 199213.6562, kl_loss = 4.1517\n",
      "Batch 500, loss = 1879.3088, recon_loss = 1877.6661, kl_loss = 1.6427\n",
      "Batch 550, loss = 28375.9199, recon_loss = 28374.3086, kl_loss = 1.6114\n",
      "Batch 600, loss = 39325796.0000, recon_loss = 39325792.0000, kl_loss = 3.4254\n",
      "Batch 650, loss = 390570602135552.0000, recon_loss = 390570602135552.0000, kl_loss = 3.1405\n",
      "Batch 700, loss = 5848174572863488.0000, recon_loss = 5848174572863488.0000, kl_loss = 3.4587\n",
      "Average loss: 36437521444214224.0000\n",
      "Epoch: 33\n",
      "Batch 50, loss = 6239.2114, recon_loss = 6235.3413, kl_loss = 3.8702\n",
      "Batch 100, loss = 953.6680, recon_loss = 951.9605, kl_loss = 1.7075\n",
      "Batch 150, loss = 184.8984, recon_loss = 183.9452, kl_loss = 0.9533\n",
      "Batch 200, loss = 303941.1250, recon_loss = 303940.1250, kl_loss = 1.0089\n",
      "Batch 250, loss = 338.7862, recon_loss = 337.8329, kl_loss = 0.9533\n",
      "Batch 300, loss = 528.0748, recon_loss = 526.3036, kl_loss = 1.7711\n",
      "Batch 350, loss = 713.9054, recon_loss = 712.8685, kl_loss = 1.0369\n",
      "Batch 400, loss = 1520.9750, recon_loss = 1517.2463, kl_loss = 3.7287\n",
      "Batch 450, loss = 197167.4844, recon_loss = 197163.3594, kl_loss = 4.1200\n",
      "Batch 500, loss = 1879.0623, recon_loss = 1877.4188, kl_loss = 1.6435\n",
      "Batch 550, loss = 28374.9980, recon_loss = 28373.4238, kl_loss = 1.5741\n",
      "Batch 600, loss = 39255976.0000, recon_loss = 39255972.0000, kl_loss = 3.3935\n",
      "Batch 650, loss = 390569461284864.0000, recon_loss = 390569461284864.0000, kl_loss = 3.1938\n",
      "Batch 700, loss = 5848174572863488.0000, recon_loss = 5848174572863488.0000, kl_loss = 3.5154\n",
      "Average loss: 36437521250530752.0000\n",
      "Epoch: 34\n",
      "Batch 50, loss = 6234.0298, recon_loss = 6230.1797, kl_loss = 3.8503\n",
      "Batch 100, loss = 963.2140, recon_loss = 961.4175, kl_loss = 1.7965\n",
      "Batch 150, loss = 184.0313, recon_loss = 183.0991, kl_loss = 0.9322\n",
      "Batch 200, loss = 304107.0938, recon_loss = 304105.6250, kl_loss = 1.4839\n",
      "Batch 250, loss = 335.6416, recon_loss = 334.7939, kl_loss = 0.8477\n",
      "Batch 300, loss = 511.4936, recon_loss = 509.8699, kl_loss = 1.6237\n",
      "Batch 350, loss = 713.1032, recon_loss = 712.1182, kl_loss = 0.9850\n",
      "Batch 400, loss = 1517.9977, recon_loss = 1514.2698, kl_loss = 3.7280\n",
      "Batch 450, loss = 196944.3438, recon_loss = 196940.3594, kl_loss = 3.9769\n",
      "Batch 500, loss = 1879.6255, recon_loss = 1878.0619, kl_loss = 1.5635\n",
      "Batch 550, loss = 28374.6992, recon_loss = 28373.0781, kl_loss = 1.6209\n",
      "Batch 600, loss = 39188716.0000, recon_loss = 39188712.0000, kl_loss = 4.0181\n",
      "Batch 650, loss = 390568353988608.0000, recon_loss = 390568353988608.0000, kl_loss = 3.2041\n",
      "Batch 700, loss = 5848173499121664.0000, recon_loss = 5848173499121664.0000, kl_loss = 3.5301\n",
      "Average loss: 36437518108387456.0000\n",
      "Epoch: 35\n",
      "Batch 50, loss = 6255.3130, recon_loss = 6251.4126, kl_loss = 3.9002\n",
      "Batch 100, loss = 1034.5046, recon_loss = 1033.0608, kl_loss = 1.4438\n",
      "Batch 150, loss = 187.6907, recon_loss = 186.7548, kl_loss = 0.9359\n",
      "Batch 200, loss = 303936.6875, recon_loss = 303935.7500, kl_loss = 0.9409\n",
      "Batch 250, loss = 343.3003, recon_loss = 342.4827, kl_loss = 0.8176\n",
      "Batch 300, loss = 542.4760, recon_loss = 540.7843, kl_loss = 1.6916\n",
      "Batch 350, loss = 715.3973, recon_loss = 714.3371, kl_loss = 1.0602\n",
      "Batch 400, loss = 1515.8002, recon_loss = 1512.1095, kl_loss = 3.6906\n",
      "Batch 450, loss = 196394.2031, recon_loss = 196390.0625, kl_loss = 4.1423\n",
      "Batch 500, loss = 1879.6841, recon_loss = 1878.0614, kl_loss = 1.6226\n",
      "Batch 550, loss = 28375.2539, recon_loss = 28373.6602, kl_loss = 1.5942\n",
      "Batch 600, loss = 39120548.0000, recon_loss = 39120544.0000, kl_loss = 4.2101\n",
      "Batch 650, loss = 390567213137920.0000, recon_loss = 390567213137920.0000, kl_loss = 3.2159\n",
      "Batch 700, loss = 5848171351638016.0000, recon_loss = 5848171351638016.0000, kl_loss = 3.5368\n",
      "Average loss: 36437517173768808.0000\n",
      "Epoch: 36\n",
      "Batch 50, loss = 6275.9849, recon_loss = 6272.1738, kl_loss = 3.8109\n",
      "Batch 100, loss = 966.8635, recon_loss = 965.0975, kl_loss = 1.7660\n",
      "Batch 150, loss = 187.8174, recon_loss = 186.9321, kl_loss = 0.8853\n",
      "Batch 200, loss = 303938.2812, recon_loss = 303937.3125, kl_loss = 0.9784\n",
      "Batch 250, loss = 338.0644, recon_loss = 337.1027, kl_loss = 0.9617\n",
      "Batch 300, loss = 556.7266, recon_loss = 555.0109, kl_loss = 1.7156\n",
      "Batch 350, loss = 713.1746, recon_loss = 712.1305, kl_loss = 1.0441\n",
      "Batch 400, loss = 1520.2021, recon_loss = 1516.7474, kl_loss = 3.4547\n",
      "Batch 450, loss = 196532.6562, recon_loss = 196528.6562, kl_loss = 3.9939\n",
      "Batch 500, loss = 1879.2135, recon_loss = 1877.6320, kl_loss = 1.5816\n",
      "Batch 550, loss = 28373.1465, recon_loss = 28371.5176, kl_loss = 1.6296\n",
      "Batch 600, loss = 39055660.0000, recon_loss = 39055656.0000, kl_loss = 4.0997\n",
      "Batch 650, loss = 390566105841664.0000, recon_loss = 390566105841664.0000, kl_loss = 3.2396\n",
      "Batch 700, loss = 5848171351638016.0000, recon_loss = 5848171351638016.0000, kl_loss = 3.5628\n",
      "Average loss: 36437516981684560.0000\n",
      "Epoch: 37\n",
      "Batch 50, loss = 6278.6470, recon_loss = 6274.7065, kl_loss = 3.9406\n",
      "Batch 100, loss = 1003.9658, recon_loss = 1002.3879, kl_loss = 1.5779\n",
      "Batch 150, loss = 181.8367, recon_loss = 180.9136, kl_loss = 0.9231\n",
      "Batch 200, loss = 303928.5938, recon_loss = 303927.6250, kl_loss = 0.9564\n",
      "Batch 250, loss = 330.5737, recon_loss = 329.6033, kl_loss = 0.9704\n",
      "Batch 300, loss = 546.4379, recon_loss = 544.7483, kl_loss = 1.6896\n",
      "Batch 350, loss = 710.9365, recon_loss = 709.8977, kl_loss = 1.0387\n",
      "Batch 400, loss = 1522.6066, recon_loss = 1519.2489, kl_loss = 3.3576\n",
      "Batch 450, loss = 196580.6406, recon_loss = 196576.7656, kl_loss = 3.8744\n",
      "Batch 500, loss = 1880.4614, recon_loss = 1878.8127, kl_loss = 1.6487\n",
      "Batch 550, loss = 28375.1152, recon_loss = 28373.4355, kl_loss = 1.6802\n",
      "Batch 600, loss = 38989956.0000, recon_loss = 38989952.0000, kl_loss = 3.2506\n",
      "Batch 650, loss = 390564998545408.0000, recon_loss = 390564998545408.0000, kl_loss = 3.4048\n",
      "Batch 700, loss = 5848169741025280.0000, recon_loss = 5848169741025280.0000, kl_loss = 3.7437\n",
      "Average loss: 36437516794640928.0000\n",
      "Epoch: 38\n",
      "Batch 50, loss = 6283.8794, recon_loss = 6279.9546, kl_loss = 3.9248\n",
      "Batch 100, loss = 924.4526, recon_loss = 922.7831, kl_loss = 1.6695\n",
      "Batch 150, loss = 190.7516, recon_loss = 189.7355, kl_loss = 1.0160\n",
      "Batch 200, loss = 303927.4688, recon_loss = 303926.4688, kl_loss = 0.9991\n",
      "Batch 250, loss = 332.9709, recon_loss = 332.1118, kl_loss = 0.8591\n",
      "Batch 300, loss = 584.8602, recon_loss = 583.3046, kl_loss = 1.5556\n",
      "Batch 350, loss = 711.2465, recon_loss = 710.2416, kl_loss = 1.0049\n",
      "Batch 400, loss = 1513.9790, recon_loss = 1510.6401, kl_loss = 3.3389\n",
      "Batch 450, loss = 197697.2500, recon_loss = 197693.5000, kl_loss = 3.7448\n",
      "Batch 500, loss = 1878.1705, recon_loss = 1876.4973, kl_loss = 1.6732\n",
      "Batch 550, loss = 28377.3340, recon_loss = 28375.5938, kl_loss = 1.7409\n",
      "Batch 600, loss = 38926080.0000, recon_loss = 38926076.0000, kl_loss = 3.5636\n",
      "Batch 650, loss = 390563891249152.0000, recon_loss = 390563891249152.0000, kl_loss = 3.4242\n",
      "Batch 700, loss = 5848168130412544.0000, recon_loss = 5848168130412544.0000, kl_loss = 4.0640\n",
      "Average loss: 36437516613777320.0000\n",
      "Epoch: 39\n",
      "Batch 50, loss = 6262.8096, recon_loss = 6258.8398, kl_loss = 3.9699\n",
      "Batch 100, loss = 1004.9200, recon_loss = 1003.5138, kl_loss = 1.4062\n",
      "Batch 150, loss = 181.7637, recon_loss = 180.8968, kl_loss = 0.8668\n",
      "Batch 200, loss = 303915.5312, recon_loss = 303914.5625, kl_loss = 0.9734\n",
      "Batch 250, loss = 335.1352, recon_loss = 334.2131, kl_loss = 0.9221\n",
      "Batch 300, loss = 533.7032, recon_loss = 531.9989, kl_loss = 1.7044\n",
      "Batch 350, loss = 710.5977, recon_loss = 709.5763, kl_loss = 1.0214\n",
      "Batch 400, loss = 1514.6265, recon_loss = 1511.3945, kl_loss = 3.2320\n",
      "Batch 450, loss = 197240.4062, recon_loss = 197236.1875, kl_loss = 4.2121\n",
      "Batch 500, loss = 1878.3884, recon_loss = 1876.5706, kl_loss = 1.8179\n",
      "Batch 550, loss = 28373.7793, recon_loss = 28372.0469, kl_loss = 1.7330\n",
      "Batch 600, loss = 38860964.0000, recon_loss = 38860960.0000, kl_loss = 3.4008\n",
      "Batch 650, loss = 390562783952896.0000, recon_loss = 390562783952896.0000, kl_loss = 3.4163\n",
      "Batch 700, loss = 5848168130412544.0000, recon_loss = 5848168130412544.0000, kl_loss = 4.0618\n",
      "Average loss: 36437516418046416.0000\n",
      "Epoch: 40\n",
      "Batch 50, loss = 6294.6558, recon_loss = 6290.7212, kl_loss = 3.9347\n",
      "Batch 100, loss = 1017.5743, recon_loss = 1016.1405, kl_loss = 1.4338\n",
      "Batch 150, loss = 185.6078, recon_loss = 184.7039, kl_loss = 0.9039\n",
      "Batch 200, loss = 303924.3125, recon_loss = 303923.3750, kl_loss = 0.9323\n",
      "Batch 250, loss = 327.7334, recon_loss = 326.8352, kl_loss = 0.8982\n",
      "Batch 300, loss = 574.2937, recon_loss = 572.7395, kl_loss = 1.5542\n",
      "Batch 350, loss = 712.1415, recon_loss = 711.0953, kl_loss = 1.0462\n",
      "Batch 400, loss = 1516.7323, recon_loss = 1513.4812, kl_loss = 3.2511\n",
      "Batch 450, loss = 201595.8438, recon_loss = 201591.8750, kl_loss = 3.9673\n",
      "Batch 500, loss = 1880.0264, recon_loss = 1878.2626, kl_loss = 1.7638\n",
      "Batch 550, loss = 28375.3203, recon_loss = 28373.5918, kl_loss = 1.7285\n",
      "Batch 600, loss = 38798972.0000, recon_loss = 38798968.0000, kl_loss = 3.2083\n",
      "Batch 650, loss = 390561643102208.0000, recon_loss = 390561643102208.0000, kl_loss = 3.0536\n",
      "Batch 700, loss = 5848166519799808.0000, recon_loss = 5848166519799808.0000, kl_loss = 4.0733\n",
      "Average loss: 36437516220563064.0000\n",
      "Epoch: 41\n",
      "Batch 50, loss = 6320.5591, recon_loss = 6316.6294, kl_loss = 3.9298\n",
      "Batch 100, loss = 998.8916, recon_loss = 997.6140, kl_loss = 1.2776\n",
      "Batch 150, loss = 182.7376, recon_loss = 181.7652, kl_loss = 0.9724\n",
      "Batch 200, loss = 303914.5000, recon_loss = 303913.4688, kl_loss = 1.0388\n",
      "Batch 250, loss = 325.4010, recon_loss = 324.4344, kl_loss = 0.9666\n",
      "Batch 300, loss = 558.1450, recon_loss = 556.3673, kl_loss = 1.7777\n",
      "Batch 350, loss = 710.8487, recon_loss = 709.7785, kl_loss = 1.0702\n",
      "Batch 400, loss = 1518.5433, recon_loss = 1515.0828, kl_loss = 3.4606\n",
      "Batch 450, loss = 199176.4688, recon_loss = 199172.5469, kl_loss = 3.9273\n",
      "Batch 500, loss = 1878.5055, recon_loss = 1876.8127, kl_loss = 1.6927\n",
      "Batch 550, loss = 28372.0254, recon_loss = 28370.3848, kl_loss = 1.6412\n",
      "Batch 600, loss = 38744200.0000, recon_loss = 38744196.0000, kl_loss = 3.0936\n",
      "Batch 650, loss = 390560569360384.0000, recon_loss = 390560569360384.0000, kl_loss = 3.4627\n",
      "Batch 700, loss = 5848164909187072.0000, recon_loss = 5848164909187072.0000, kl_loss = 4.1112\n",
      "Average loss: 36437516036736152.0000\n",
      "Epoch: 42\n",
      "Batch 50, loss = 6285.7544, recon_loss = 6281.9932, kl_loss = 3.7613\n",
      "Batch 100, loss = 990.3069, recon_loss = 988.6552, kl_loss = 1.6517\n",
      "Batch 150, loss = 185.1924, recon_loss = 184.2884, kl_loss = 0.9041\n",
      "Batch 200, loss = 303905.8750, recon_loss = 303904.8438, kl_loss = 1.0316\n",
      "Batch 250, loss = 325.9428, recon_loss = 324.9678, kl_loss = 0.9750\n",
      "Batch 300, loss = 553.7767, recon_loss = 552.2171, kl_loss = 1.5596\n",
      "Batch 350, loss = 711.0797, recon_loss = 710.0392, kl_loss = 1.0405\n",
      "Batch 400, loss = 1512.4989, recon_loss = 1509.2324, kl_loss = 3.2665\n",
      "Batch 450, loss = 196195.1562, recon_loss = 196191.1250, kl_loss = 4.0275\n",
      "Batch 500, loss = 1880.1024, recon_loss = 1878.3984, kl_loss = 1.7040\n",
      "Batch 550, loss = 28375.4824, recon_loss = 28373.7500, kl_loss = 1.7315\n",
      "Batch 600, loss = 38681284.0000, recon_loss = 38681280.0000, kl_loss = 3.4802\n",
      "Batch 650, loss = 390559495618560.0000, recon_loss = 390559495618560.0000, kl_loss = 3.4943\n",
      "Batch 700, loss = 5848164372316160.0000, recon_loss = 5848164372316160.0000, kl_loss = 4.1465\n",
      "Average loss: 36437515852112888.0000\n",
      "Epoch: 43\n",
      "Batch 50, loss = 6301.9727, recon_loss = 6298.1416, kl_loss = 3.8313\n",
      "Batch 100, loss = 1012.7955, recon_loss = 1011.2963, kl_loss = 1.4992\n",
      "Batch 150, loss = 184.4124, recon_loss = 183.5254, kl_loss = 0.8870\n",
      "Batch 200, loss = 303915.9688, recon_loss = 303914.9375, kl_loss = 1.0389\n",
      "Batch 250, loss = 324.9886, recon_loss = 324.0419, kl_loss = 0.9467\n",
      "Batch 300, loss = 513.6660, recon_loss = 511.9836, kl_loss = 1.6823\n",
      "Batch 350, loss = 710.3825, recon_loss = 709.2906, kl_loss = 1.0919\n",
      "Batch 400, loss = 1516.6315, recon_loss = 1513.4099, kl_loss = 3.2215\n",
      "Batch 450, loss = 204495.0000, recon_loss = 204490.8750, kl_loss = 4.1244\n",
      "Batch 500, loss = 1879.6206, recon_loss = 1877.8739, kl_loss = 1.7467\n",
      "Batch 550, loss = 28373.9785, recon_loss = 28372.1836, kl_loss = 1.7940\n",
      "Batch 600, loss = 38624524.0000, recon_loss = 38624520.0000, kl_loss = 3.6789\n",
      "Batch 650, loss = 390558321213440.0000, recon_loss = 390558321213440.0000, kl_loss = 3.4964\n",
      "Batch 700, loss = 5848162761703424.0000, recon_loss = 5848162761703424.0000, kl_loss = 4.1512\n",
      "Average loss: 36437515665065656.0000\n",
      "Epoch: 44\n",
      "Batch 50, loss = 6299.8608, recon_loss = 6295.9785, kl_loss = 3.8825\n",
      "Batch 100, loss = 1016.2451, recon_loss = 1014.6063, kl_loss = 1.6387\n",
      "Batch 150, loss = 180.7011, recon_loss = 179.7487, kl_loss = 0.9524\n",
      "Batch 200, loss = 303909.6875, recon_loss = 303908.6562, kl_loss = 1.0427\n",
      "Batch 250, loss = 317.1280, recon_loss = 316.1034, kl_loss = 1.0246\n",
      "Batch 300, loss = 574.6687, recon_loss = 572.9432, kl_loss = 1.7255\n",
      "Batch 350, loss = 711.6326, recon_loss = 710.5948, kl_loss = 1.0377\n",
      "Batch 400, loss = 1516.2852, recon_loss = 1512.9725, kl_loss = 3.3126\n",
      "Batch 450, loss = 196901.2812, recon_loss = 196897.3906, kl_loss = 3.8902\n",
      "Batch 500, loss = 1879.2240, recon_loss = 1877.4647, kl_loss = 1.7593\n",
      "Batch 550, loss = 28372.0918, recon_loss = 28370.3320, kl_loss = 1.7599\n",
      "Batch 600, loss = 38583084.0000, recon_loss = 38583080.0000, kl_loss = 3.7295\n",
      "Batch 650, loss = 390557213917184.0000, recon_loss = 390557213917184.0000, kl_loss = 3.5064\n",
      "Batch 700, loss = 5848161687961600.0000, recon_loss = 5848161687961600.0000, kl_loss = 4.1687\n",
      "Average loss: 36437515454312672.0000\n",
      "Epoch: 45\n",
      "Batch 50, loss = 6243.6577, recon_loss = 6239.7920, kl_loss = 3.8658\n",
      "Batch 100, loss = 1027.3859, recon_loss = 1025.6367, kl_loss = 1.7491\n",
      "Batch 150, loss = 180.8479, recon_loss = 179.8479, kl_loss = 1.0000\n",
      "Batch 200, loss = 303910.4062, recon_loss = 303909.3438, kl_loss = 1.0532\n",
      "Batch 250, loss = 314.8047, recon_loss = 313.6912, kl_loss = 1.1135\n",
      "Batch 300, loss = 565.9470, recon_loss = 564.1768, kl_loss = 1.7703\n",
      "Batch 350, loss = 711.3752, recon_loss = 710.3046, kl_loss = 1.0706\n",
      "Batch 400, loss = 1516.5602, recon_loss = 1513.3135, kl_loss = 3.2467\n",
      "Batch 450, loss = 196359.9219, recon_loss = 196355.8125, kl_loss = 4.1159\n",
      "Batch 500, loss = 1879.7179, recon_loss = 1877.9934, kl_loss = 1.7245\n",
      "Batch 550, loss = 28371.7383, recon_loss = 28369.9219, kl_loss = 1.8171\n",
      "Batch 600, loss = 38542212.0000, recon_loss = 38542208.0000, kl_loss = 3.6555\n",
      "Batch 650, loss = 390556073066496.0000, recon_loss = 390556073066496.0000, kl_loss = 3.5439\n",
      "Batch 700, loss = 5848161151090688.0000, recon_loss = 5848161151090688.0000, kl_loss = 4.2038\n",
      "Average loss: 36437515266207648.0000\n",
      "Epoch: 46\n",
      "Batch 50, loss = 6256.7871, recon_loss = 6253.1025, kl_loss = 3.6847\n",
      "Batch 100, loss = 982.6445, recon_loss = 980.9697, kl_loss = 1.6748\n",
      "Batch 150, loss = 179.0059, recon_loss = 178.0323, kl_loss = 0.9736\n",
      "Batch 200, loss = 303904.0625, recon_loss = 303903.0000, kl_loss = 1.0533\n",
      "Batch 250, loss = 318.3088, recon_loss = 317.2466, kl_loss = 1.0623\n",
      "Batch 300, loss = 549.6682, recon_loss = 547.9914, kl_loss = 1.6768\n",
      "Batch 350, loss = 709.8959, recon_loss = 708.7834, kl_loss = 1.1125\n",
      "Batch 400, loss = 1510.9423, recon_loss = 1507.6448, kl_loss = 3.2975\n",
      "Batch 450, loss = 196187.9531, recon_loss = 196184.0000, kl_loss = 3.9464\n",
      "Batch 500, loss = 1879.6621, recon_loss = 1877.8806, kl_loss = 1.7815\n",
      "Batch 550, loss = 28374.7676, recon_loss = 28373.0059, kl_loss = 1.7623\n",
      "Batch 600, loss = 38487316.0000, recon_loss = 38487312.0000, kl_loss = 3.4241\n",
      "Batch 650, loss = 390554999324672.0000, recon_loss = 390554999324672.0000, kl_loss = 3.5972\n",
      "Batch 700, loss = 5848159540477952.0000, recon_loss = 5848159540477952.0000, kl_loss = 4.2696\n",
      "Average loss: 36437512120043048.0000\n",
      "Epoch: 47\n",
      "Batch 50, loss = 6388.2603, recon_loss = 6384.8735, kl_loss = 3.3867\n",
      "Batch 100, loss = 976.1881, recon_loss = 974.3761, kl_loss = 1.8120\n",
      "Batch 150, loss = 181.6882, recon_loss = 180.4667, kl_loss = 1.2215\n",
      "Batch 200, loss = 303899.0000, recon_loss = 303897.9375, kl_loss = 1.0698\n",
      "Batch 250, loss = 314.3635, recon_loss = 313.2076, kl_loss = 1.1559\n",
      "Batch 300, loss = 560.6507, recon_loss = 558.8289, kl_loss = 1.8218\n",
      "Batch 350, loss = 707.9676, recon_loss = 706.8567, kl_loss = 1.1109\n",
      "Batch 400, loss = 1511.6960, recon_loss = 1508.4653, kl_loss = 3.2307\n",
      "Batch 450, loss = 195330.9219, recon_loss = 195327.0156, kl_loss = 3.9107\n",
      "Batch 500, loss = 1879.2760, recon_loss = 1877.5266, kl_loss = 1.7494\n",
      "Batch 550, loss = 28372.9844, recon_loss = 28371.1836, kl_loss = 1.8000\n",
      "Batch 600, loss = 38428636.0000, recon_loss = 38428632.0000, kl_loss = 3.4360\n",
      "Batch 650, loss = 390553858473984.0000, recon_loss = 390553858473984.0000, kl_loss = 3.5980\n",
      "Batch 700, loss = 5848158466736128.0000, recon_loss = 5848158466736128.0000, kl_loss = 4.2856\n",
      "Average loss: 36437511194879176.0000\n",
      "Epoch: 48\n",
      "Batch 50, loss = 6344.9966, recon_loss = 6341.2393, kl_loss = 3.7572\n",
      "Batch 100, loss = 999.6436, recon_loss = 997.8229, kl_loss = 1.8207\n",
      "Batch 150, loss = 179.4142, recon_loss = 178.2809, kl_loss = 1.1333\n",
      "Batch 200, loss = 303898.4062, recon_loss = 303897.2812, kl_loss = 1.1205\n",
      "Batch 250, loss = 313.2177, recon_loss = 312.0658, kl_loss = 1.1520\n",
      "Batch 300, loss = 566.6533, recon_loss = 564.8124, kl_loss = 1.8408\n",
      "Batch 350, loss = 708.4362, recon_loss = 707.2573, kl_loss = 1.1789\n",
      "Batch 400, loss = 1511.2828, recon_loss = 1508.1770, kl_loss = 3.1058\n",
      "Batch 450, loss = 194986.4375, recon_loss = 194982.3750, kl_loss = 4.0577\n",
      "Batch 500, loss = 1876.4050, recon_loss = 1874.6235, kl_loss = 1.7815\n",
      "Batch 550, loss = 28371.5879, recon_loss = 28369.8105, kl_loss = 1.7777\n",
      "Batch 600, loss = 38373876.0000, recon_loss = 38373872.0000, kl_loss = 3.5425\n",
      "Batch 650, loss = 390552751177728.0000, recon_loss = 390552751177728.0000, kl_loss = 3.6070\n",
      "Batch 700, loss = 5848157929865216.0000, recon_loss = 5848157929865216.0000, kl_loss = 4.2943\n",
      "Average loss: 36437511000661424.0000\n",
      "Epoch: 49\n",
      "Batch 50, loss = 6258.0093, recon_loss = 6254.3350, kl_loss = 3.6744\n",
      "Batch 100, loss = 998.0049, recon_loss = 996.1862, kl_loss = 1.8187\n",
      "Batch 150, loss = 174.0018, recon_loss = 172.8742, kl_loss = 1.1275\n",
      "Batch 200, loss = 303890.0938, recon_loss = 303888.9688, kl_loss = 1.1250\n",
      "Batch 250, loss = 311.5839, recon_loss = 310.4410, kl_loss = 1.1429\n",
      "Batch 300, loss = 547.1297, recon_loss = 545.2982, kl_loss = 1.8315\n",
      "Batch 350, loss = 707.4467, recon_loss = 706.2408, kl_loss = 1.2058\n",
      "Batch 400, loss = 1510.6934, recon_loss = 1507.5430, kl_loss = 3.1503\n",
      "Batch 450, loss = 195138.5469, recon_loss = 195134.2500, kl_loss = 4.2935\n",
      "Batch 500, loss = 1875.7062, recon_loss = 1873.9979, kl_loss = 1.7082\n",
      "Batch 550, loss = 28369.8398, recon_loss = 28368.1484, kl_loss = 1.6914\n",
      "Batch 600, loss = 38329252.0000, recon_loss = 38329248.0000, kl_loss = 3.7189\n",
      "Batch 650, loss = 390551677435904.0000, recon_loss = 390551677435904.0000, kl_loss = 3.6246\n",
      "Batch 700, loss = 5848156319252480.0000, recon_loss = 5848156319252480.0000, kl_loss = 4.3169\n",
      "Average loss: 36437510818482856.0000\n",
      "Epoch: 50\n",
      "Batch 50, loss = 6268.9609, recon_loss = 6265.5645, kl_loss = 3.3966\n",
      "Batch 100, loss = 1111.9728, recon_loss = 1110.1246, kl_loss = 1.8481\n",
      "Batch 150, loss = 176.3403, recon_loss = 175.1863, kl_loss = 1.1540\n",
      "Batch 200, loss = 303904.0000, recon_loss = 303902.8750, kl_loss = 1.1385\n",
      "Batch 250, loss = 312.1247, recon_loss = 310.9998, kl_loss = 1.1249\n",
      "Batch 300, loss = 562.3831, recon_loss = 560.5942, kl_loss = 1.7889\n",
      "Batch 350, loss = 707.3136, recon_loss = 706.1211, kl_loss = 1.1925\n",
      "Batch 400, loss = 1513.5742, recon_loss = 1510.3892, kl_loss = 3.1850\n",
      "Batch 450, loss = 197235.0469, recon_loss = 197230.9375, kl_loss = 4.1062\n",
      "Batch 500, loss = 1876.2133, recon_loss = 1874.5310, kl_loss = 1.6823\n",
      "Batch 550, loss = 28372.8086, recon_loss = 28371.1035, kl_loss = 1.7058\n",
      "Batch 600, loss = 38293604.0000, recon_loss = 38293600.0000, kl_loss = 3.4481\n",
      "Batch 650, loss = 390550570139648.0000, recon_loss = 390550570139648.0000, kl_loss = 3.6617\n",
      "Batch 700, loss = 5848155782381568.0000, recon_loss = 5848155782381568.0000, kl_loss = 4.3545\n",
      "Average loss: 36437510256663992.0000\n",
      "Epoch: 51\n",
      "Batch 50, loss = 6320.9473, recon_loss = 6317.5098, kl_loss = 3.4373\n",
      "Batch 100, loss = 995.0386, recon_loss = 993.2816, kl_loss = 1.7569\n",
      "Batch 150, loss = 326.8550, recon_loss = 325.3264, kl_loss = 1.5286\n",
      "Batch 200, loss = 303889.5312, recon_loss = 303888.3438, kl_loss = 1.1958\n",
      "Batch 250, loss = 311.3127, recon_loss = 310.1234, kl_loss = 1.1894\n",
      "Batch 300, loss = 506.7482, recon_loss = 504.9355, kl_loss = 1.8128\n",
      "Batch 350, loss = 706.0790, recon_loss = 704.8558, kl_loss = 1.2231\n",
      "Batch 400, loss = 1509.2894, recon_loss = 1506.1702, kl_loss = 3.1192\n",
      "Batch 450, loss = 197036.4531, recon_loss = 197032.3125, kl_loss = 4.1337\n",
      "Batch 500, loss = 1875.5105, recon_loss = 1873.7701, kl_loss = 1.7403\n",
      "Batch 550, loss = 28372.4336, recon_loss = 28370.6953, kl_loss = 1.7387\n",
      "Batch 600, loss = 38249644.0000, recon_loss = 38249640.0000, kl_loss = 3.7302\n",
      "Batch 650, loss = 390549429288960.0000, recon_loss = 390549429288960.0000, kl_loss = 3.6710\n",
      "Batch 700, loss = 5848154171768832.0000, recon_loss = 5848154171768832.0000, kl_loss = 4.3672\n",
      "Average loss: 36437510060853832.0000\n",
      "Epoch: 52\n",
      "Batch 50, loss = 6232.8760, recon_loss = 6229.4238, kl_loss = 3.4520\n",
      "Batch 100, loss = 960.5655, recon_loss = 958.6471, kl_loss = 1.9184\n",
      "Batch 150, loss = 195.5101, recon_loss = 194.4099, kl_loss = 1.1003\n",
      "Batch 200, loss = 303873.2188, recon_loss = 303872.0625, kl_loss = 1.1462\n",
      "Batch 250, loss = 309.8167, recon_loss = 308.6694, kl_loss = 1.1473\n",
      "Batch 300, loss = 538.9925, recon_loss = 537.2255, kl_loss = 1.7671\n",
      "Batch 350, loss = 708.4432, recon_loss = 707.1398, kl_loss = 1.3034\n",
      "Batch 400, loss = 1512.4471, recon_loss = 1509.3450, kl_loss = 3.1022\n",
      "Batch 450, loss = 194661.8281, recon_loss = 194657.5312, kl_loss = 4.2955\n",
      "Batch 500, loss = 1875.3881, recon_loss = 1873.6890, kl_loss = 1.6991\n",
      "Batch 550, loss = 28372.5957, recon_loss = 28370.8711, kl_loss = 1.7247\n",
      "Batch 600, loss = 38204060.0000, recon_loss = 38204056.0000, kl_loss = 3.4810\n",
      "Batch 650, loss = 390548288438272.0000, recon_loss = 390548288438272.0000, kl_loss = 3.6985\n",
      "Batch 700, loss = 5848152024285184.0000, recon_loss = 5848152024285184.0000, kl_loss = 4.3969\n",
      "Average loss: 36437509863115640.0000\n",
      "Epoch: 53\n",
      "Batch 50, loss = 6222.1572, recon_loss = 6218.8154, kl_loss = 3.3420\n",
      "Batch 100, loss = 972.4974, recon_loss = 970.5001, kl_loss = 1.9974\n",
      "Batch 150, loss = 170.0723, recon_loss = 168.8726, kl_loss = 1.1998\n",
      "Batch 200, loss = 303880.7500, recon_loss = 303879.5312, kl_loss = 1.2328\n",
      "Batch 250, loss = 305.0337, recon_loss = 303.7923, kl_loss = 1.2414\n",
      "Batch 300, loss = 591.2365, recon_loss = 589.3569, kl_loss = 1.8795\n",
      "Batch 350, loss = 707.4332, recon_loss = 706.2051, kl_loss = 1.2282\n",
      "Batch 400, loss = 1511.7615, recon_loss = 1508.7852, kl_loss = 2.9763\n",
      "Batch 450, loss = 195278.3906, recon_loss = 195274.3750, kl_loss = 4.0227\n",
      "Batch 500, loss = 1875.9258, recon_loss = 1874.2499, kl_loss = 1.6759\n",
      "Batch 550, loss = 28372.2949, recon_loss = 28370.6250, kl_loss = 1.6701\n",
      "Batch 600, loss = 38168324.0000, recon_loss = 38168320.0000, kl_loss = 3.6892\n",
      "Batch 650, loss = 390547181142016.0000, recon_loss = 390547181142016.0000, kl_loss = 3.7090\n",
      "Batch 700, loss = 5848152024285184.0000, recon_loss = 5848152024285184.0000, kl_loss = 4.4037\n",
      "Average loss: 36437509681377256.0000\n",
      "Epoch: 54\n",
      "Batch 50, loss = 6228.3315, recon_loss = 6224.9814, kl_loss = 3.3503\n",
      "Batch 100, loss = 933.1131, recon_loss = 931.1583, kl_loss = 1.9548\n",
      "Batch 150, loss = 177.1324, recon_loss = 175.9134, kl_loss = 1.2189\n",
      "Batch 200, loss = 303871.1875, recon_loss = 303870.0312, kl_loss = 1.1713\n",
      "Batch 250, loss = 311.1228, recon_loss = 309.9370, kl_loss = 1.1858\n",
      "Batch 300, loss = 545.6245, recon_loss = 543.7510, kl_loss = 1.8735\n",
      "Batch 350, loss = 708.4771, recon_loss = 707.1955, kl_loss = 1.2816\n",
      "Batch 400, loss = 1516.5901, recon_loss = 1513.5693, kl_loss = 3.0207\n",
      "Batch 450, loss = 195748.1562, recon_loss = 195744.1250, kl_loss = 4.0271\n",
      "Batch 500, loss = 1875.5442, recon_loss = 1873.8318, kl_loss = 1.7124\n",
      "Batch 550, loss = 28370.7871, recon_loss = 28369.0469, kl_loss = 1.7400\n",
      "Batch 600, loss = 38130732.0000, recon_loss = 38130728.0000, kl_loss = 3.2914\n",
      "Batch 650, loss = 390546107400192.0000, recon_loss = 390546107400192.0000, kl_loss = 3.7351\n",
      "Batch 700, loss = 5848150950543360.0000, recon_loss = 5848150950543360.0000, kl_loss = 4.4397\n",
      "Average loss: 36437509493147208.0000\n",
      "Epoch: 55\n",
      "Batch 50, loss = 6225.8057, recon_loss = 6222.5645, kl_loss = 3.2414\n",
      "Batch 100, loss = 910.5744, recon_loss = 908.7542, kl_loss = 1.8203\n",
      "Batch 150, loss = 178.7276, recon_loss = 177.6004, kl_loss = 1.1272\n",
      "Batch 200, loss = 303888.1875, recon_loss = 303886.9375, kl_loss = 1.2543\n",
      "Batch 250, loss = 302.6648, recon_loss = 301.4205, kl_loss = 1.2443\n",
      "Batch 300, loss = 449.2150, recon_loss = 447.3927, kl_loss = 1.8223\n",
      "Batch 350, loss = 706.5045, recon_loss = 705.2502, kl_loss = 1.2542\n",
      "Batch 400, loss = 1510.9158, recon_loss = 1507.8477, kl_loss = 3.0681\n",
      "Batch 450, loss = 194753.5000, recon_loss = 194749.3438, kl_loss = 4.1553\n",
      "Batch 500, loss = 1876.7610, recon_loss = 1875.1051, kl_loss = 1.6559\n",
      "Batch 550, loss = 28371.2949, recon_loss = 28369.5938, kl_loss = 1.7015\n",
      "Batch 600, loss = 38097288.0000, recon_loss = 38097284.0000, kl_loss = 3.3033\n",
      "Batch 650, loss = 390544966549504.0000, recon_loss = 390544966549504.0000, kl_loss = 3.7418\n",
      "Batch 700, loss = 5848149339930624.0000, recon_loss = 5848149339930624.0000, kl_loss = 4.4615\n",
      "Average loss: 36437509305018768.0000\n",
      "Epoch: 56\n",
      "Batch 50, loss = 6204.5552, recon_loss = 6201.1309, kl_loss = 3.4241\n",
      "Batch 100, loss = 994.1289, recon_loss = 992.1868, kl_loss = 1.9422\n",
      "Batch 150, loss = 176.4167, recon_loss = 175.3681, kl_loss = 1.0486\n",
      "Batch 200, loss = 303867.4375, recon_loss = 303866.2188, kl_loss = 1.2272\n",
      "Batch 250, loss = 304.2469, recon_loss = 302.9412, kl_loss = 1.3057\n",
      "Batch 300, loss = 467.7809, recon_loss = 466.0286, kl_loss = 1.7523\n",
      "Batch 350, loss = 706.9090, recon_loss = 705.6553, kl_loss = 1.2537\n",
      "Batch 400, loss = 1514.6427, recon_loss = 1511.5856, kl_loss = 3.0572\n",
      "Batch 450, loss = 192986.0156, recon_loss = 192981.7812, kl_loss = 4.2329\n",
      "Batch 500, loss = 1875.8287, recon_loss = 1874.0995, kl_loss = 1.7293\n",
      "Batch 550, loss = 28369.0801, recon_loss = 28367.3203, kl_loss = 1.7603\n",
      "Batch 600, loss = 38076820.0000, recon_loss = 38076816.0000, kl_loss = 3.1964\n",
      "Batch 650, loss = 390543859253248.0000, recon_loss = 390543859253248.0000, kl_loss = 3.7615\n",
      "Batch 700, loss = 5848148803059712.0000, recon_loss = 5848148803059712.0000, kl_loss = 4.4945\n",
      "Average loss: 36437508731087304.0000\n",
      "Epoch: 57\n",
      "Batch 50, loss = 6206.1973, recon_loss = 6202.8184, kl_loss = 3.3788\n",
      "Batch 100, loss = 1024.9500, recon_loss = 1022.9547, kl_loss = 1.9953\n",
      "Batch 150, loss = 182.4831, recon_loss = 181.3859, kl_loss = 1.0972\n",
      "Batch 200, loss = 303866.2500, recon_loss = 303865.0938, kl_loss = 1.1689\n",
      "Batch 250, loss = 302.0904, recon_loss = 300.7898, kl_loss = 1.3006\n",
      "Batch 300, loss = 569.6432, recon_loss = 567.7328, kl_loss = 1.9104\n",
      "Batch 350, loss = 706.9809, recon_loss = 705.6814, kl_loss = 1.2995\n",
      "Batch 400, loss = 1515.4156, recon_loss = 1512.6167, kl_loss = 2.7989\n",
      "Batch 450, loss = 199235.2188, recon_loss = 199231.1250, kl_loss = 4.0900\n",
      "Batch 500, loss = 1876.7742, recon_loss = 1875.0377, kl_loss = 1.7364\n",
      "Batch 550, loss = 28372.0449, recon_loss = 28370.2832, kl_loss = 1.7626\n",
      "Batch 600, loss = 38072044.0000, recon_loss = 38072040.0000, kl_loss = 2.8640\n",
      "Batch 650, loss = 390542718402560.0000, recon_loss = 390542718402560.0000, kl_loss = 3.7636\n",
      "Batch 700, loss = 5848147192446976.0000, recon_loss = 5848147192446976.0000, kl_loss = 4.5110\n",
      "Average loss: 36437508535276784.0000\n",
      "Epoch: 58\n",
      "Batch 50, loss = 6208.7759, recon_loss = 6205.3208, kl_loss = 3.4553\n",
      "Batch 100, loss = 971.3585, recon_loss = 969.4823, kl_loss = 1.8762\n",
      "Batch 150, loss = 170.0129, recon_loss = 168.8004, kl_loss = 1.2125\n",
      "Batch 200, loss = 303881.0938, recon_loss = 303879.9375, kl_loss = 1.1691\n",
      "Batch 250, loss = 304.3176, recon_loss = 303.0310, kl_loss = 1.2866\n",
      "Batch 300, loss = 545.3206, recon_loss = 543.4468, kl_loss = 1.8738\n",
      "Batch 350, loss = 709.3416, recon_loss = 708.0321, kl_loss = 1.3095\n",
      "Batch 400, loss = 1512.8967, recon_loss = 1510.0823, kl_loss = 2.8144\n",
      "Batch 450, loss = 193094.6250, recon_loss = 193090.4844, kl_loss = 4.1435\n",
      "Batch 500, loss = 1876.1528, recon_loss = 1874.3938, kl_loss = 1.7590\n",
      "Batch 550, loss = 28371.7363, recon_loss = 28369.9922, kl_loss = 1.7437\n",
      "Batch 600, loss = 38021836.0000, recon_loss = 38021832.0000, kl_loss = 3.0421\n",
      "Batch 650, loss = 390541611106304.0000, recon_loss = 390541611106304.0000, kl_loss = 3.7930\n",
      "Batch 700, loss = 5848145581834240.0000, recon_loss = 5848145581834240.0000, kl_loss = 4.5373\n",
      "Average loss: 36437508354968280.0000\n",
      "Epoch: 59\n",
      "Batch 50, loss = 45848.4961, recon_loss = 45845.1406, kl_loss = 3.3567\n",
      "Batch 100, loss = 997.0159, recon_loss = 995.1258, kl_loss = 1.8901\n",
      "Batch 150, loss = 167.8834, recon_loss = 166.6863, kl_loss = 1.1971\n",
      "Batch 200, loss = 303880.8750, recon_loss = 303879.6562, kl_loss = 1.2174\n",
      "Batch 250, loss = 299.1091, recon_loss = 297.8528, kl_loss = 1.2563\n",
      "Batch 300, loss = 501.5304, recon_loss = 499.6499, kl_loss = 1.8805\n",
      "Batch 350, loss = 708.0117, recon_loss = 706.6821, kl_loss = 1.3296\n",
      "Batch 400, loss = 1511.5938, recon_loss = 1508.7698, kl_loss = 2.8240\n",
      "Batch 450, loss = 192847.2344, recon_loss = 192843.1562, kl_loss = 4.0716\n",
      "Batch 500, loss = 1875.0625, recon_loss = 1873.3179, kl_loss = 1.7446\n",
      "Batch 550, loss = 28370.9043, recon_loss = 28369.1523, kl_loss = 1.7522\n",
      "Batch 600, loss = 37978380.0000, recon_loss = 37978376.0000, kl_loss = 2.7158\n",
      "Batch 650, loss = 390540537364480.0000, recon_loss = 390540537364480.0000, kl_loss = 3.8185\n",
      "Batch 700, loss = 5848145044963328.0000, recon_loss = 5848145044963328.0000, kl_loss = 4.5611\n",
      "Average loss: 36437504486903776.0000\n",
      "Epoch: 60\n",
      "Batch 50, loss = 6165.6138, recon_loss = 6162.1445, kl_loss = 3.4693\n",
      "Batch 100, loss = 940.5938, recon_loss = 938.6361, kl_loss = 1.9577\n",
      "Batch 150, loss = 187.3151, recon_loss = 186.0321, kl_loss = 1.2829\n",
      "Batch 200, loss = 303870.6562, recon_loss = 303869.4375, kl_loss = 1.2272\n",
      "Batch 250, loss = 303.4744, recon_loss = 302.2167, kl_loss = 1.2577\n",
      "Batch 300, loss = 643.5269, recon_loss = 641.5867, kl_loss = 1.9401\n",
      "Batch 350, loss = 707.4943, recon_loss = 706.1281, kl_loss = 1.3663\n",
      "Batch 400, loss = 1513.9999, recon_loss = 1511.1360, kl_loss = 2.8639\n",
      "Batch 450, loss = 192489.2969, recon_loss = 192485.0625, kl_loss = 4.2319\n",
      "Batch 500, loss = 1873.1771, recon_loss = 1871.4327, kl_loss = 1.7444\n",
      "Batch 550, loss = 28368.4102, recon_loss = 28366.6855, kl_loss = 1.7250\n",
      "Batch 600, loss = 37954960.0000, recon_loss = 37954956.0000, kl_loss = 2.6068\n",
      "Batch 650, loss = 390539396513792.0000, recon_loss = 390539396513792.0000, kl_loss = 3.8249\n",
      "Batch 700, loss = 5848143434350592.0000, recon_loss = 5848143434350592.0000, kl_loss = 4.5697\n",
      "Average loss: 36437504302057960.0000\n",
      "Epoch: 61\n",
      "Batch 50, loss = 6160.4482, recon_loss = 6157.0674, kl_loss = 3.3810\n",
      "Batch 100, loss = 973.6062, recon_loss = 971.5806, kl_loss = 2.0256\n",
      "Batch 150, loss = 168.1703, recon_loss = 166.8875, kl_loss = 1.2828\n",
      "Batch 200, loss = 303884.9375, recon_loss = 303883.6250, kl_loss = 1.3091\n",
      "Batch 250, loss = 301.7761, recon_loss = 300.4496, kl_loss = 1.3265\n",
      "Batch 300, loss = 499.5711, recon_loss = 497.6227, kl_loss = 1.9485\n",
      "Batch 350, loss = 709.2206, recon_loss = 707.9126, kl_loss = 1.3080\n",
      "Batch 400, loss = 1512.1549, recon_loss = 1509.3618, kl_loss = 2.7931\n",
      "Batch 450, loss = 194989.7031, recon_loss = 194985.3594, kl_loss = 4.3450\n",
      "Batch 500, loss = 1875.3917, recon_loss = 1873.6775, kl_loss = 1.7142\n",
      "Batch 550, loss = 28369.7812, recon_loss = 28368.1172, kl_loss = 1.6646\n",
      "Batch 600, loss = 37929560.0000, recon_loss = 37929556.0000, kl_loss = 2.5550\n",
      "Batch 650, loss = 390538289217536.0000, recon_loss = 390538289217536.0000, kl_loss = 3.8200\n",
      "Batch 700, loss = 5848142360608768.0000, recon_loss = 5848142360608768.0000, kl_loss = 4.5700\n",
      "Average loss: 36437504080509064.0000\n",
      "Epoch: 62\n",
      "Batch 50, loss = 6259.1519, recon_loss = 6255.6831, kl_loss = 3.4689\n",
      "Batch 100, loss = 930.2665, recon_loss = 928.2357, kl_loss = 2.0308\n",
      "Batch 150, loss = 194.6093, recon_loss = 193.3817, kl_loss = 1.2276\n",
      "Batch 200, loss = 303866.0625, recon_loss = 303864.7812, kl_loss = 1.2948\n",
      "Batch 250, loss = 300.4389, recon_loss = 299.1742, kl_loss = 1.2647\n",
      "Batch 300, loss = 556.2262, recon_loss = 554.1602, kl_loss = 2.0660\n",
      "Batch 350, loss = 706.8336, recon_loss = 705.5334, kl_loss = 1.3001\n",
      "Batch 400, loss = 1517.8424, recon_loss = 1515.1101, kl_loss = 2.7322\n",
      "Batch 450, loss = 193561.5938, recon_loss = 193557.1875, kl_loss = 4.4026\n",
      "Batch 500, loss = 1874.4728, recon_loss = 1872.7983, kl_loss = 1.6744\n",
      "Batch 550, loss = 28369.0957, recon_loss = 28367.3652, kl_loss = 1.7301\n",
      "Batch 600, loss = 37905372.0000, recon_loss = 37905368.0000, kl_loss = 3.3174\n",
      "Batch 650, loss = 390537148366848.0000, recon_loss = 390537148366848.0000, kl_loss = 3.8528\n",
      "Batch 700, loss = 5848142360608768.0000, recon_loss = 5848142360608768.0000, kl_loss = 4.6193\n",
      "Average loss: 36437503903310008.0000\n",
      "Epoch: 63\n",
      "Batch 50, loss = 6150.6162, recon_loss = 6147.1465, kl_loss = 3.4697\n",
      "Batch 100, loss = 891.7928, recon_loss = 889.7928, kl_loss = 2.0000\n",
      "Batch 150, loss = 174.6772, recon_loss = 173.4542, kl_loss = 1.2229\n",
      "Batch 200, loss = 303858.3125, recon_loss = 303857.0938, kl_loss = 1.2340\n",
      "Batch 250, loss = 296.2693, recon_loss = 294.9823, kl_loss = 1.2870\n",
      "Batch 300, loss = 582.4940, recon_loss = 580.4950, kl_loss = 1.9989\n",
      "Batch 350, loss = 713.4382, recon_loss = 712.0803, kl_loss = 1.3578\n",
      "Batch 400, loss = 1511.5957, recon_loss = 1508.8405, kl_loss = 2.7552\n",
      "Batch 450, loss = 197444.7031, recon_loss = 197440.6875, kl_loss = 4.0083\n",
      "Batch 500, loss = 1874.3367, recon_loss = 1872.6271, kl_loss = 1.7096\n",
      "Batch 550, loss = 28369.9277, recon_loss = 28368.2227, kl_loss = 1.7044\n",
      "Batch 600, loss = 37887884.0000, recon_loss = 37887880.0000, kl_loss = 2.7439\n",
      "Batch 650, loss = 390536074625024.0000, recon_loss = 390536074625024.0000, kl_loss = 3.8734\n",
      "Batch 700, loss = 5848140749996032.0000, recon_loss = 5848140749996032.0000, kl_loss = 4.6314\n",
      "Average loss: 36437500752531608.0000\n",
      "Epoch: 64\n",
      "Batch 50, loss = 6176.8066, recon_loss = 6173.3687, kl_loss = 3.4381\n",
      "Batch 100, loss = 900.1583, recon_loss = 898.1260, kl_loss = 2.0323\n",
      "Batch 150, loss = 189.4308, recon_loss = 188.2779, kl_loss = 1.1529\n",
      "Batch 200, loss = 303853.5000, recon_loss = 303852.1875, kl_loss = 1.3059\n",
      "Batch 250, loss = 296.5005, recon_loss = 295.1805, kl_loss = 1.3200\n",
      "Batch 300, loss = 596.1784, recon_loss = 594.0809, kl_loss = 2.0975\n",
      "Batch 350, loss = 707.8041, recon_loss = 706.4065, kl_loss = 1.3976\n",
      "Batch 400, loss = 1520.0255, recon_loss = 1517.1558, kl_loss = 2.8698\n",
      "Batch 450, loss = 192338.5625, recon_loss = 192334.2188, kl_loss = 4.3504\n",
      "Batch 500, loss = 1874.7203, recon_loss = 1872.9480, kl_loss = 1.7724\n",
      "Batch 550, loss = 28370.3027, recon_loss = 28368.5527, kl_loss = 1.7493\n",
      "Batch 600, loss = 37875308.0000, recon_loss = 37875304.0000, kl_loss = 2.7316\n",
      "Batch 650, loss = 390534933774336.0000, recon_loss = 390534933774336.0000, kl_loss = 3.8601\n",
      "Batch 700, loss = 5848139139383296.0000, recon_loss = 5848139139383296.0000, kl_loss = 4.6184\n",
      "Average loss: 36437500565777512.0000\n",
      "Epoch: 65\n",
      "Batch 50, loss = 6107.0801, recon_loss = 6103.5283, kl_loss = 3.5518\n",
      "Batch 100, loss = 914.6110, recon_loss = 912.5081, kl_loss = 2.1029\n",
      "Batch 150, loss = 164.0737, recon_loss = 162.7830, kl_loss = 1.2908\n",
      "Batch 200, loss = 303847.3125, recon_loss = 303845.9688, kl_loss = 1.3457\n",
      "Batch 250, loss = 301.6893, recon_loss = 300.3664, kl_loss = 1.3229\n",
      "Batch 300, loss = 531.0430, recon_loss = 529.0971, kl_loss = 1.9459\n",
      "Batch 350, loss = 705.6985, recon_loss = 704.3951, kl_loss = 1.3034\n",
      "Batch 400, loss = 1512.4401, recon_loss = 1509.5035, kl_loss = 2.9365\n",
      "Batch 450, loss = 192359.8594, recon_loss = 192355.6094, kl_loss = 4.2457\n",
      "Batch 500, loss = 1877.4495, recon_loss = 1875.7544, kl_loss = 1.6950\n",
      "Batch 550, loss = 28367.4570, recon_loss = 28365.7832, kl_loss = 1.6738\n",
      "Batch 600, loss = 37871148.0000, recon_loss = 37871144.0000, kl_loss = 2.9904\n",
      "Batch 650, loss = 390533860032512.0000, recon_loss = 390533860032512.0000, kl_loss = 3.8923\n",
      "Batch 700, loss = 5848138602512384.0000, recon_loss = 5848138602512384.0000, kl_loss = 4.6512\n",
      "Average loss: 36437500371201056.0000\n",
      "Epoch: 66\n",
      "Batch 50, loss = 6199.9941, recon_loss = 6196.5908, kl_loss = 3.4033\n",
      "Batch 100, loss = 884.2184, recon_loss = 882.1318, kl_loss = 2.0866\n",
      "Batch 150, loss = 169.7357, recon_loss = 168.6477, kl_loss = 1.0880\n",
      "Batch 200, loss = 303849.6875, recon_loss = 303848.4062, kl_loss = 1.2887\n",
      "Batch 250, loss = 295.5528, recon_loss = 294.1907, kl_loss = 1.3621\n",
      "Batch 300, loss = 573.2323, recon_loss = 571.2874, kl_loss = 1.9449\n",
      "Batch 350, loss = 707.7194, recon_loss = 706.3475, kl_loss = 1.3719\n",
      "Batch 400, loss = 1512.2477, recon_loss = 1509.4414, kl_loss = 2.8063\n",
      "Batch 450, loss = 191503.7500, recon_loss = 191499.6562, kl_loss = 4.0931\n",
      "Batch 500, loss = 1887.8710, recon_loss = 1886.2012, kl_loss = 1.6698\n",
      "Batch 550, loss = 28369.3691, recon_loss = 28367.7441, kl_loss = 1.6255\n",
      "Batch 600, loss = 37860748.0000, recon_loss = 37860744.0000, kl_loss = 3.1618\n",
      "Batch 650, loss = 390532719181824.0000, recon_loss = 390532719181824.0000, kl_loss = 3.8961\n",
      "Batch 700, loss = 5848136991899648.0000, recon_loss = 5848136991899648.0000, kl_loss = 4.6655\n",
      "Average loss: 36437500180746008.0000\n",
      "Epoch: 67\n",
      "Batch 50, loss = 6882.6011, recon_loss = 6879.1489, kl_loss = 3.4520\n",
      "Batch 100, loss = 916.6804, recon_loss = 914.5966, kl_loss = 2.0839\n",
      "Batch 150, loss = 161.6193, recon_loss = 160.3613, kl_loss = 1.2580\n",
      "Batch 200, loss = 303847.1562, recon_loss = 303845.7188, kl_loss = 1.4323\n",
      "Batch 250, loss = 294.6309, recon_loss = 293.3086, kl_loss = 1.3223\n",
      "Batch 300, loss = 569.3596, recon_loss = 567.3513, kl_loss = 2.0082\n",
      "Batch 350, loss = 708.4675, recon_loss = 707.0199, kl_loss = 1.4476\n",
      "Batch 400, loss = 1513.8505, recon_loss = 1510.9358, kl_loss = 2.9147\n",
      "Batch 450, loss = 192775.6719, recon_loss = 192771.5312, kl_loss = 4.1469\n",
      "Batch 500, loss = 1874.6536, recon_loss = 1873.0262, kl_loss = 1.6273\n",
      "Batch 550, loss = 28370.3652, recon_loss = 28368.7031, kl_loss = 1.6617\n",
      "Batch 600, loss = 37854236.0000, recon_loss = 37854232.0000, kl_loss = 2.4229\n",
      "Batch 650, loss = 390531511222272.0000, recon_loss = 390531511222272.0000, kl_loss = 3.9272\n",
      "Batch 700, loss = 5848135381286912.0000, recon_loss = 5848135381286912.0000, kl_loss = 4.6948\n",
      "Average loss: 36437499980503128.0000\n",
      "Epoch: 68\n",
      "Batch 50, loss = 6209.6187, recon_loss = 6206.1235, kl_loss = 3.4950\n",
      "Batch 100, loss = 802.2628, recon_loss = 800.0730, kl_loss = 2.1898\n",
      "Batch 150, loss = 157.7570, recon_loss = 156.4340, kl_loss = 1.3230\n",
      "Batch 200, loss = 303876.3125, recon_loss = 303874.8438, kl_loss = 1.4698\n",
      "Batch 250, loss = 298.4706, recon_loss = 297.0602, kl_loss = 1.4103\n",
      "Batch 300, loss = 583.3331, recon_loss = 581.3824, kl_loss = 1.9507\n",
      "Batch 350, loss = 713.1755, recon_loss = 711.7551, kl_loss = 1.4204\n",
      "Batch 400, loss = 1515.0884, recon_loss = 1512.0696, kl_loss = 3.0188\n",
      "Batch 450, loss = 191002.7969, recon_loss = 190998.6250, kl_loss = 4.1655\n",
      "Batch 500, loss = 1873.6334, recon_loss = 1871.9453, kl_loss = 1.6881\n",
      "Batch 550, loss = 28368.6387, recon_loss = 28366.9863, kl_loss = 1.6522\n",
      "Batch 600, loss = 37869184.0000, recon_loss = 37869180.0000, kl_loss = 3.5084\n",
      "Batch 650, loss = 390530403926016.0000, recon_loss = 390530403926016.0000, kl_loss = 3.9706\n",
      "Batch 700, loss = 5848134844416000.0000, recon_loss = 5848134844416000.0000, kl_loss = 4.7432\n",
      "Average loss: 36437499055664064.0000\n",
      "Epoch: 69\n",
      "Batch 50, loss = 6778.3398, recon_loss = 6774.9023, kl_loss = 3.4376\n",
      "Batch 100, loss = 817.6008, recon_loss = 815.3953, kl_loss = 2.2055\n",
      "Batch 150, loss = 194.7554, recon_loss = 193.4571, kl_loss = 1.2983\n",
      "Batch 200, loss = 303886.8750, recon_loss = 303885.5625, kl_loss = 1.3189\n",
      "Batch 250, loss = 295.0578, recon_loss = 293.6946, kl_loss = 1.3632\n",
      "Batch 300, loss = 482.7401, recon_loss = 480.7472, kl_loss = 1.9929\n",
      "Batch 350, loss = 706.8582, recon_loss = 705.4392, kl_loss = 1.4190\n",
      "Batch 400, loss = 1515.1483, recon_loss = 1512.2297, kl_loss = 2.9186\n",
      "Batch 450, loss = 190645.2500, recon_loss = 190640.9531, kl_loss = 4.2937\n",
      "Batch 500, loss = 1877.0708, recon_loss = 1875.4004, kl_loss = 1.6704\n",
      "Batch 550, loss = 28370.5820, recon_loss = 28368.9766, kl_loss = 1.6048\n",
      "Batch 600, loss = 37868380.0000, recon_loss = 37868376.0000, kl_loss = 2.7381\n",
      "Batch 650, loss = 390529263075328.0000, recon_loss = 390529263075328.0000, kl_loss = 3.9571\n",
      "Batch 700, loss = 5848133770674176.0000, recon_loss = 5848133770674176.0000, kl_loss = 4.7317\n",
      "Average loss: 36437498851586200.0000\n",
      "Epoch: 70\n",
      "Batch 50, loss = 6173.3652, recon_loss = 6169.8975, kl_loss = 3.4677\n",
      "Batch 100, loss = 926.5242, recon_loss = 924.4372, kl_loss = 2.0870\n",
      "Batch 150, loss = 160.4373, recon_loss = 159.1507, kl_loss = 1.2866\n",
      "Batch 200, loss = 303855.6875, recon_loss = 303854.2500, kl_loss = 1.4298\n",
      "Batch 250, loss = 297.1229, recon_loss = 295.7799, kl_loss = 1.3430\n",
      "Batch 300, loss = 546.8466, recon_loss = 544.8531, kl_loss = 1.9935\n",
      "Batch 350, loss = 705.8743, recon_loss = 704.4324, kl_loss = 1.4419\n",
      "Batch 400, loss = 1517.5759, recon_loss = 1514.6082, kl_loss = 2.9678\n",
      "Batch 450, loss = 190447.9531, recon_loss = 190443.7188, kl_loss = 4.2358\n",
      "Batch 500, loss = 1879.3168, recon_loss = 1877.6416, kl_loss = 1.6752\n",
      "Batch 550, loss = 28370.1953, recon_loss = 28368.5898, kl_loss = 1.6055\n",
      "Batch 600, loss = 37860876.0000, recon_loss = 37860872.0000, kl_loss = 2.6074\n",
      "Batch 650, loss = 390528155779072.0000, recon_loss = 390528155779072.0000, kl_loss = 3.9747\n",
      "Batch 700, loss = 5848132160061440.0000, recon_loss = 5848132160061440.0000, kl_loss = 4.7429\n",
      "Average loss: 36437498666745400.0000\n",
      "Epoch: 71\n",
      "Batch 50, loss = 6132.0879, recon_loss = 6128.7109, kl_loss = 3.3767\n",
      "Batch 100, loss = 856.3525, recon_loss = 854.1432, kl_loss = 2.2093\n",
      "Batch 150, loss = 157.4342, recon_loss = 156.1309, kl_loss = 1.3033\n",
      "Batch 200, loss = 303903.5000, recon_loss = 303902.1250, kl_loss = 1.3875\n",
      "Batch 250, loss = 302.1894, recon_loss = 300.7668, kl_loss = 1.4227\n",
      "Batch 300, loss = 499.6405, recon_loss = 497.5945, kl_loss = 2.0460\n",
      "Batch 350, loss = 707.3624, recon_loss = 705.9297, kl_loss = 1.4327\n",
      "Batch 400, loss = 1508.4771, recon_loss = 1505.4731, kl_loss = 3.0039\n",
      "Batch 450, loss = 190548.6250, recon_loss = 190544.3750, kl_loss = 4.2514\n",
      "Batch 500, loss = 1874.1434, recon_loss = 1872.5027, kl_loss = 1.6407\n",
      "Batch 550, loss = 28370.4082, recon_loss = 28368.8711, kl_loss = 1.5379\n",
      "Batch 600, loss = 37856836.0000, recon_loss = 37856832.0000, kl_loss = 3.2479\n",
      "Batch 650, loss = 390526947819520.0000, recon_loss = 390526947819520.0000, kl_loss = 3.9775\n",
      "Batch 700, loss = 5848132160061440.0000, recon_loss = 5848132160061440.0000, kl_loss = 4.7459\n",
      "Average loss: 36437497734981208.0000\n",
      "Epoch: 72\n",
      "Batch 50, loss = 6177.2500, recon_loss = 6173.8145, kl_loss = 3.4357\n",
      "Batch 100, loss = 878.2401, recon_loss = 876.0050, kl_loss = 2.2351\n",
      "Batch 150, loss = 159.1800, recon_loss = 157.7930, kl_loss = 1.3870\n",
      "Batch 200, loss = 303875.8438, recon_loss = 303874.3750, kl_loss = 1.4576\n",
      "Batch 250, loss = 294.7503, recon_loss = 293.3283, kl_loss = 1.4220\n",
      "Batch 300, loss = 552.5290, recon_loss = 550.5076, kl_loss = 2.0214\n",
      "Batch 350, loss = 712.0671, recon_loss = 710.6646, kl_loss = 1.4026\n",
      "Batch 400, loss = 1517.7196, recon_loss = 1514.7711, kl_loss = 2.9485\n",
      "Batch 450, loss = 192104.1406, recon_loss = 192099.7656, kl_loss = 4.3716\n",
      "Batch 500, loss = 1874.9525, recon_loss = 1873.3458, kl_loss = 1.6067\n",
      "Batch 550, loss = 28368.1191, recon_loss = 28366.6641, kl_loss = 1.4545\n",
      "Batch 600, loss = 37850236.0000, recon_loss = 37850232.0000, kl_loss = 3.5663\n",
      "Batch 650, loss = 390525806968832.0000, recon_loss = 390525806968832.0000, kl_loss = 4.0228\n",
      "Batch 700, loss = 5848130549448704.0000, recon_loss = 5848130549448704.0000, kl_loss = 4.7987\n",
      "Average loss: 36437497543335576.0000\n",
      "Epoch: 73\n",
      "Batch 50, loss = 6167.5220, recon_loss = 6164.0605, kl_loss = 3.4616\n",
      "Batch 100, loss = 852.2317, recon_loss = 849.9845, kl_loss = 2.2472\n",
      "Batch 150, loss = 156.1012, recon_loss = 154.7919, kl_loss = 1.3092\n",
      "Batch 200, loss = 303859.4688, recon_loss = 303858.0625, kl_loss = 1.4181\n",
      "Batch 250, loss = 302.4932, recon_loss = 301.0874, kl_loss = 1.4058\n",
      "Batch 300, loss = 474.8084, recon_loss = 472.7875, kl_loss = 2.0209\n",
      "Batch 350, loss = 710.6722, recon_loss = 709.1780, kl_loss = 1.4943\n",
      "Batch 400, loss = 1517.9670, recon_loss = 1514.9572, kl_loss = 3.0099\n",
      "Batch 450, loss = 191070.7656, recon_loss = 191066.4062, kl_loss = 4.3526\n",
      "Batch 500, loss = 1875.7621, recon_loss = 1874.1562, kl_loss = 1.6058\n",
      "Batch 550, loss = 28370.8984, recon_loss = 28369.3398, kl_loss = 1.5577\n",
      "Batch 600, loss = 37859112.0000, recon_loss = 37859108.0000, kl_loss = 3.6921\n",
      "Batch 650, loss = 390524699672576.0000, recon_loss = 390524699672576.0000, kl_loss = 4.0130\n",
      "Batch 700, loss = 5848128938835968.0000, recon_loss = 5848128938835968.0000, kl_loss = 4.7883\n",
      "Average loss: 36437497325514248.0000\n",
      "Epoch: 74\n",
      "Batch 50, loss = 6262.8535, recon_loss = 6259.6055, kl_loss = 3.2479\n",
      "Batch 100, loss = 782.0225, recon_loss = 779.6865, kl_loss = 2.3359\n",
      "Batch 150, loss = 158.5702, recon_loss = 157.1710, kl_loss = 1.3992\n",
      "Batch 200, loss = 303881.5625, recon_loss = 303879.9375, kl_loss = 1.6108\n",
      "Batch 250, loss = 299.5596, recon_loss = 298.0595, kl_loss = 1.5001\n",
      "Batch 300, loss = 526.2078, recon_loss = 524.1600, kl_loss = 2.0477\n",
      "Batch 350, loss = 703.7171, recon_loss = 702.2809, kl_loss = 1.4362\n",
      "Batch 400, loss = 1514.7825, recon_loss = 1511.9089, kl_loss = 2.8735\n",
      "Batch 450, loss = 191306.2656, recon_loss = 191301.9219, kl_loss = 4.3416\n",
      "Batch 500, loss = 1879.0880, recon_loss = 1877.3774, kl_loss = 1.7106\n",
      "Batch 550, loss = 28366.9121, recon_loss = 28365.3496, kl_loss = 1.5618\n",
      "Batch 600, loss = 37822740.0000, recon_loss = 37822736.0000, kl_loss = 3.5408\n",
      "Batch 650, loss = 390523592376320.0000, recon_loss = 390523592376320.0000, kl_loss = 4.0346\n",
      "Batch 700, loss = 5848127865094144.0000, recon_loss = 5848127865094144.0000, kl_loss = 4.8136\n",
      "Average loss: 36437497138446328.0000\n",
      "Epoch: 75\n",
      "Batch 50, loss = 6184.6719, recon_loss = 6181.2393, kl_loss = 3.4326\n",
      "Batch 100, loss = 847.0556, recon_loss = 844.8082, kl_loss = 2.2474\n",
      "Batch 150, loss = 160.4272, recon_loss = 159.0351, kl_loss = 1.3921\n",
      "Batch 200, loss = 303902.8125, recon_loss = 303901.3125, kl_loss = 1.4972\n",
      "Batch 250, loss = 306.9416, recon_loss = 305.4786, kl_loss = 1.4630\n",
      "Batch 300, loss = 556.2641, recon_loss = 554.1609, kl_loss = 2.1032\n",
      "Batch 350, loss = 711.8287, recon_loss = 710.4008, kl_loss = 1.4279\n",
      "Batch 400, loss = 1516.8810, recon_loss = 1514.0546, kl_loss = 2.8264\n",
      "Batch 450, loss = 189972.2812, recon_loss = 189967.8906, kl_loss = 4.3906\n",
      "Batch 500, loss = 1894.3441, recon_loss = 1892.6664, kl_loss = 1.6778\n",
      "Batch 550, loss = 28366.6855, recon_loss = 28365.1543, kl_loss = 1.5307\n",
      "Batch 600, loss = 37799308.0000, recon_loss = 37799304.0000, kl_loss = 3.5773\n",
      "Batch 650, loss = 390522384416768.0000, recon_loss = 390522384416768.0000, kl_loss = 4.0805\n",
      "Batch 700, loss = 5848126791352320.0000, recon_loss = 5848126791352320.0000, kl_loss = 4.8633\n",
      "Average loss: 36437496946830416.0000\n",
      "Epoch: 76\n",
      "Batch 50, loss = 6214.5640, recon_loss = 6211.1353, kl_loss = 3.4285\n",
      "Batch 100, loss = 720.7838, recon_loss = 718.4799, kl_loss = 2.3039\n",
      "Batch 150, loss = 160.8095, recon_loss = 159.4778, kl_loss = 1.3317\n",
      "Batch 200, loss = 303864.2500, recon_loss = 303862.7188, kl_loss = 1.5246\n",
      "Batch 250, loss = 293.2803, recon_loss = 291.8572, kl_loss = 1.4231\n",
      "Batch 300, loss = 552.6293, recon_loss = 550.5010, kl_loss = 2.1283\n",
      "Batch 350, loss = 705.7850, recon_loss = 704.3370, kl_loss = 1.4481\n",
      "Batch 400, loss = 1511.9434, recon_loss = 1509.0150, kl_loss = 2.9283\n",
      "Batch 450, loss = 190382.4062, recon_loss = 190378.0156, kl_loss = 4.3874\n",
      "Batch 500, loss = 1877.1144, recon_loss = 1875.4679, kl_loss = 1.6465\n",
      "Batch 550, loss = 28368.4395, recon_loss = 28366.9570, kl_loss = 1.4829\n",
      "Batch 600, loss = 37832716.0000, recon_loss = 37832712.0000, kl_loss = 3.7939\n",
      "Batch 650, loss = 390521310674944.0000, recon_loss = 390521310674944.0000, kl_loss = 4.0660\n",
      "Batch 700, loss = 5848125180739584.0000, recon_loss = 5848125180739584.0000, kl_loss = 4.8529\n",
      "Average loss: 36437496754948368.0000\n",
      "Epoch: 77\n",
      "Batch 50, loss = 9335.9941, recon_loss = 9332.6982, kl_loss = 3.2958\n",
      "Batch 100, loss = 759.5828, recon_loss = 757.2708, kl_loss = 2.3121\n",
      "Batch 150, loss = 159.8752, recon_loss = 158.5012, kl_loss = 1.3740\n",
      "Batch 200, loss = 303861.5000, recon_loss = 303859.9062, kl_loss = 1.5890\n",
      "Batch 250, loss = 303.9106, recon_loss = 302.4223, kl_loss = 1.4882\n",
      "Batch 300, loss = 538.8914, recon_loss = 536.6915, kl_loss = 2.1999\n",
      "Batch 350, loss = 706.9858, recon_loss = 705.5627, kl_loss = 1.4231\n",
      "Batch 400, loss = 1515.1610, recon_loss = 1512.2638, kl_loss = 2.8973\n",
      "Batch 450, loss = 189106.5156, recon_loss = 189102.1562, kl_loss = 4.3585\n",
      "Batch 500, loss = 1873.5918, recon_loss = 1871.9769, kl_loss = 1.6149\n",
      "Batch 550, loss = 28370.3086, recon_loss = 28368.8379, kl_loss = 1.4714\n",
      "Batch 600, loss = 37781948.0000, recon_loss = 37781944.0000, kl_loss = 2.8142\n",
      "Batch 650, loss = 390520169824256.0000, recon_loss = 390520169824256.0000, kl_loss = 4.0669\n",
      "Batch 700, loss = 5848125180739584.0000, recon_loss = 5848125180739584.0000, kl_loss = 4.8582\n",
      "Average loss: 36437496552233784.0000\n",
      "Epoch: 78\n",
      "Batch 50, loss = 6244.1465, recon_loss = 6240.7725, kl_loss = 3.3741\n",
      "Batch 100, loss = 728.3408, recon_loss = 725.9491, kl_loss = 2.3917\n",
      "Batch 150, loss = 196.2237, recon_loss = 194.8494, kl_loss = 1.3744\n",
      "Batch 200, loss = 303863.2500, recon_loss = 303861.6875, kl_loss = 1.5707\n",
      "Batch 250, loss = 294.8223, recon_loss = 293.4277, kl_loss = 1.3947\n",
      "Batch 300, loss = 430.3698, recon_loss = 428.3268, kl_loss = 2.0430\n",
      "Batch 350, loss = 709.6635, recon_loss = 708.2294, kl_loss = 1.4341\n",
      "Batch 400, loss = 1511.4207, recon_loss = 1508.6116, kl_loss = 2.8090\n",
      "Batch 450, loss = 191007.5312, recon_loss = 191002.7812, kl_loss = 4.7486\n",
      "Batch 500, loss = 1874.3602, recon_loss = 1872.8240, kl_loss = 1.5362\n",
      "Batch 550, loss = 28369.9844, recon_loss = 28368.4863, kl_loss = 1.4974\n",
      "Batch 600, loss = 37745548.0000, recon_loss = 37745544.0000, kl_loss = 2.9253\n",
      "Batch 650, loss = 390519028973568.0000, recon_loss = 390519028973568.0000, kl_loss = 4.0677\n",
      "Batch 700, loss = 5848123570126848.0000, recon_loss = 5848123570126848.0000, kl_loss = 4.8567\n",
      "Average loss: 36437496357592680.0000\n",
      "Epoch: 79\n",
      "Batch 50, loss = 6325.2974, recon_loss = 6322.0513, kl_loss = 3.2462\n",
      "Batch 100, loss = 919.4548, recon_loss = 917.0931, kl_loss = 2.3617\n",
      "Batch 150, loss = 200.1125, recon_loss = 198.9353, kl_loss = 1.1772\n",
      "Batch 200, loss = 303862.1250, recon_loss = 303860.6250, kl_loss = 1.4849\n",
      "Batch 250, loss = 300.0053, recon_loss = 298.5209, kl_loss = 1.4845\n",
      "Batch 300, loss = 470.3032, recon_loss = 468.1356, kl_loss = 2.1676\n",
      "Batch 350, loss = 708.8655, recon_loss = 707.4435, kl_loss = 1.4220\n",
      "Batch 400, loss = 1508.2385, recon_loss = 1505.3545, kl_loss = 2.8840\n",
      "Batch 450, loss = 188483.5625, recon_loss = 188479.0312, kl_loss = 4.5352\n",
      "Batch 500, loss = 1875.4967, recon_loss = 1873.9452, kl_loss = 1.5515\n",
      "Batch 550, loss = 28368.9453, recon_loss = 28367.4863, kl_loss = 1.4583\n",
      "Batch 600, loss = 37677896.0000, recon_loss = 37677892.0000, kl_loss = 2.9186\n",
      "Batch 650, loss = 390517888122880.0000, recon_loss = 390517888122880.0000, kl_loss = 4.0986\n",
      "Batch 700, loss = 5848123570126848.0000, recon_loss = 5848123570126848.0000, kl_loss = 4.8941\n",
      "Average loss: 36437490260268872.0000\n",
      "Epoch: 80\n",
      "Batch 50, loss = 6339.9087, recon_loss = 6336.5859, kl_loss = 3.3229\n",
      "Batch 100, loss = 721.9195, recon_loss = 719.5193, kl_loss = 2.4001\n",
      "Batch 150, loss = 161.2358, recon_loss = 159.8383, kl_loss = 1.3974\n",
      "Batch 200, loss = 303855.2812, recon_loss = 303853.8125, kl_loss = 1.4803\n",
      "Batch 250, loss = 293.2920, recon_loss = 291.8694, kl_loss = 1.4226\n",
      "Batch 300, loss = 578.1990, recon_loss = 576.0257, kl_loss = 2.1733\n",
      "Batch 350, loss = 708.8912, recon_loss = 707.5307, kl_loss = 1.3605\n",
      "Batch 400, loss = 1533.8517, recon_loss = 1530.9824, kl_loss = 2.8693\n",
      "Batch 450, loss = 187798.7500, recon_loss = 187794.3125, kl_loss = 4.4422\n",
      "Batch 500, loss = 1878.3121, recon_loss = 1876.7777, kl_loss = 1.5345\n",
      "Batch 550, loss = 28369.1738, recon_loss = 28367.7070, kl_loss = 1.4673\n",
      "Batch 600, loss = 37628512.0000, recon_loss = 37628508.0000, kl_loss = 3.0569\n",
      "Batch 650, loss = 390516747272192.0000, recon_loss = 390516747272192.0000, kl_loss = 4.1357\n",
      "Batch 700, loss = 5848121959514112.0000, recon_loss = 5848121959514112.0000, kl_loss = 4.9297\n",
      "Average loss: 36437490057597944.0000\n",
      "Epoch: 81\n",
      "Batch 50, loss = 6346.1973, recon_loss = 6342.7793, kl_loss = 3.4179\n",
      "Batch 100, loss = 732.6548, recon_loss = 730.2996, kl_loss = 2.3551\n",
      "Batch 150, loss = 157.5976, recon_loss = 156.3066, kl_loss = 1.2909\n",
      "Batch 200, loss = 303863.7188, recon_loss = 303862.2188, kl_loss = 1.4912\n",
      "Batch 250, loss = 297.7310, recon_loss = 296.3466, kl_loss = 1.3843\n",
      "Batch 300, loss = 540.2134, recon_loss = 538.0841, kl_loss = 2.1293\n",
      "Batch 350, loss = 706.7503, recon_loss = 705.3099, kl_loss = 1.4404\n",
      "Batch 400, loss = 1511.1522, recon_loss = 1508.3295, kl_loss = 2.8227\n",
      "Batch 450, loss = 187960.7656, recon_loss = 187956.1562, kl_loss = 4.6054\n",
      "Batch 500, loss = 1876.1643, recon_loss = 1874.5720, kl_loss = 1.5923\n",
      "Batch 550, loss = 28368.4062, recon_loss = 28366.8945, kl_loss = 1.5117\n",
      "Batch 600, loss = 37597868.0000, recon_loss = 37597864.0000, kl_loss = 3.2731\n",
      "Batch 650, loss = 390515673530368.0000, recon_loss = 390515673530368.0000, kl_loss = 4.1330\n",
      "Batch 700, loss = 5848120348901376.0000, recon_loss = 5848120348901376.0000, kl_loss = 4.9341\n",
      "Average loss: 36437489862642272.0000\n",
      "Epoch: 82\n",
      "Batch 50, loss = 6307.9722, recon_loss = 6304.5103, kl_loss = 3.4621\n",
      "Batch 100, loss = 805.7289, recon_loss = 803.3420, kl_loss = 2.3869\n",
      "Batch 150, loss = 191.0850, recon_loss = 189.6649, kl_loss = 1.4201\n",
      "Batch 200, loss = 303871.3750, recon_loss = 303869.7812, kl_loss = 1.5811\n",
      "Batch 250, loss = 291.3196, recon_loss = 289.8658, kl_loss = 1.4538\n",
      "Batch 300, loss = 417.7660, recon_loss = 415.6319, kl_loss = 2.1341\n",
      "Batch 350, loss = 707.2136, recon_loss = 705.7662, kl_loss = 1.4474\n",
      "Batch 400, loss = 1514.7771, recon_loss = 1511.9972, kl_loss = 2.7799\n",
      "Batch 450, loss = 188394.7500, recon_loss = 188389.8594, kl_loss = 4.8856\n",
      "Batch 500, loss = 1876.0750, recon_loss = 1874.5236, kl_loss = 1.5514\n",
      "Batch 550, loss = 28367.9434, recon_loss = 28366.4082, kl_loss = 1.5350\n",
      "Batch 600, loss = 37584320.0000, recon_loss = 37584316.0000, kl_loss = 3.2683\n",
      "Batch 650, loss = 390514465570816.0000, recon_loss = 390514465570816.0000, kl_loss = 4.1626\n",
      "Batch 700, loss = 5848119275159552.0000, recon_loss = 5848119275159552.0000, kl_loss = 4.9750\n",
      "Average loss: 36437489673673056.0000\n",
      "Epoch: 83\n",
      "Batch 50, loss = 6414.3525, recon_loss = 6410.8774, kl_loss = 3.4749\n",
      "Batch 100, loss = 742.0656, recon_loss = 739.7017, kl_loss = 2.3639\n",
      "Batch 150, loss = 152.9400, recon_loss = 151.4784, kl_loss = 1.4616\n",
      "Batch 200, loss = 303858.6875, recon_loss = 303857.0938, kl_loss = 1.6005\n",
      "Batch 250, loss = 292.2757, recon_loss = 290.7496, kl_loss = 1.5261\n",
      "Batch 300, loss = 549.4271, recon_loss = 547.1173, kl_loss = 2.3098\n",
      "Batch 350, loss = 708.1184, recon_loss = 706.6071, kl_loss = 1.5113\n",
      "Batch 400, loss = 1514.2758, recon_loss = 1511.4722, kl_loss = 2.8036\n",
      "Batch 450, loss = 192462.7812, recon_loss = 192457.9062, kl_loss = 4.8711\n",
      "Batch 500, loss = 1875.5387, recon_loss = 1873.9117, kl_loss = 1.6270\n",
      "Batch 550, loss = 28368.0273, recon_loss = 28366.4355, kl_loss = 1.5913\n",
      "Batch 600, loss = 37548144.0000, recon_loss = 37548140.0000, kl_loss = 3.2263\n",
      "Batch 650, loss = 390513358274560.0000, recon_loss = 390513358274560.0000, kl_loss = 4.1726\n",
      "Batch 700, loss = 5848117664546816.0000, recon_loss = 5848117664546816.0000, kl_loss = 4.9759\n",
      "Average loss: 36437489485769104.0000\n",
      "Epoch: 84\n",
      "Batch 50, loss = 6349.2339, recon_loss = 6345.8643, kl_loss = 3.3696\n",
      "Batch 100, loss = 808.9489, recon_loss = 806.4076, kl_loss = 2.5413\n",
      "Batch 150, loss = 152.0741, recon_loss = 150.6202, kl_loss = 1.4539\n",
      "Batch 200, loss = 303841.3438, recon_loss = 303839.5938, kl_loss = 1.7511\n",
      "Batch 250, loss = 293.1556, recon_loss = 291.6494, kl_loss = 1.5063\n",
      "Batch 300, loss = 624.8602, recon_loss = 622.4346, kl_loss = 2.4256\n",
      "Batch 350, loss = 705.8758, recon_loss = 704.3914, kl_loss = 1.4844\n",
      "Batch 400, loss = 1512.1876, recon_loss = 1509.3301, kl_loss = 2.8575\n",
      "Batch 450, loss = 191041.6562, recon_loss = 191036.9531, kl_loss = 4.6994\n",
      "Batch 500, loss = 1876.5526, recon_loss = 1874.8956, kl_loss = 1.6570\n",
      "Batch 550, loss = 28369.5918, recon_loss = 28368.0098, kl_loss = 1.5821\n",
      "Batch 600, loss = 37542748.0000, recon_loss = 37542744.0000, kl_loss = 2.9794\n",
      "Batch 650, loss = 390512217423872.0000, recon_loss = 390512217423872.0000, kl_loss = 4.1697\n",
      "Batch 700, loss = 5848116053934080.0000, recon_loss = 5848116053934080.0000, kl_loss = 4.9738\n",
      "Average loss: 36437488543583240.0000\n",
      "Epoch: 85\n",
      "Batch 50, loss = 6376.6182, recon_loss = 6373.1572, kl_loss = 3.4611\n",
      "Batch 100, loss = 726.9327, recon_loss = 724.4047, kl_loss = 2.5280\n",
      "Batch 150, loss = 158.3640, recon_loss = 156.9003, kl_loss = 1.4637\n",
      "Batch 200, loss = 303838.8125, recon_loss = 303837.1250, kl_loss = 1.6933\n",
      "Batch 250, loss = 288.5481, recon_loss = 287.0176, kl_loss = 1.5305\n",
      "Batch 300, loss = 387.2043, recon_loss = 385.0010, kl_loss = 2.2033\n",
      "Batch 350, loss = 706.6358, recon_loss = 705.1724, kl_loss = 1.4634\n",
      "Batch 400, loss = 1507.6382, recon_loss = 1504.9451, kl_loss = 2.6931\n",
      "Batch 450, loss = 187984.5469, recon_loss = 187980.0312, kl_loss = 4.5175\n",
      "Batch 500, loss = 1877.1364, recon_loss = 1875.5076, kl_loss = 1.6288\n",
      "Batch 550, loss = 28371.8906, recon_loss = 28370.3145, kl_loss = 1.5766\n",
      "Batch 600, loss = 37455252.0000, recon_loss = 37455248.0000, kl_loss = 3.2532\n",
      "Batch 650, loss = 390511110127616.0000, recon_loss = 390511110127616.0000, kl_loss = 4.2223\n",
      "Batch 700, loss = 5848116053934080.0000, recon_loss = 5848116053934080.0000, kl_loss = 5.0316\n",
      "Average loss: 36437488363189944.0000\n",
      "Epoch: 86\n",
      "Batch 50, loss = 6389.9165, recon_loss = 6386.5654, kl_loss = 3.3512\n",
      "Batch 100, loss = 716.7724, recon_loss = 714.2764, kl_loss = 2.4961\n",
      "Batch 150, loss = 154.1091, recon_loss = 152.5910, kl_loss = 1.5181\n",
      "Batch 200, loss = 303843.3125, recon_loss = 303841.4688, kl_loss = 1.8409\n",
      "Batch 250, loss = 294.6913, recon_loss = 293.1668, kl_loss = 1.5245\n",
      "Batch 300, loss = 461.0222, recon_loss = 458.7334, kl_loss = 2.2889\n",
      "Batch 350, loss = 704.9193, recon_loss = 703.4613, kl_loss = 1.4580\n",
      "Batch 400, loss = 1509.3943, recon_loss = 1506.6528, kl_loss = 2.7414\n",
      "Batch 450, loss = 189483.9531, recon_loss = 189479.3125, kl_loss = 4.6344\n",
      "Batch 500, loss = 1877.8855, recon_loss = 1876.2126, kl_loss = 1.6729\n",
      "Batch 550, loss = 28367.3945, recon_loss = 28365.8164, kl_loss = 1.5778\n",
      "Batch 600, loss = 37424276.0000, recon_loss = 37424272.0000, kl_loss = 3.1255\n",
      "Batch 650, loss = 390509969276928.0000, recon_loss = 390509969276928.0000, kl_loss = 4.2116\n",
      "Batch 700, loss = 5848114443321344.0000, recon_loss = 5848114443321344.0000, kl_loss = 5.0974\n",
      "Average loss: 36437488168479208.0000\n",
      "Epoch: 87\n",
      "Batch 50, loss = 6563.3467, recon_loss = 6559.9033, kl_loss = 3.4435\n",
      "Batch 100, loss = 799.7469, recon_loss = 797.2222, kl_loss = 2.5247\n",
      "Batch 150, loss = 188.4554, recon_loss = 187.0453, kl_loss = 1.4102\n",
      "Batch 200, loss = 303853.1562, recon_loss = 303851.5312, kl_loss = 1.6329\n",
      "Batch 250, loss = 287.0518, recon_loss = 285.5895, kl_loss = 1.4623\n",
      "Batch 300, loss = 556.4753, recon_loss = 554.1018, kl_loss = 2.3735\n",
      "Batch 350, loss = 709.7233, recon_loss = 708.3098, kl_loss = 1.4135\n",
      "Batch 400, loss = 1510.2592, recon_loss = 1507.5593, kl_loss = 2.6999\n",
      "Batch 450, loss = 188779.7656, recon_loss = 188775.1562, kl_loss = 4.6133\n",
      "Batch 500, loss = 1880.3110, recon_loss = 1878.6489, kl_loss = 1.6621\n",
      "Batch 550, loss = 28369.2246, recon_loss = 28367.5254, kl_loss = 1.6991\n",
      "Batch 600, loss = 37380068.0000, recon_loss = 37380064.0000, kl_loss = 3.0676\n",
      "Batch 650, loss = 390508828426240.0000, recon_loss = 390508828426240.0000, kl_loss = 4.2397\n",
      "Batch 700, loss = 5848113369579520.0000, recon_loss = 5848113369579520.0000, kl_loss = 5.1455\n",
      "Average loss: 36437487229209992.0000\n",
      "Epoch: 88\n",
      "Batch 50, loss = 6297.2939, recon_loss = 6293.8931, kl_loss = 3.4010\n",
      "Batch 100, loss = 717.0740, recon_loss = 714.5219, kl_loss = 2.5522\n",
      "Batch 150, loss = 155.2259, recon_loss = 153.8503, kl_loss = 1.3756\n",
      "Batch 200, loss = 303843.0938, recon_loss = 303841.4688, kl_loss = 1.6287\n",
      "Batch 250, loss = 293.7740, recon_loss = 292.2741, kl_loss = 1.4999\n",
      "Batch 300, loss = 553.7126, recon_loss = 551.3622, kl_loss = 2.3504\n",
      "Batch 350, loss = 705.1851, recon_loss = 703.6716, kl_loss = 1.5134\n",
      "Batch 400, loss = 1508.6953, recon_loss = 1506.0312, kl_loss = 2.6641\n",
      "Batch 450, loss = 188211.1562, recon_loss = 188206.1875, kl_loss = 4.9680\n",
      "Batch 500, loss = 1876.3794, recon_loss = 1874.6138, kl_loss = 1.7656\n",
      "Batch 550, loss = 28370.4355, recon_loss = 28368.7402, kl_loss = 1.6949\n",
      "Batch 600, loss = 37340636.0000, recon_loss = 37340632.0000, kl_loss = 3.1337\n",
      "Batch 650, loss = 390507721129984.0000, recon_loss = 390507721129984.0000, kl_loss = 4.2134\n",
      "Batch 700, loss = 5848112832708608.0000, recon_loss = 5848112832708608.0000, kl_loss = 5.1346\n",
      "Average loss: 36437487024980616.0000\n",
      "Epoch: 89\n",
      "Batch 50, loss = 6298.6758, recon_loss = 6295.3145, kl_loss = 3.3614\n",
      "Batch 100, loss = 768.7510, recon_loss = 766.2040, kl_loss = 2.5470\n",
      "Batch 150, loss = 183.7537, recon_loss = 182.3550, kl_loss = 1.3986\n",
      "Batch 200, loss = 303850.1562, recon_loss = 303848.5000, kl_loss = 1.6717\n",
      "Batch 250, loss = 288.8514, recon_loss = 287.2564, kl_loss = 1.5950\n",
      "Batch 300, loss = 454.9875, recon_loss = 452.6915, kl_loss = 2.2960\n",
      "Batch 350, loss = 701.6547, recon_loss = 700.2080, kl_loss = 1.4466\n",
      "Batch 400, loss = 1510.9027, recon_loss = 1508.2113, kl_loss = 2.6914\n",
      "Batch 450, loss = 190020.0312, recon_loss = 190015.2969, kl_loss = 4.7383\n",
      "Batch 500, loss = 1877.1414, recon_loss = 1875.4053, kl_loss = 1.7360\n",
      "Batch 550, loss = 28371.1387, recon_loss = 28369.4512, kl_loss = 1.6867\n",
      "Batch 600, loss = 37321512.0000, recon_loss = 37321508.0000, kl_loss = 2.8460\n",
      "Batch 650, loss = 390506546724864.0000, recon_loss = 390506546724864.0000, kl_loss = 4.2433\n",
      "Batch 700, loss = 5848111222095872.0000, recon_loss = 5848111222095872.0000, kl_loss = 5.1690\n",
      "Average loss: 36437486837175464.0000\n",
      "Epoch: 90\n",
      "Batch 50, loss = 6377.7437, recon_loss = 6374.3359, kl_loss = 3.4076\n",
      "Batch 100, loss = 784.7983, recon_loss = 782.3135, kl_loss = 2.4848\n",
      "Batch 150, loss = 152.2757, recon_loss = 150.7924, kl_loss = 1.4833\n",
      "Batch 200, loss = 303844.5000, recon_loss = 303842.7500, kl_loss = 1.7424\n",
      "Batch 250, loss = 286.3215, recon_loss = 284.8067, kl_loss = 1.5148\n",
      "Batch 300, loss = 459.2279, recon_loss = 457.0168, kl_loss = 2.2112\n",
      "Batch 350, loss = 709.1396, recon_loss = 707.7339, kl_loss = 1.4057\n",
      "Batch 400, loss = 1507.5249, recon_loss = 1504.7673, kl_loss = 2.7575\n",
      "Batch 450, loss = 187734.5781, recon_loss = 187729.8125, kl_loss = 4.7683\n",
      "Batch 500, loss = 1891.4142, recon_loss = 1889.6748, kl_loss = 1.7394\n",
      "Batch 550, loss = 28369.2012, recon_loss = 28367.5586, kl_loss = 1.6429\n",
      "Batch 600, loss = 37253356.0000, recon_loss = 37253352.0000, kl_loss = 2.9497\n",
      "Batch 650, loss = 390505405874176.0000, recon_loss = 390505405874176.0000, kl_loss = 4.2373\n",
      "Batch 700, loss = 5848109074612224.0000, recon_loss = 5848109074612224.0000, kl_loss = 5.1619\n",
      "Average loss: 36437486639479144.0000\n",
      "Epoch: 91\n",
      "Batch 50, loss = 6908.1992, recon_loss = 6904.6748, kl_loss = 3.5243\n",
      "Batch 100, loss = 746.3519, recon_loss = 743.8958, kl_loss = 2.4561\n",
      "Batch 150, loss = 152.3423, recon_loss = 150.9997, kl_loss = 1.3426\n",
      "Batch 200, loss = 303853.3438, recon_loss = 303851.5312, kl_loss = 1.8024\n",
      "Batch 250, loss = 295.0739, recon_loss = 293.5311, kl_loss = 1.5428\n",
      "Batch 300, loss = 574.3361, recon_loss = 571.9387, kl_loss = 2.3974\n",
      "Batch 350, loss = 701.4104, recon_loss = 699.9476, kl_loss = 1.4628\n",
      "Batch 400, loss = 1503.2971, recon_loss = 1500.5236, kl_loss = 2.7736\n",
      "Batch 450, loss = 186389.5781, recon_loss = 186384.5625, kl_loss = 5.0087\n",
      "Batch 500, loss = 1877.3282, recon_loss = 1875.5972, kl_loss = 1.7311\n",
      "Batch 550, loss = 28369.3223, recon_loss = 28367.6660, kl_loss = 1.6571\n",
      "Batch 600, loss = 37216276.0000, recon_loss = 37216272.0000, kl_loss = 3.1434\n",
      "Batch 650, loss = 390504298577920.0000, recon_loss = 390504298577920.0000, kl_loss = 4.2682\n",
      "Batch 700, loss = 5848109074612224.0000, recon_loss = 5848109074612224.0000, kl_loss = 5.2058\n",
      "Average loss: 36437486443077536.0000\n",
      "Epoch: 92\n",
      "Batch 50, loss = 6334.3677, recon_loss = 6330.9287, kl_loss = 3.4392\n",
      "Batch 100, loss = 813.9018, recon_loss = 811.3395, kl_loss = 2.5623\n",
      "Batch 150, loss = 168.8393, recon_loss = 167.4093, kl_loss = 1.4300\n",
      "Batch 200, loss = 303841.5312, recon_loss = 303839.7188, kl_loss = 1.8269\n",
      "Batch 250, loss = 293.1141, recon_loss = 291.6269, kl_loss = 1.4872\n",
      "Batch 300, loss = 566.1273, recon_loss = 563.7512, kl_loss = 2.3761\n",
      "Batch 350, loss = 704.8745, recon_loss = 703.4366, kl_loss = 1.4378\n",
      "Batch 400, loss = 1512.3467, recon_loss = 1509.6185, kl_loss = 2.7282\n",
      "Batch 450, loss = 186221.5625, recon_loss = 186216.7812, kl_loss = 4.7866\n",
      "Batch 500, loss = 1887.5942, recon_loss = 1885.8572, kl_loss = 1.7370\n",
      "Batch 550, loss = 28368.8516, recon_loss = 28367.1641, kl_loss = 1.6882\n",
      "Batch 600, loss = 37168452.0000, recon_loss = 37168448.0000, kl_loss = 3.0366\n",
      "Batch 650, loss = 390503157727232.0000, recon_loss = 390503157727232.0000, kl_loss = 4.2716\n",
      "Batch 700, loss = 5848107463999488.0000, recon_loss = 5848107463999488.0000, kl_loss = 5.0306\n",
      "Average loss: 36437486252177992.0000\n",
      "Epoch: 93\n",
      "Batch 50, loss = 6373.2461, recon_loss = 6369.7500, kl_loss = 3.4959\n",
      "Batch 100, loss = 761.3229, recon_loss = 758.7208, kl_loss = 2.6021\n",
      "Batch 150, loss = 209.6078, recon_loss = 208.1385, kl_loss = 1.4693\n",
      "Batch 200, loss = 303848.9062, recon_loss = 303847.1250, kl_loss = 1.7923\n",
      "Batch 250, loss = 294.9593, recon_loss = 293.3692, kl_loss = 1.5900\n",
      "Batch 300, loss = 597.4622, recon_loss = 595.0637, kl_loss = 2.3985\n",
      "Batch 350, loss = 702.7532, recon_loss = 701.3412, kl_loss = 1.4120\n",
      "Batch 400, loss = 1509.4238, recon_loss = 1506.5377, kl_loss = 2.8861\n",
      "Batch 450, loss = 185362.7031, recon_loss = 185357.5625, kl_loss = 5.1461\n",
      "Batch 500, loss = 1876.7854, recon_loss = 1875.0176, kl_loss = 1.7678\n",
      "Batch 550, loss = 28369.2344, recon_loss = 28367.5176, kl_loss = 1.7165\n",
      "Batch 600, loss = 37096724.0000, recon_loss = 37096720.0000, kl_loss = 3.2052\n",
      "Batch 650, loss = 390502050430976.0000, recon_loss = 390502050430976.0000, kl_loss = 4.0941\n",
      "Batch 700, loss = 5848106390257664.0000, recon_loss = 5848106390257664.0000, kl_loss = 5.0215\n",
      "Average loss: 36437486053480072.0000\n",
      "Epoch: 94\n",
      "Batch 50, loss = 6461.7070, recon_loss = 6458.1729, kl_loss = 3.5341\n",
      "Batch 100, loss = 819.6266, recon_loss = 817.0546, kl_loss = 2.5720\n",
      "Batch 150, loss = 177.6658, recon_loss = 176.2435, kl_loss = 1.4223\n",
      "Batch 200, loss = 303837.8438, recon_loss = 303836.0625, kl_loss = 1.7721\n",
      "Batch 250, loss = 286.3836, recon_loss = 284.9541, kl_loss = 1.4295\n",
      "Batch 300, loss = 437.5460, recon_loss = 435.2649, kl_loss = 2.2811\n",
      "Batch 350, loss = 702.6839, recon_loss = 701.2015, kl_loss = 1.4824\n",
      "Batch 400, loss = 1508.4159, recon_loss = 1505.6030, kl_loss = 2.8129\n",
      "Batch 450, loss = 187221.5469, recon_loss = 187216.4375, kl_loss = 5.1118\n",
      "Batch 500, loss = 1878.8551, recon_loss = 1877.0527, kl_loss = 1.8024\n",
      "Batch 550, loss = 28371.0566, recon_loss = 28369.3906, kl_loss = 1.6664\n",
      "Batch 600, loss = 37037652.0000, recon_loss = 37037648.0000, kl_loss = 3.2022\n",
      "Batch 650, loss = 390500909580288.0000, recon_loss = 390500909580288.0000, kl_loss = 4.1101\n",
      "Batch 700, loss = 5848105853386752.0000, recon_loss = 5848105853386752.0000, kl_loss = 5.0344\n",
      "Average loss: 36437485867799176.0000\n",
      "Epoch: 95\n",
      "Batch 50, loss = 6344.0781, recon_loss = 6340.6523, kl_loss = 3.4259\n",
      "Batch 100, loss = 743.6426, recon_loss = 741.0619, kl_loss = 2.5807\n",
      "Batch 150, loss = 152.8164, recon_loss = 151.1971, kl_loss = 1.6193\n",
      "Batch 200, loss = 303828.1562, recon_loss = 303826.2188, kl_loss = 1.9311\n",
      "Batch 250, loss = 288.0260, recon_loss = 286.5538, kl_loss = 1.4722\n",
      "Batch 300, loss = 495.1775, recon_loss = 492.7609, kl_loss = 2.4166\n",
      "Batch 350, loss = 702.9385, recon_loss = 701.4867, kl_loss = 1.4518\n",
      "Batch 400, loss = 1505.8879, recon_loss = 1503.1079, kl_loss = 2.7800\n",
      "Batch 450, loss = 185943.8594, recon_loss = 185938.7031, kl_loss = 5.1534\n",
      "Batch 500, loss = 1877.7279, recon_loss = 1875.9448, kl_loss = 1.7831\n",
      "Batch 550, loss = 28367.6777, recon_loss = 28366.0234, kl_loss = 1.6550\n",
      "Batch 600, loss = 37037076.0000, recon_loss = 37037072.0000, kl_loss = 3.4023\n",
      "Batch 650, loss = 390499768729600.0000, recon_loss = 390499768729600.0000, kl_loss = 4.1483\n",
      "Batch 700, loss = 5848104779644928.0000, recon_loss = 5848104779644928.0000, kl_loss = 5.0728\n",
      "Average loss: 36437479769612528.0000\n",
      "Epoch: 96\n",
      "Batch 50, loss = 6414.7671, recon_loss = 6411.0264, kl_loss = 3.7406\n",
      "Batch 100, loss = 730.8539, recon_loss = 728.2585, kl_loss = 2.5953\n",
      "Batch 150, loss = 169.7211, recon_loss = 168.2952, kl_loss = 1.4259\n",
      "Batch 200, loss = 303834.3438, recon_loss = 303832.5938, kl_loss = 1.7467\n",
      "Batch 250, loss = 286.4663, recon_loss = 284.9276, kl_loss = 1.5387\n",
      "Batch 300, loss = 441.0039, recon_loss = 438.6678, kl_loss = 2.3361\n",
      "Batch 350, loss = 706.1131, recon_loss = 704.6918, kl_loss = 1.4212\n",
      "Batch 400, loss = 1514.8314, recon_loss = 1512.1614, kl_loss = 2.6700\n",
      "Batch 450, loss = 185125.0625, recon_loss = 185119.9688, kl_loss = 5.0944\n",
      "Batch 500, loss = 1876.9891, recon_loss = 1875.2471, kl_loss = 1.7420\n",
      "Batch 550, loss = 28367.6191, recon_loss = 28365.9746, kl_loss = 1.6452\n",
      "Batch 600, loss = 36989360.0000, recon_loss = 36989356.0000, kl_loss = 3.4884\n",
      "Batch 650, loss = 390498694987776.0000, recon_loss = 390498694987776.0000, kl_loss = 4.1356\n",
      "Batch 700, loss = 5848102632161280.0000, recon_loss = 5848102632161280.0000, kl_loss = 5.0744\n",
      "Average loss: 36437478828984360.0000\n",
      "Epoch: 97\n",
      "Batch 50, loss = 6330.0679, recon_loss = 6326.6021, kl_loss = 3.4659\n",
      "Batch 100, loss = 747.3647, recon_loss = 744.6974, kl_loss = 2.6673\n",
      "Batch 150, loss = 153.6450, recon_loss = 152.1820, kl_loss = 1.4630\n",
      "Batch 200, loss = 303832.3125, recon_loss = 303830.5312, kl_loss = 1.7803\n",
      "Batch 250, loss = 305.1010, recon_loss = 303.6113, kl_loss = 1.4897\n",
      "Batch 300, loss = 531.4611, recon_loss = 529.0850, kl_loss = 2.3760\n",
      "Batch 350, loss = 699.6206, recon_loss = 698.1829, kl_loss = 1.4377\n",
      "Batch 400, loss = 1514.8108, recon_loss = 1511.9833, kl_loss = 2.8275\n",
      "Batch 450, loss = 184666.6250, recon_loss = 184661.5312, kl_loss = 5.0985\n",
      "Batch 500, loss = 1892.5210, recon_loss = 1890.7021, kl_loss = 1.8189\n",
      "Batch 550, loss = 28368.2793, recon_loss = 28366.6348, kl_loss = 1.6442\n",
      "Batch 600, loss = 36932996.0000, recon_loss = 36932992.0000, kl_loss = 2.9808\n",
      "Batch 650, loss = 390497554137088.0000, recon_loss = 390497554137088.0000, kl_loss = 4.1811\n",
      "Batch 700, loss = 5848102632161280.0000, recon_loss = 5848102632161280.0000, kl_loss = 5.1271\n",
      "Average loss: 36437478639704120.0000\n",
      "Epoch: 98\n",
      "Batch 50, loss = 6295.5273, recon_loss = 6291.9819, kl_loss = 3.5455\n",
      "Batch 100, loss = 735.6619, recon_loss = 733.0342, kl_loss = 2.6277\n",
      "Batch 150, loss = 169.2865, recon_loss = 167.7614, kl_loss = 1.5251\n",
      "Batch 200, loss = 303838.7812, recon_loss = 303836.9062, kl_loss = 1.8613\n",
      "Batch 250, loss = 288.9271, recon_loss = 287.3375, kl_loss = 1.5896\n",
      "Batch 300, loss = 520.8527, recon_loss = 518.4598, kl_loss = 2.3930\n",
      "Batch 350, loss = 702.6735, recon_loss = 701.2086, kl_loss = 1.4648\n",
      "Batch 400, loss = 1510.0967, recon_loss = 1507.2656, kl_loss = 2.8311\n",
      "Batch 450, loss = 185016.9531, recon_loss = 185011.6562, kl_loss = 5.3046\n",
      "Batch 500, loss = 1874.8170, recon_loss = 1873.0579, kl_loss = 1.7592\n",
      "Batch 550, loss = 28368.1465, recon_loss = 28366.5195, kl_loss = 1.6263\n",
      "Batch 600, loss = 36896788.0000, recon_loss = 36896784.0000, kl_loss = 2.8439\n",
      "Batch 650, loss = 390496413286400.0000, recon_loss = 390496413286400.0000, kl_loss = 4.1899\n",
      "Batch 700, loss = 5848100484677632.0000, recon_loss = 5848100484677632.0000, kl_loss = 5.1368\n",
      "Average loss: 36437478457318072.0000\n",
      "Epoch: 99\n",
      "Batch 50, loss = 6413.4604, recon_loss = 6409.8848, kl_loss = 3.5755\n",
      "Batch 100, loss = 691.3077, recon_loss = 688.6470, kl_loss = 2.6606\n",
      "Batch 150, loss = 147.5143, recon_loss = 146.0336, kl_loss = 1.4807\n",
      "Batch 200, loss = 303841.5625, recon_loss = 303839.5625, kl_loss = 1.9864\n",
      "Batch 250, loss = 288.4149, recon_loss = 286.8153, kl_loss = 1.5996\n",
      "Batch 300, loss = 610.5449, recon_loss = 608.1261, kl_loss = 2.4189\n",
      "Batch 350, loss = 702.1877, recon_loss = 700.6884, kl_loss = 1.4993\n",
      "Batch 400, loss = 1513.1731, recon_loss = 1510.2874, kl_loss = 2.8857\n",
      "Batch 450, loss = 184514.9688, recon_loss = 184509.7188, kl_loss = 5.2457\n",
      "Batch 500, loss = 1875.4573, recon_loss = 1873.7435, kl_loss = 1.7138\n",
      "Batch 550, loss = 28369.9023, recon_loss = 28368.2520, kl_loss = 1.6500\n",
      "Batch 600, loss = 36879068.0000, recon_loss = 36879064.0000, kl_loss = 3.2363\n",
      "Batch 650, loss = 390495272435712.0000, recon_loss = 390495272435712.0000, kl_loss = 4.1955\n",
      "Batch 700, loss = 5848099410935808.0000, recon_loss = 5848099410935808.0000, kl_loss = 5.1390\n",
      "Average loss: 36437478261858256.0000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "loss_arr = vrae.fit(train_dataset)\n",
    "\n",
    "#If the model has to be saved, with the learnt parameters use:\n",
    "# vrae.fit(dataset, save = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fa9cecfef98>]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(loss_arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the model to be fetched later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To save a presaved model, execute:\n",
    "# vrae.save('vrae_layer1_epoch1000.pth')\n",
    "# vrae.save('vrae_layer2_epoch1000.pth')\n",
    "\n",
    "# To load a presaved model, execute:\n",
    "# vrae.load('vrae_layer1_epoch1000.pth')\n",
    "# vrae.load('vrae_layer2_epoch1000.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vrae.is_fitted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform the input timeseries to encoded latent vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.37149006,  0.19548929, -0.4733491 , ..., -0.8907772 ,\n",
       "         0.32326856, -0.55709785],\n",
       "       [ 0.3595212 ,  0.25622487, -0.58140874, ..., -0.7897379 ,\n",
       "         0.37766486, -0.5722628 ],\n",
       "       [ 0.41739964,  0.19003512, -0.5061105 , ..., -0.86193854,\n",
       "         0.35663676, -0.55590016],\n",
       "       ...,\n",
       "       [ 0.26835892,  0.2436367 , -0.39543933, ..., -0.9192079 ,\n",
       "         0.34381288, -0.5295244 ],\n",
       "       [ 0.27450037,  0.2393853 , -0.37724158, ..., -0.93880385,\n",
       "         0.3433256 , -0.547297  ],\n",
       "       [ 0.24829076,  0.2739212 , -0.4094233 , ..., -0.877944  ,\n",
       "         0.34034395, -0.5496271 ]], dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z_run = vrae.transform(test_dataset)\n",
    "z_run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64, 30)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z_run.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from einops import rearrange\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concat_recon(recon_output):\n",
    "    \n",
    "    w,b,f = recon_output.shape\n",
    "    tmp = rearrange(recon_output, 'w b f -> b w f')\n",
    "    output = tmp.reshape(w*b,f)\n",
    "\n",
    "    return output\n",
    "\n",
    "def eval_recon(recon, real, scaler = None, undo = True):\n",
    "    criterion = nn.MSELoss()\n",
    "    \n",
    "    if undo == True:\n",
    "        assert scaler != None, 'Scaler should be defined!!'\n",
    "        \n",
    "        # reverse scaling\n",
    "        recon = scaler.inverse_transform(recon)\n",
    "    \n",
    "    r = recon.shape[0]\n",
    "    real = real[:r,:]\n",
    "\n",
    "    # compute loss\n",
    "    eval_loss = criterion(torch.tensor(recon), torch.tensor(real))\n",
    "    \n",
    "    return eval_loss\n",
    "\n",
    "def get_diff(recon, real, undo = True):\n",
    "    if undo == True:\n",
    "        # undo minmax scaling\n",
    "        recon = inverse_minmax(recon)\n",
    "    \n",
    "    r = recon.shape[0]\n",
    "    real = real[:r,:]\n",
    "    \n",
    "    return recon, real, np.abs(recon-real)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reconstruct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30, 704, 92)\n"
     ]
    }
   ],
   "source": [
    "# train reconstruct\n",
    "train_recon = vrae.reconstruct(train_dataset)\n",
    "print(train_recon.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21120, 92)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_recon = concat_recon(train_recon)\n",
    "train_recon.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.2022e+13, dtype=torch.float64)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_recon(recon = train_recon, real = TRAIN_DF, scaler = scaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eval_recon(train_recon, TRAIN_SCALED, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30, 64, 92)\n"
     ]
    }
   ],
   "source": [
    "# test reconstruct\n",
    "test_recon = vrae.reconstruct(test_dataset)\n",
    "print(test_recon.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1920, 92)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_recon = concat_recon(test_recon)\n",
    "test_recon.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.4607e+12, dtype=torch.float64)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_recon(recon = test_recon, real = TEST_DF, scaler = scaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eval_recon(test_recon, TEST_SCALED, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize Train Difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21120, 92)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_recon, train_real, train_diff  = get_diff(train_recon, TRAIN_SCALED, False)\n",
    "train_diff.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_recon = pd.DataFrame(train_recon, columns= cols)\n",
    "train_real = pd.DataFrame(train_real, columns= cols)\n",
    "train_diff = pd.DataFrame(train_diff, columns= cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (20,5)\n",
    "\n",
    "for i in cols:\n",
    "    print(f'Saving plot {i}')\n",
    "    plt.plot(train_diff[i])\n",
    "    plt.title(f'{i}')\n",
    "    plt.savefig(f'./result/plots/train/layer2/{i}.png')\n",
    "    plt.clf() # Clear the current figure\n",
    "\n",
    "# plt.plot(train_diff[cols[random.randrange(92)]])\n",
    "# plt.title(f'{cols[random.randrange(92)]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize Test Difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_recon, test_real, test_diff  = get_diff(test_recon, TEST_SCALED, False)\n",
    "test_diff.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_recon = pd.DataFrame(test_recon, columns= cols)\n",
    "test_real = pd.DataFrame(test_real, columns= cols)\n",
    "test_diff = pd.DataFrame(test_diff, columns= cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (20,5)\n",
    "\n",
    "for i in cols:\n",
    "    print(f'Saving plot {i}')\n",
    "    plt.plot(test_diff[i])\n",
    "    plt.title(f'{i}')\n",
    "    plt.savefig(f'./result/plots/test/layer2/{i}.png')\n",
    "    plt.clf() # Clear the current figure\n",
    "\n",
    "\n",
    "# plt.plot(train_diff[cols[random.randrange(92)]])\n",
    "# plt.title(f'{cols[random.randrange(92)]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Contents\n",
    "\n",
    "0. [Load data and preprocess](#Load-data-and-preprocess)\n",
    "1. [Initialize VRAE object](#Initialize-VRAE-object)\n",
    "2. [Fit the model onto dataset](#Fit-the-model-onto-dataset)\n",
    "3. [Transform the input timeseries to encoded latent vectors](#Transform-the-input-timeseries-to-encoded-latent-vectors)\n",
    "4. [Save the model to be fetched later](#Save-the-model-to-be-fetched-later)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "def fix_seed(seed: int) -> None:\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "fix_seed(555)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import required modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.vrae import VRAE\n",
    "\n",
    "from model.utils import *\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from tqdm.notebook import trange\n",
    "import tqdm\n",
    "\n",
    "import pickle\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dload = './save_model' #download directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### utils.load_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_gen_data(file_name, scale_type = 'Standard', cols_to_remove = None):\n",
    "    \"\"\"\n",
    "    folder: folder where data is located\n",
    "    \"\"\"\n",
    "    \n",
    "    # define path(must be in pkl file)\n",
    "    data_loc = f'./data/netis/{file_name}.pkl'    \n",
    "    \n",
    "    # get data\n",
    "    with open(data_loc, 'rb') as f:\n",
    "        df = pickle.load(f)\n",
    "    \n",
    "    # if needed remove columns that is not necessary\n",
    "    if cols_to_remove != None:\n",
    "        df = df_total.drop(cols_to_remove, axis=1)\n",
    "    \n",
    "    df = df.dropna()\n",
    "    \n",
    "    # TRAIN TEST SPLIT\n",
    "    # TRAIN\n",
    "    TRAIN_DF = df.query('Time < 20211103184400 or Time > 20211106084400 and label==0')\n",
    "    \n",
    "    # TEST(GET ONLY 정상)\n",
    "    TEST_DF = df.query('Time >= 20211103184400 and Time <= 20211106084400 and label==0')\n",
    "\n",
    "    TOTAL_DF = df.to_numpy()\n",
    "    \n",
    "    # REMOVE TIME & LABEL\n",
    "    TRAIN_DF = TRAIN_DF.iloc[:,1:-1]\n",
    "    cols = TRAIN_DF.columns\n",
    "    TRAIN_DF = TRAIN_DF.to_numpy()\n",
    "    TEST_DF = TEST_DF.iloc[:,1:-1].to_numpy()\n",
    "    \n",
    "    if scale_type == 'MinMax':\n",
    "        scaler = MinMaxScaler()\n",
    "    elif scale_type == 'Standard':\n",
    "        scaler = StandardScaler()\n",
    "    else:\n",
    "        pass\n",
    "    \n",
    "    TRAIN_SCALED = scaler.fit(TRAIN_DF).transform(TRAIN_DF)\n",
    "    TEST_SCALED = scaler.transform(TEST_DF)\n",
    "    \n",
    "    return TOTAL_DF, TRAIN_DF, TEST_DF, TRAIN_SCALED, TEST_SCALED, cols, scaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyper parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data and preprocess\n",
    "- `file_name` : pkl file_name\n",
    "- `cols_to_remove` : generation 수행하지 않을 column 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(26002, 94)\n",
      "(22363, 92)\n",
      "(3627, 92)\n"
     ]
    }
   ],
   "source": [
    "# params\n",
    "file_name = 'netis'\n",
    "\n",
    "# load data\n",
    "TOTAL_DF, TRAIN_DF, TEST_DF, TRAIN_SCALED, TEST_SCALED, cols, scaler = load_gen_data(file_name)\n",
    "\n",
    "# shape\n",
    "print(TOTAL_DF.shape)\n",
    "print(TRAIN_SCALED.shape)\n",
    "print(TEST_SCALED.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GenerationDataset(Dataset):\n",
    "    def __init__(self, data, window):\n",
    "        self.data = torch.Tensor(data)\n",
    "        self.window = window\n",
    " \n",
    "    def __len__(self):\n",
    "        return len(self.data) // self.window # -1\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "#         x = self.data[index*self.window:index*(self.window+1)]\n",
    "        x = self.data[index*self.window:(index+1)*(self.window)]\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "window = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.GenerationDataset at 0x7faaf47789e8>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset = GenerationDataset(TRAIN_SCALED, window)\n",
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.GenerationDataset at 0x7faa14b9fa90>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset = GenerationDataset(TEST_SCALED, window)\n",
    "test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([30, 92])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Fetch `sequence_length` from dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequence_length = train_dataset[0].shape[0]\n",
    "sequence_length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Fetch `number_of_features` from dataset**\n",
    "\n",
    "This config corresponds to number of input features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "92"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "number_of_features = train_dataset[0].shape[1]\n",
    "number_of_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 5\n",
    "hidden_size = 90\n",
    "# hidden_layer_depth = 2\n",
    "hidden_layer_depth = 1\n",
    "latent_length = 30\n",
    "batch_size = 64\n",
    "learning_rate = 0.0002\n",
    "dropout_rate = 0.2\n",
    "optimizer = 'Adam' # options: ADAM, SGD\n",
    "cuda = True # options: True, False\n",
    "print_every=50\n",
    "clip = True # options: True, False\n",
    "max_grad_norm=5\n",
    "loss = 'MSELoss' # options: SmoothL1Loss, MSELoss\n",
    "block = 'LSTM' # options: LSTM, GRU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize VRAE object\n",
    "\n",
    "VRAE inherits from `sklearn.base.BaseEstimator` and overrides `fit`, `transform` and `fit_transform` functions, similar to sklearn modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/rnn.py:65: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  \"num_layers={}\".format(dropout, num_layers))\n",
      "/usr/local/lib/python3.6/dist-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    }
   ],
   "source": [
    "vrae = VRAE(sequence_length=sequence_length,\n",
    "            number_of_features = number_of_features,\n",
    "            hidden_size = hidden_size, \n",
    "            hidden_layer_depth = hidden_layer_depth,\n",
    "            latent_length = latent_length,\n",
    "            batch_size = batch_size,\n",
    "            learning_rate = learning_rate,\n",
    "            n_epochs = n_epochs,\n",
    "            dropout_rate = dropout_rate,\n",
    "            optimizer = optimizer, \n",
    "            cuda = cuda,\n",
    "            print_every=print_every, \n",
    "            clip=clip, \n",
    "            max_grad_norm=max_grad_norm,\n",
    "            loss = loss,\n",
    "            block = block,\n",
    "            dload = dload)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit the model onto dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9cd0fc578f62444190236fd7ab7cf0a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "Average loss: 120207.4260\n",
      "Epoch: 1\n",
      "Average loss: 119823.7354\n",
      "Epoch: 2\n",
      "Average loss: 119614.9631\n",
      "Epoch: 3\n",
      "Average loss: 119419.6828\n",
      "Epoch: 4\n",
      "Average loss: 119217.4336\n",
      "\n"
     ]
    }
   ],
   "source": [
    "loss_arr = vrae.fit(train_dataset)\n",
    "\n",
    "#If the model has to be saved, with the learnt parameters use:\n",
    "# vrae.fit(dataset, save = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fa9cf0dfe80>]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(loss_arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the model to be fetched later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vrae.save('vrae_layer1_epoch1000.pth')\n",
    "vrae.save('vrae_layer2_epoch1000.pth')\n",
    "\n",
    "# To load a presaved model, execute:\n",
    "# vrae.load('vrae_layer1_epoch1000.pth')\n",
    "# vrae.load('vrae_layer2_epoch1000.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vrae.is_fitted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform the input timeseries to encoded latent vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.37149006,  0.19548929, -0.4733491 , ..., -0.8907772 ,\n",
       "         0.32326856, -0.55709785],\n",
       "       [ 0.3595212 ,  0.25622487, -0.58140874, ..., -0.7897379 ,\n",
       "         0.37766486, -0.5722628 ],\n",
       "       [ 0.41739964,  0.19003512, -0.5061105 , ..., -0.86193854,\n",
       "         0.35663676, -0.55590016],\n",
       "       ...,\n",
       "       [ 0.26835892,  0.2436367 , -0.39543933, ..., -0.9192079 ,\n",
       "         0.34381288, -0.5295244 ],\n",
       "       [ 0.27450037,  0.2393853 , -0.37724158, ..., -0.93880385,\n",
       "         0.3433256 , -0.547297  ],\n",
       "       [ 0.24829076,  0.2739212 , -0.4094233 , ..., -0.877944  ,\n",
       "         0.34034395, -0.5496271 ]], dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z_run = vrae.transform(test_dataset)\n",
    "z_run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64, 30)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z_run.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from einops import rearrange\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concat_recon(recon_output):\n",
    "    \n",
    "    w,b,f = recon_output.shape\n",
    "    tmp = rearrange(recon_output, 'w b f -> b w f')\n",
    "    output = tmp.reshape(w*b,f)\n",
    "\n",
    "    return output\n",
    "\n",
    "def eval_recon(recon, real, scaler = None, undo = True):\n",
    "    criterion = nn.MSELoss()\n",
    "    \n",
    "    if undo == True:\n",
    "        assert scaler != None, 'Scaler should be defined!!'\n",
    "        \n",
    "        # reverse scaling\n",
    "        recon = scaler.inverse_transform(recon)\n",
    "    \n",
    "    r = recon.shape[0]\n",
    "    real = real[:r,:]\n",
    "\n",
    "    # compute loss\n",
    "    eval_loss = criterion(torch.tensor(recon), torch.tensor(real))\n",
    "    \n",
    "    return eval_loss\n",
    "\n",
    "def get_diff(recon, real, undo = True):\n",
    "    if undo == True:\n",
    "        # undo minmax scaling\n",
    "        recon = inverse_minmax(recon)\n",
    "    \n",
    "    r = recon.shape[0]\n",
    "    real = real[:r,:]\n",
    "    \n",
    "    return recon, real, np.abs(recon-real)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reconstruct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30, 704, 92)\n"
     ]
    }
   ],
   "source": [
    "# train reconstruct\n",
    "train_recon = vrae.reconstruct(train_dataset)\n",
    "print(train_recon.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21120, 92)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_recon = concat_recon(train_recon)\n",
    "train_recon.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.2022e+13, dtype=torch.float64)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_recon(recon = train_recon, real = TRAIN_DF, scaler = scaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eval_recon(train_recon, TRAIN_SCALED, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30, 64, 92)\n"
     ]
    }
   ],
   "source": [
    "# test reconstruct\n",
    "test_recon = vrae.reconstruct(test_dataset)\n",
    "print(test_recon.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1920, 92)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_recon = concat_recon(test_recon)\n",
    "test_recon.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.4607e+12, dtype=torch.float64)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_recon(recon = test_recon, real = TEST_DF, scaler = scaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eval_recon(test_recon, TEST_SCALED, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize Train Difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21120, 92)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_recon, train_real, train_diff  = get_diff(train_recon, TRAIN_SCALED, False)\n",
    "train_diff.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_recon = pd.DataFrame(train_recon, columns= cols)\n",
    "train_real = pd.DataFrame(train_real, columns= cols)\n",
    "train_diff = pd.DataFrame(train_diff, columns= cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (20,5)\n",
    "\n",
    "for i in cols:\n",
    "    print(f'Saving plot {i}')\n",
    "    plt.plot(train_diff[i])\n",
    "    plt.title(f'{i}')\n",
    "    plt.savefig(f'./plots/train/layer2/{i}.png')\n",
    "    plt.clf() # Clear the current figure\n",
    "\n",
    "# plt.plot(train_diff[cols[random.randrange(92)]])\n",
    "# plt.title(f'{cols[random.randrange(92)]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize Test Difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_recon, test_real, test_diff  = get_diff(test_recon, TEST_SCALED, False)\n",
    "test_diff.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_recon = pd.DataFrame(test_recon, columns= cols)\n",
    "test_real = pd.DataFrame(test_real, columns= cols)\n",
    "test_diff = pd.DataFrame(test_diff, columns= cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (20,5)\n",
    "\n",
    "for i in cols:\n",
    "    print(f'Saving plot {i}')\n",
    "    plt.plot(test_diff[i])\n",
    "    plt.title(f'{i}')\n",
    "    plt.savefig(f'./plots/test/layer2/{i}.png')\n",
    "    plt.clf() # Clear the current figure\n",
    "\n",
    "\n",
    "# plt.plot(train_diff[cols[random.randrange(92)]])\n",
    "# plt.title(f'{cols[random.randrange(92)]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

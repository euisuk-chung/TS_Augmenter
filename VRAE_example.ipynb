{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Contents\n",
    "\n",
    "0. [Load data and preprocess](#Load-data-and-preprocess)\n",
    "1. [Initialize VRAE object](#Initialize-VRAE-object)\n",
    "2. [Fit the model onto dataset](#Fit-the-model-onto-dataset)\n",
    "3. [Transform the input timeseries to encoded latent vectors](#Transform-the-input-timeseries-to-encoded-latent-vectors)\n",
    "4. [Save the model to be fetched later](#Save-the-model-to-be-fetched-later)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import required modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.vrae import VRAE\n",
    "\n",
    "from model.utils import *\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from tqdm.notebook import trange\n",
    "import tqdm\n",
    "\n",
    "import pickle\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dload = './saved_model' #download directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### utils.load_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_gen_data(file_name, cols_to_remove = None):\n",
    "    \"\"\"\n",
    "    folder: folder where data is located\n",
    "    \"\"\"\n",
    "    \n",
    "    # define path(must be in pkl file)\n",
    "    data_loc = f'./data/netis/{file_name}.pkl'    \n",
    "    \n",
    "    # get data\n",
    "    with open(data_loc, 'rb') as f:\n",
    "        df = pickle.load(f)\n",
    "    \n",
    "    # if needed remove columns that is not necessary\n",
    "    if cols_to_remove != None:\n",
    "        df = df_total.drop(cols_to_remove, axis=1)\n",
    "    \n",
    "    df = df.dropna()\n",
    "    \n",
    "    # TRAIN TEST SPLIT\n",
    "    # TRAIN\n",
    "    TRAIN_DF = df.query('Time < 20211103184400 or Time > 20211106084400 and label==0')\n",
    "    \n",
    "    # TEST(GET ONLY 정상)\n",
    "    TEST_DF = df.query('Time >= 20211103184400 and Time <= 20211106084400 and label==0')\n",
    "\n",
    "    TOTAL_DF = df.to_numpy()\n",
    "    \n",
    "    # REMOVE TIME & LABEL\n",
    "    TRAIN_DF = TRAIN_DF.iloc[:,1:-1]\n",
    "    TEST_DF = TEST_DF.iloc[:,1:-1]\n",
    "    \n",
    "    scaler = MinMaxScaler()\n",
    "    \n",
    "    TRAIN_SCALED_DF = scaler.fit(TRAIN_DF).transform(TRAIN_DF)\n",
    "    TEST_SCALED_DF = scaler.transform(TEST_DF)\n",
    "    \n",
    "    return TOTAL_DF, TRAIN_SCALED_DF, TEST_SCALED_DF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyper parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data and preprocess\n",
    "- `file_name` : pkl file_name\n",
    "- `cols_to_remove` : generation 수행하지 않을 column 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(26002, 94)\n",
      "(22363, 92)\n",
      "(3627, 92)\n"
     ]
    }
   ],
   "source": [
    "# params\n",
    "file_name = 'netis'\n",
    "\n",
    "# load data\n",
    "TOTAL_DF, TRAIN_DF, TEST_DF = load_gen_data(file_name)\n",
    "\n",
    "# shape\n",
    "print(TOTAL_DF.shape)\n",
    "print(TRAIN_DF.shape)\n",
    "print(TEST_DF.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.66328864e-04, 2.52639355e-05, 2.90615333e-05, ...,\n",
       "        3.42446043e-01, 4.98597475e-01, 1.65289256e-01],\n",
       "       [2.66795942e-04, 3.25753827e-05, 3.13032504e-05, ...,\n",
       "        3.51079137e-01, 4.97896213e-01, 1.65289256e-01],\n",
       "       [2.01613776e-04, 1.37864421e-05, 3.04728091e-05, ...,\n",
       "        3.51079137e-01, 4.97896213e-01, 1.23966942e-01],\n",
       "       ...,\n",
       "       [2.66813941e-03, 9.48559406e-04, 3.24553957e-06, ...,\n",
       "        6.04316547e-01, 9.89481066e-01, 2.89256198e-01],\n",
       "       [1.45200665e-03, 2.26151271e-03, 3.08280452e-06, ...,\n",
       "        6.04316547e-01, 9.88779804e-01, 3.05785124e-01],\n",
       "       [8.30917887e-03, 8.96945321e-04, 7.79900694e-06, ...,\n",
       "        6.04316547e-01, 9.88779804e-01, 2.97520661e-01]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TRAIN_DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.02355635e-03, 6.62881732e-05, 1.69243372e-05, ...,\n",
       "        6.79136691e-01, 3.52033661e-01, 2.14876033e-01],\n",
       "       [4.07135202e-03, 1.18662977e-04, 6.92800865e-06, ...,\n",
       "        6.79136691e-01, 3.52734923e-01, 2.14876033e-01],\n",
       "       [4.02378633e-03, 2.82489361e-04, 2.07942738e-05, ...,\n",
       "        6.79136691e-01, 3.52734923e-01, 2.14876033e-01],\n",
       "       ...,\n",
       "       [3.98419630e-03, 7.85747554e-05, 1.75819403e-05, ...,\n",
       "        5.98561151e-01, 4.25666199e-01, 2.56198347e-01],\n",
       "       [3.98799304e-03, 4.90275879e-05, 3.81572787e-06, ...,\n",
       "        6.00000000e-01, 4.24964937e-01, 2.56198347e-01],\n",
       "       [3.93781591e-03, 3.97621553e-05, 8.13602856e-06, ...,\n",
       "        6.04316547e-01, 4.24964937e-01, 2.47933884e-01]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TEST_DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GenerationDataset(Dataset):\n",
    "    def __init__(self, data, window):\n",
    "        self.data = torch.Tensor(data)\n",
    "        self.window = window\n",
    " \n",
    "    def __len__(self):\n",
    "        return len(self.data) // self.window -1\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "#         x = self.data[index*self.window:index*(self.window+1)]\n",
    "        x = self.data[index*self.window:(index+1)*(self.window)]\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "window = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.GenerationDataset at 0x7efbee52de80>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset = GenerationDataset(TRAIN_DF, window)\n",
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.GenerationDataset at 0x7efbee5764e0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset = GenerationDataset(TEST_DF, window)\n",
    "test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 92])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Fetch `sequence_length` from dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequence_length = train_dataset[0].shape[0]\n",
    "sequence_length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Fetch `number_of_features` from dataset**\n",
    "\n",
    "This config corresponds to number of input features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "92"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "number_of_features = train_dataset[0].shape[1]\n",
    "number_of_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 1000\n",
    "hidden_size = 90\n",
    "hidden_layer_depth = 1\n",
    "latent_length = 20\n",
    "batch_size = 1\n",
    "learning_rate = 0.0005\n",
    "dropout_rate = 0.2\n",
    "optimizer = 'Adam' # options: ADAM, SGD\n",
    "cuda = True # options: True, False\n",
    "print_every=30\n",
    "clip = True # options: True, False\n",
    "max_grad_norm=5\n",
    "loss = 'MSELoss' # options: SmoothL1Loss, MSELoss\n",
    "block = 'LSTM' # options: LSTM, GRU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize VRAE object\n",
    "\n",
    "VRAE inherits from `sklearn.base.BaseEstimator` and overrides `fit`, `transform` and `fit_transform` functions, similar to sklearn modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/rnn.py:65: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  \"num_layers={}\".format(dropout, num_layers))\n",
      "/usr/local/lib/python3.6/dist-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    }
   ],
   "source": [
    "vrae = VRAE(sequence_length=sequence_length,\n",
    "            number_of_features = number_of_features,\n",
    "            hidden_size = hidden_size, \n",
    "            hidden_layer_depth = hidden_layer_depth,\n",
    "            latent_length = latent_length,\n",
    "            batch_size = batch_size,\n",
    "            learning_rate = learning_rate,\n",
    "            n_epochs = n_epochs,\n",
    "            dropout_rate = dropout_rate,\n",
    "            optimizer = optimizer, \n",
    "            cuda = cuda,\n",
    "            print_every=print_every, \n",
    "            clip=clip, \n",
    "            max_grad_norm=max_grad_norm,\n",
    "            loss = loss,\n",
    "            block = block,\n",
    "            dload = dload)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit the model onto dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f242b60c3dc7498891f43ea913ecf886",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "Batch 30, loss = 13.5689, recon_loss = 13.5587, kl_loss = 0.0102\n",
      "Batch 60, loss = 1.2331, recon_loss = 0.9340, kl_loss = 0.2991\n",
      "Batch 90, loss = 1.3064, recon_loss = 1.1876, kl_loss = 0.1188\n",
      "Batch 120, loss = 1.2437, recon_loss = 1.1185, kl_loss = 0.1252\n",
      "Batch 150, loss = 114.6840, recon_loss = 114.3879, kl_loss = 0.2962\n",
      "Batch 180, loss = 30.6796, recon_loss = 30.4654, kl_loss = 0.2141\n",
      "Batch 210, loss = 141.6872, recon_loss = 141.4629, kl_loss = 0.2244\n",
      "Average loss: 38.4770\n",
      "Epoch: 1\n",
      "Batch 30, loss = 20.6469, recon_loss = 20.5294, kl_loss = 0.1175\n",
      "Batch 60, loss = 0.8517, recon_loss = 0.7684, kl_loss = 0.0833\n",
      "Batch 90, loss = 1.2049, recon_loss = 1.1256, kl_loss = 0.0793\n",
      "Batch 120, loss = 0.5958, recon_loss = 0.5386, kl_loss = 0.0572\n",
      "Batch 150, loss = 129.7405, recon_loss = 129.6276, kl_loss = 0.1129\n",
      "Batch 180, loss = 59.1760, recon_loss = 59.0556, kl_loss = 0.1204\n",
      "Batch 210, loss = 84.6632, recon_loss = 84.6073, kl_loss = 0.0559\n",
      "Average loss: 44.8867\n",
      "Epoch: 2\n",
      "Batch 30, loss = 21.1980, recon_loss = 21.1587, kl_loss = 0.0392\n",
      "Batch 60, loss = 1.7035, recon_loss = 1.6675, kl_loss = 0.0359\n",
      "Batch 90, loss = 1.1264, recon_loss = 1.0694, kl_loss = 0.0570\n",
      "Batch 120, loss = 0.6011, recon_loss = 0.5398, kl_loss = 0.0614\n",
      "Batch 150, loss = 134.0852, recon_loss = 133.9292, kl_loss = 0.1559\n",
      "Batch 180, loss = 79.7308, recon_loss = 79.5946, kl_loss = 0.1362\n",
      "Batch 210, loss = 61.8710, recon_loss = 61.8235, kl_loss = 0.0474\n",
      "Average loss: 45.5076\n",
      "Epoch: 3\n",
      "Batch 30, loss = 17.4591, recon_loss = 17.4274, kl_loss = 0.0318\n",
      "Batch 60, loss = 2.0626, recon_loss = 2.0311, kl_loss = 0.0316\n",
      "Batch 90, loss = 1.0239, recon_loss = 0.9762, kl_loss = 0.0477\n",
      "Batch 120, loss = 0.5637, recon_loss = 0.5359, kl_loss = 0.0278\n",
      "Batch 150, loss = 137.3516, recon_loss = 137.2190, kl_loss = 0.1326\n",
      "Batch 180, loss = 90.0705, recon_loss = 89.9629, kl_loss = 0.1076\n",
      "Batch 210, loss = 53.6939, recon_loss = 53.6555, kl_loss = 0.0383\n",
      "Average loss: 44.5113\n",
      "Epoch: 4\n",
      "Batch 30, loss = 15.2072, recon_loss = 15.1785, kl_loss = 0.0286\n",
      "Batch 60, loss = 1.8428, recon_loss = 1.8150, kl_loss = 0.0277\n",
      "Batch 90, loss = 1.0288, recon_loss = 1.0089, kl_loss = 0.0199\n",
      "Batch 120, loss = 0.5521, recon_loss = 0.5303, kl_loss = 0.0218\n",
      "Batch 150, loss = 141.8895, recon_loss = 141.8323, kl_loss = 0.0572\n",
      "Batch 180, loss = 99.1789, recon_loss = 99.1296, kl_loss = 0.0493\n",
      "Batch 210, loss = 47.7535, recon_loss = 47.7364, kl_loss = 0.0171\n",
      "Average loss: 44.5112\n",
      "Epoch: 5\n",
      "Batch 30, loss = 14.0636, recon_loss = 14.0498, kl_loss = 0.0138\n",
      "Batch 60, loss = 1.8828, recon_loss = 1.8691, kl_loss = 0.0137\n",
      "Batch 90, loss = 0.9947, recon_loss = 0.9816, kl_loss = 0.0132\n",
      "Batch 120, loss = 0.5453, recon_loss = 0.5332, kl_loss = 0.0121\n",
      "Batch 150, loss = 147.0398, recon_loss = 146.9842, kl_loss = 0.0556\n",
      "Batch 180, loss = 107.7097, recon_loss = 107.6573, kl_loss = 0.0525\n",
      "Batch 210, loss = 41.3158, recon_loss = 41.3061, kl_loss = 0.0098\n",
      "Average loss: 45.2905\n",
      "Epoch: 6\n",
      "Batch 30, loss = 12.6376, recon_loss = 12.6290, kl_loss = 0.0086\n",
      "Batch 60, loss = 1.9713, recon_loss = 1.9623, kl_loss = 0.0090\n",
      "Batch 90, loss = 0.9927, recon_loss = 0.9858, kl_loss = 0.0069\n",
      "Batch 120, loss = 0.5604, recon_loss = 0.5557, kl_loss = 0.0047\n",
      "Batch 150, loss = 148.9644, recon_loss = 148.8777, kl_loss = 0.0867\n",
      "Batch 180, loss = 112.3328, recon_loss = 112.2627, kl_loss = 0.0701\n",
      "Batch 210, loss = 38.7653, recon_loss = 38.7604, kl_loss = 0.0049\n",
      "Average loss: 45.4518\n",
      "Epoch: 7\n",
      "Batch 30, loss = 11.5264, recon_loss = 11.5225, kl_loss = 0.0039\n",
      "Batch 60, loss = 1.6667, recon_loss = 1.6622, kl_loss = 0.0045\n",
      "Batch 90, loss = 0.9843, recon_loss = 0.9796, kl_loss = 0.0047\n",
      "Batch 120, loss = 0.5399, recon_loss = 0.5358, kl_loss = 0.0041\n",
      "Batch 150, loss = 150.8437, recon_loss = 150.7647, kl_loss = 0.0790\n",
      "Batch 180, loss = 115.6332, recon_loss = 115.5918, kl_loss = 0.0414\n",
      "Batch 210, loss = 36.5566, recon_loss = 36.5529, kl_loss = 0.0037\n",
      "Average loss: 45.6912\n",
      "Epoch: 8\n",
      "Batch 30, loss = 11.8148, recon_loss = 11.8114, kl_loss = 0.0033\n",
      "Batch 60, loss = 1.7450, recon_loss = 1.7415, kl_loss = 0.0035\n",
      "Batch 90, loss = 0.9855, recon_loss = 0.9831, kl_loss = 0.0023\n",
      "Batch 120, loss = 0.5371, recon_loss = 0.5359, kl_loss = 0.0011\n",
      "Batch 150, loss = 152.6950, recon_loss = 152.6359, kl_loss = 0.0591\n",
      "Batch 180, loss = 120.7202, recon_loss = 120.6776, kl_loss = 0.0426\n",
      "Batch 210, loss = 32.8552, recon_loss = 32.8529, kl_loss = 0.0022\n",
      "Average loss: 46.5336\n",
      "Epoch: 9\n",
      "Batch 30, loss = 11.4861, recon_loss = 11.4845, kl_loss = 0.0016\n",
      "Batch 60, loss = 1.8008, recon_loss = 1.7987, kl_loss = 0.0022\n",
      "Batch 90, loss = 0.9950, recon_loss = 0.9932, kl_loss = 0.0018\n",
      "Batch 120, loss = 0.5589, recon_loss = 0.5576, kl_loss = 0.0012\n",
      "Batch 150, loss = 152.7094, recon_loss = 152.6503, kl_loss = 0.0591\n",
      "Batch 180, loss = 122.8915, recon_loss = 122.8282, kl_loss = 0.0633\n",
      "Batch 210, loss = 32.3703, recon_loss = 32.3675, kl_loss = 0.0028\n",
      "Average loss: 46.4147\n",
      "Epoch: 10\n",
      "Batch 30, loss = 10.5685, recon_loss = 10.5669, kl_loss = 0.0015\n",
      "Batch 60, loss = 1.6492, recon_loss = 1.6467, kl_loss = 0.0025\n",
      "Batch 90, loss = 0.9669, recon_loss = 0.9654, kl_loss = 0.0015\n",
      "Batch 120, loss = 0.5364, recon_loss = 0.5352, kl_loss = 0.0012\n",
      "Batch 150, loss = 153.1574, recon_loss = 153.0772, kl_loss = 0.0802\n",
      "Batch 180, loss = 124.5403, recon_loss = 124.4791, kl_loss = 0.0613\n",
      "Batch 210, loss = 31.3582, recon_loss = 31.3560, kl_loss = 0.0022\n",
      "Average loss: 46.5124\n",
      "Epoch: 11\n",
      "Batch 30, loss = 10.4876, recon_loss = 10.4860, kl_loss = 0.0016\n",
      "Batch 60, loss = 1.5995, recon_loss = 1.5973, kl_loss = 0.0023\n",
      "Batch 90, loss = 0.9729, recon_loss = 0.9716, kl_loss = 0.0013\n",
      "Batch 120, loss = 0.5856, recon_loss = 0.5852, kl_loss = 0.0004\n",
      "Batch 150, loss = 153.5469, recon_loss = 153.5002, kl_loss = 0.0466\n",
      "Batch 180, loss = 126.3860, recon_loss = 126.3625, kl_loss = 0.0236\n",
      "Batch 210, loss = 29.6091, recon_loss = 29.6075, kl_loss = 0.0015\n",
      "Average loss: 46.9399\n",
      "Epoch: 12\n",
      "Batch 30, loss = 10.4660, recon_loss = 10.4646, kl_loss = 0.0015\n",
      "Batch 60, loss = 1.7811, recon_loss = 1.7792, kl_loss = 0.0020\n",
      "Batch 90, loss = 0.9723, recon_loss = 0.9709, kl_loss = 0.0014\n",
      "Batch 120, loss = 0.5296, recon_loss = 0.5290, kl_loss = 0.0006\n",
      "Batch 150, loss = 153.1855, recon_loss = 153.1416, kl_loss = 0.0439\n",
      "Batch 180, loss = 127.2269, recon_loss = 127.1947, kl_loss = 0.0321\n",
      "Batch 210, loss = 30.5105, recon_loss = 30.5068, kl_loss = 0.0038\n",
      "Average loss: 46.6649\n",
      "Epoch: 13\n",
      "Batch 30, loss = 9.7374, recon_loss = 9.7364, kl_loss = 0.0011\n",
      "Batch 60, loss = 1.4186, recon_loss = 1.4173, kl_loss = 0.0013\n",
      "Batch 90, loss = 0.9631, recon_loss = 0.9623, kl_loss = 0.0008\n",
      "Batch 120, loss = 0.5347, recon_loss = 0.5342, kl_loss = 0.0004\n",
      "Batch 150, loss = 153.7995, recon_loss = 153.7336, kl_loss = 0.0659\n",
      "Batch 180, loss = 127.1134, recon_loss = 127.0812, kl_loss = 0.0322\n",
      "Batch 210, loss = 30.8283, recon_loss = 30.8263, kl_loss = 0.0021\n",
      "Average loss: 46.7297\n",
      "Epoch: 14\n",
      "Batch 30, loss = 9.9962, recon_loss = 9.9952, kl_loss = 0.0010\n",
      "Batch 60, loss = 1.3421, recon_loss = 1.3411, kl_loss = 0.0010\n",
      "Batch 90, loss = 0.9611, recon_loss = 0.9607, kl_loss = 0.0004\n",
      "Batch 120, loss = 0.5389, recon_loss = 0.5387, kl_loss = 0.0002\n",
      "Batch 150, loss = 154.0322, recon_loss = 153.9991, kl_loss = 0.0332\n",
      "Batch 180, loss = 128.4256, recon_loss = 128.4026, kl_loss = 0.0230\n",
      "Batch 210, loss = 28.9590, recon_loss = 28.9572, kl_loss = 0.0018\n",
      "Average loss: 47.0818\n",
      "Epoch: 15\n",
      "Batch 30, loss = 10.9292, recon_loss = 10.9284, kl_loss = 0.0008\n",
      "Batch 60, loss = 1.5267, recon_loss = 1.5256, kl_loss = 0.0011\n",
      "Batch 90, loss = 0.9606, recon_loss = 0.9601, kl_loss = 0.0004\n",
      "Batch 120, loss = 0.5311, recon_loss = 0.5310, kl_loss = 0.0001\n",
      "Batch 150, loss = 154.2431, recon_loss = 154.2122, kl_loss = 0.0309\n",
      "Batch 180, loss = 129.7345, recon_loss = 129.6987, kl_loss = 0.0358\n",
      "Batch 210, loss = 29.2790, recon_loss = 29.2745, kl_loss = 0.0046\n",
      "Average loss: 47.0275\n",
      "Epoch: 16\n",
      "Batch 30, loss = 10.2153, recon_loss = 10.2145, kl_loss = 0.0008\n",
      "Batch 60, loss = 1.2894, recon_loss = 1.2880, kl_loss = 0.0015\n",
      "Batch 90, loss = 0.9567, recon_loss = 0.9565, kl_loss = 0.0003\n",
      "Batch 120, loss = 0.5351, recon_loss = 0.5350, kl_loss = 0.0001\n",
      "Batch 150, loss = 154.7711, recon_loss = 154.7158, kl_loss = 0.0553\n",
      "Batch 180, loss = 131.4604, recon_loss = 131.4227, kl_loss = 0.0377\n",
      "Batch 210, loss = 28.9100, recon_loss = 28.9055, kl_loss = 0.0045\n",
      "Average loss: 47.6547\n",
      "Epoch: 17\n",
      "Batch 30, loss = 10.7448, recon_loss = 10.7430, kl_loss = 0.0019\n",
      "Batch 60, loss = 1.4658, recon_loss = 1.4635, kl_loss = 0.0023\n",
      "Batch 90, loss = 0.9565, recon_loss = 0.9561, kl_loss = 0.0003\n",
      "Batch 120, loss = 0.5317, recon_loss = 0.5314, kl_loss = 0.0002\n",
      "Batch 150, loss = 155.0417, recon_loss = 154.9900, kl_loss = 0.0517\n",
      "Batch 180, loss = 131.6424, recon_loss = 131.6245, kl_loss = 0.0178\n",
      "Batch 210, loss = 29.3045, recon_loss = 29.3025, kl_loss = 0.0020\n",
      "Average loss: 47.1844\n",
      "Epoch: 18\n",
      "Batch 30, loss = 10.5244, recon_loss = 10.5229, kl_loss = 0.0016\n",
      "Batch 60, loss = 1.3226, recon_loss = 1.3213, kl_loss = 0.0013\n",
      "Batch 90, loss = 0.9464, recon_loss = 0.9461, kl_loss = 0.0003\n",
      "Batch 120, loss = 0.5397, recon_loss = 0.5396, kl_loss = 0.0001\n",
      "Batch 150, loss = 156.5618, recon_loss = 156.5368, kl_loss = 0.0249\n",
      "Batch 180, loss = 134.9398, recon_loss = 134.9284, kl_loss = 0.0114\n",
      "Batch 210, loss = 27.9854, recon_loss = 27.9831, kl_loss = 0.0023\n",
      "Average loss: 48.1949\n",
      "Epoch: 19\n",
      "Batch 30, loss = 10.1361, recon_loss = 10.1349, kl_loss = 0.0012\n",
      "Batch 60, loss = 1.3078, recon_loss = 1.3060, kl_loss = 0.0018\n",
      "Batch 90, loss = 0.9563, recon_loss = 0.9560, kl_loss = 0.0003\n",
      "Batch 120, loss = 0.5402, recon_loss = 0.5401, kl_loss = 0.0001\n",
      "Batch 150, loss = 156.2833, recon_loss = 156.2654, kl_loss = 0.0179\n",
      "Batch 180, loss = 135.5939, recon_loss = 135.5763, kl_loss = 0.0177\n",
      "Batch 210, loss = 27.7195, recon_loss = 27.7132, kl_loss = 0.0063\n",
      "Average loss: 48.0261\n",
      "Epoch: 20\n",
      "Batch 30, loss = 10.4977, recon_loss = 10.4969, kl_loss = 0.0008\n",
      "Batch 60, loss = 1.3495, recon_loss = 1.3483, kl_loss = 0.0012\n",
      "Batch 90, loss = 0.9649, recon_loss = 0.9647, kl_loss = 0.0002\n",
      "Batch 120, loss = 0.5422, recon_loss = 0.5422, kl_loss = 0.0001\n",
      "Batch 150, loss = 157.2204, recon_loss = 157.1866, kl_loss = 0.0338\n",
      "Batch 180, loss = 137.6450, recon_loss = 137.6201, kl_loss = 0.0249\n",
      "Batch 210, loss = 27.3941, recon_loss = 27.3888, kl_loss = 0.0053\n",
      "Average loss: 48.2669\n",
      "Epoch: 21\n",
      "Batch 30, loss = 10.2714, recon_loss = 10.2701, kl_loss = 0.0013\n",
      "Batch 60, loss = 1.2200, recon_loss = 1.2190, kl_loss = 0.0010\n",
      "Batch 90, loss = 0.9583, recon_loss = 0.9582, kl_loss = 0.0001\n",
      "Batch 120, loss = 0.5403, recon_loss = 0.5403, kl_loss = 0.0000\n",
      "Batch 150, loss = 157.7559, recon_loss = 157.7167, kl_loss = 0.0392\n",
      "Batch 180, loss = 139.1610, recon_loss = 139.1400, kl_loss = 0.0211\n",
      "Batch 210, loss = 27.2975, recon_loss = 27.2936, kl_loss = 0.0039\n",
      "Average loss: 48.5529\n",
      "Epoch: 22\n",
      "Batch 30, loss = 10.2676, recon_loss = 10.2665, kl_loss = 0.0011\n",
      "Batch 60, loss = 1.1807, recon_loss = 1.1798, kl_loss = 0.0009\n",
      "Batch 90, loss = 0.9567, recon_loss = 0.9566, kl_loss = 0.0001\n",
      "Batch 120, loss = 0.5390, recon_loss = 0.5390, kl_loss = 0.0001\n",
      "Batch 150, loss = 157.6229, recon_loss = 157.5963, kl_loss = 0.0266\n",
      "Batch 180, loss = 140.0903, recon_loss = 140.0732, kl_loss = 0.0171\n",
      "Batch 210, loss = 27.4900, recon_loss = 27.4814, kl_loss = 0.0086\n",
      "Average loss: 48.7446\n",
      "Epoch: 23\n",
      "Batch 30, loss = 10.2553, recon_loss = 10.2530, kl_loss = 0.0023\n",
      "Batch 60, loss = 1.2601, recon_loss = 1.2592, kl_loss = 0.0009\n",
      "Batch 90, loss = 0.9650, recon_loss = 0.9649, kl_loss = 0.0001\n",
      "Batch 120, loss = 0.5402, recon_loss = 0.5401, kl_loss = 0.0001\n",
      "Batch 150, loss = 157.7135, recon_loss = 157.6874, kl_loss = 0.0261\n",
      "Batch 180, loss = 140.6492, recon_loss = 140.6304, kl_loss = 0.0188\n",
      "Batch 210, loss = 27.9993, recon_loss = 27.9921, kl_loss = 0.0072\n",
      "Average loss: 48.5075\n",
      "Epoch: 24\n",
      "Batch 30, loss = 10.1265, recon_loss = 10.1248, kl_loss = 0.0018\n",
      "Batch 60, loss = 1.1931, recon_loss = 1.1916, kl_loss = 0.0015\n",
      "Batch 90, loss = 0.9585, recon_loss = 0.9583, kl_loss = 0.0002\n",
      "Batch 120, loss = 0.5435, recon_loss = 0.5433, kl_loss = 0.0001\n",
      "Batch 150, loss = 157.4730, recon_loss = 157.4492, kl_loss = 0.0239\n",
      "Batch 180, loss = 139.6650, recon_loss = 139.6454, kl_loss = 0.0196\n",
      "Batch 210, loss = 28.0520, recon_loss = 28.0445, kl_loss = 0.0076\n",
      "Average loss: 48.2390\n",
      "Epoch: 25\n",
      "Batch 30, loss = 10.1626, recon_loss = 10.1611, kl_loss = 0.0016\n",
      "Batch 60, loss = 1.1707, recon_loss = 1.1693, kl_loss = 0.0014\n",
      "Batch 90, loss = 0.9563, recon_loss = 0.9562, kl_loss = 0.0001\n",
      "Batch 120, loss = 0.5546, recon_loss = 0.5545, kl_loss = 0.0000\n",
      "Batch 150, loss = 158.2772, recon_loss = 158.2542, kl_loss = 0.0229\n",
      "Batch 180, loss = 141.1476, recon_loss = 141.1304, kl_loss = 0.0172\n",
      "Batch 210, loss = 27.9119, recon_loss = 27.9042, kl_loss = 0.0078\n",
      "Average loss: 48.9692\n",
      "Epoch: 26\n",
      "Batch 30, loss = 9.9581, recon_loss = 9.9566, kl_loss = 0.0015\n",
      "Batch 60, loss = 1.1902, recon_loss = 1.1892, kl_loss = 0.0010\n",
      "Batch 90, loss = 0.9588, recon_loss = 0.9587, kl_loss = 0.0001\n",
      "Batch 120, loss = 0.5501, recon_loss = 0.5500, kl_loss = 0.0001\n",
      "Batch 150, loss = 158.4701, recon_loss = 158.4430, kl_loss = 0.0272\n",
      "Batch 180, loss = 142.2446, recon_loss = 142.2269, kl_loss = 0.0177\n",
      "Batch 210, loss = 28.4506, recon_loss = 28.4436, kl_loss = 0.0071\n",
      "Average loss: 49.0866\n",
      "Epoch: 27\n",
      "Batch 30, loss = 9.7667, recon_loss = 9.7642, kl_loss = 0.0025\n",
      "Batch 60, loss = 1.1412, recon_loss = 1.1403, kl_loss = 0.0010\n",
      "Batch 90, loss = 0.9678, recon_loss = 0.9678, kl_loss = 0.0001\n",
      "Batch 120, loss = 0.5508, recon_loss = 0.5508, kl_loss = 0.0000\n",
      "Batch 150, loss = 158.3125, recon_loss = 158.2903, kl_loss = 0.0222\n",
      "Batch 180, loss = 142.4055, recon_loss = 142.3921, kl_loss = 0.0134\n",
      "Batch 210, loss = 28.3484, recon_loss = 28.3409, kl_loss = 0.0075\n",
      "Average loss: 48.8149\n",
      "Epoch: 28\n",
      "Batch 30, loss = 9.9291, recon_loss = 9.9267, kl_loss = 0.0024\n",
      "Batch 60, loss = 1.1282, recon_loss = 1.1272, kl_loss = 0.0010\n",
      "Batch 90, loss = 0.9587, recon_loss = 0.9586, kl_loss = 0.0001\n",
      "Batch 120, loss = 0.5595, recon_loss = 0.5594, kl_loss = 0.0001\n",
      "Batch 150, loss = 158.6713, recon_loss = 158.6560, kl_loss = 0.0152\n",
      "Batch 180, loss = 143.0300, recon_loss = 143.0198, kl_loss = 0.0102\n",
      "Batch 210, loss = 27.8497, recon_loss = 27.8451, kl_loss = 0.0047\n",
      "Average loss: 48.8951\n",
      "Epoch: 29\n",
      "Batch 30, loss = 9.8938, recon_loss = 9.8905, kl_loss = 0.0033\n",
      "Batch 60, loss = 1.1140, recon_loss = 1.1129, kl_loss = 0.0011\n",
      "Batch 90, loss = 0.9576, recon_loss = 0.9576, kl_loss = 0.0001\n",
      "Batch 120, loss = 0.5805, recon_loss = 0.5804, kl_loss = 0.0001\n",
      "Batch 150, loss = 159.1076, recon_loss = 159.0902, kl_loss = 0.0174\n",
      "Batch 180, loss = 144.4252, recon_loss = 144.4102, kl_loss = 0.0150\n",
      "Batch 210, loss = 27.9494, recon_loss = 27.9340, kl_loss = 0.0153\n",
      "Average loss: 49.3815\n",
      "Epoch: 30\n",
      "Batch 30, loss = 9.3727, recon_loss = 9.3705, kl_loss = 0.0023\n",
      "Batch 60, loss = 1.1722, recon_loss = 1.1713, kl_loss = 0.0009\n",
      "Batch 90, loss = 0.9632, recon_loss = 0.9631, kl_loss = 0.0001\n",
      "Batch 120, loss = 0.5515, recon_loss = 0.5515, kl_loss = 0.0000\n",
      "Batch 150, loss = 158.8814, recon_loss = 158.8706, kl_loss = 0.0108\n",
      "Batch 180, loss = 144.5036, recon_loss = 144.4925, kl_loss = 0.0111\n",
      "Batch 210, loss = 27.8541, recon_loss = 27.8505, kl_loss = 0.0037\n",
      "Average loss: 49.0790\n",
      "Epoch: 31\n",
      "Batch 30, loss = 9.4002, recon_loss = 9.3993, kl_loss = 0.0009\n",
      "Batch 60, loss = 1.1287, recon_loss = 1.1279, kl_loss = 0.0007\n",
      "Batch 90, loss = 0.9610, recon_loss = 0.9610, kl_loss = 0.0000\n",
      "Batch 120, loss = 0.5557, recon_loss = 0.5557, kl_loss = 0.0000\n",
      "Batch 150, loss = 158.9385, recon_loss = 158.9291, kl_loss = 0.0094\n",
      "Batch 180, loss = 144.8849, recon_loss = 144.8744, kl_loss = 0.0105\n",
      "Batch 210, loss = 28.2862, recon_loss = 28.2795, kl_loss = 0.0067\n",
      "Average loss: 49.1424\n",
      "Epoch: 32\n",
      "Batch 30, loss = 9.3435, recon_loss = 9.3411, kl_loss = 0.0023\n",
      "Batch 60, loss = 1.1326, recon_loss = 1.1318, kl_loss = 0.0008\n",
      "Batch 90, loss = 0.9652, recon_loss = 0.9652, kl_loss = 0.0001\n",
      "Batch 120, loss = 0.5566, recon_loss = 0.5566, kl_loss = 0.0000\n",
      "Batch 150, loss = 159.2302, recon_loss = 159.2103, kl_loss = 0.0199\n",
      "Batch 180, loss = 144.5328, recon_loss = 144.5222, kl_loss = 0.0106\n",
      "Batch 210, loss = 28.2662, recon_loss = 28.2597, kl_loss = 0.0065\n",
      "Average loss: 48.7393\n",
      "Epoch: 33\n",
      "Batch 30, loss = 9.4604, recon_loss = 9.4583, kl_loss = 0.0021\n",
      "Batch 60, loss = 1.0529, recon_loss = 1.0523, kl_loss = 0.0006\n",
      "Batch 90, loss = 0.9595, recon_loss = 0.9595, kl_loss = 0.0000\n",
      "Batch 120, loss = 0.5570, recon_loss = 0.5570, kl_loss = 0.0001\n",
      "Batch 150, loss = 159.0904, recon_loss = 159.0777, kl_loss = 0.0127\n",
      "Batch 180, loss = 144.6905, recon_loss = 144.6787, kl_loss = 0.0117\n",
      "Batch 210, loss = 28.1344, recon_loss = 28.1281, kl_loss = 0.0064\n",
      "Average loss: 49.3328\n",
      "Epoch: 34\n",
      "Batch 30, loss = 9.6398, recon_loss = 9.6363, kl_loss = 0.0036\n",
      "Batch 60, loss = 1.0923, recon_loss = 1.0912, kl_loss = 0.0011\n",
      "Batch 90, loss = 0.9615, recon_loss = 0.9615, kl_loss = 0.0000\n",
      "Batch 120, loss = 0.5705, recon_loss = 0.5705, kl_loss = 0.0000\n",
      "Batch 150, loss = 160.2066, recon_loss = 160.1885, kl_loss = 0.0181\n",
      "Batch 180, loss = 147.3334, recon_loss = 147.3169, kl_loss = 0.0165\n",
      "Batch 210, loss = 28.6763, recon_loss = 28.6674, kl_loss = 0.0089\n",
      "Average loss: 50.1702\n",
      "Epoch: 35\n",
      "Batch 30, loss = 8.9138, recon_loss = 8.9113, kl_loss = 0.0025\n",
      "Batch 60, loss = 1.0859, recon_loss = 1.0851, kl_loss = 0.0008\n",
      "Batch 90, loss = 0.9675, recon_loss = 0.9675, kl_loss = 0.0001\n",
      "Batch 120, loss = 0.5639, recon_loss = 0.5638, kl_loss = 0.0000\n",
      "Batch 150, loss = 159.8048, recon_loss = 159.7958, kl_loss = 0.0090\n",
      "Batch 180, loss = 146.8571, recon_loss = 146.8528, kl_loss = 0.0043\n",
      "Batch 210, loss = 28.8772, recon_loss = 28.8733, kl_loss = 0.0039\n",
      "Average loss: 49.2249\n",
      "Epoch: 36\n",
      "Batch 30, loss = 8.8972, recon_loss = 8.8961, kl_loss = 0.0011\n",
      "Batch 60, loss = 0.9789, recon_loss = 0.9784, kl_loss = 0.0005\n",
      "Batch 90, loss = 0.9595, recon_loss = 0.9594, kl_loss = 0.0000\n",
      "Batch 120, loss = 0.5603, recon_loss = 0.5603, kl_loss = 0.0000\n",
      "Batch 150, loss = 159.7294, recon_loss = 159.7243, kl_loss = 0.0051\n",
      "Batch 180, loss = 147.0475, recon_loss = 147.0408, kl_loss = 0.0067\n",
      "Batch 210, loss = 28.7162, recon_loss = 28.7086, kl_loss = 0.0077\n",
      "Average loss: 49.5588\n",
      "Epoch: 37\n",
      "Batch 30, loss = 8.9762, recon_loss = 8.9746, kl_loss = 0.0016\n",
      "Batch 60, loss = 1.0234, recon_loss = 1.0228, kl_loss = 0.0006\n",
      "Batch 90, loss = 0.9519, recon_loss = 0.9519, kl_loss = 0.0000\n",
      "Batch 120, loss = 0.5632, recon_loss = 0.5632, kl_loss = 0.0001\n",
      "Batch 150, loss = 159.5712, recon_loss = 159.5556, kl_loss = 0.0156\n",
      "Batch 180, loss = 147.0574, recon_loss = 147.0445, kl_loss = 0.0129\n",
      "Batch 210, loss = 28.7627, recon_loss = 28.7530, kl_loss = 0.0097\n",
      "Average loss: 49.3922\n",
      "Epoch: 38\n",
      "Batch 30, loss = 8.9319, recon_loss = 8.9269, kl_loss = 0.0050\n",
      "Batch 60, loss = 1.0944, recon_loss = 1.0938, kl_loss = 0.0006\n",
      "Batch 90, loss = 0.9701, recon_loss = 0.9700, kl_loss = 0.0000\n",
      "Batch 120, loss = 0.5699, recon_loss = 0.5699, kl_loss = 0.0000\n",
      "Batch 150, loss = 160.4817, recon_loss = 160.4708, kl_loss = 0.0109\n",
      "Batch 180, loss = 148.4899, recon_loss = 148.4787, kl_loss = 0.0112\n",
      "Batch 210, loss = 28.7113, recon_loss = 28.7059, kl_loss = 0.0054\n",
      "Average loss: 49.9335\n",
      "Epoch: 39\n",
      "Batch 30, loss = 8.5628, recon_loss = 8.5605, kl_loss = 0.0023\n",
      "Batch 60, loss = 1.0022, recon_loss = 1.0018, kl_loss = 0.0004\n",
      "Batch 90, loss = 0.9644, recon_loss = 0.9644, kl_loss = 0.0000\n",
      "Batch 120, loss = 0.5678, recon_loss = 0.5678, kl_loss = 0.0000\n",
      "Batch 150, loss = 160.3141, recon_loss = 160.3079, kl_loss = 0.0062\n",
      "Batch 180, loss = 148.8790, recon_loss = 148.8699, kl_loss = 0.0090\n",
      "Batch 210, loss = 28.9427, recon_loss = 28.9375, kl_loss = 0.0052\n",
      "Average loss: 49.8678\n",
      "Epoch: 40\n",
      "Batch 30, loss = 8.4965, recon_loss = 8.4942, kl_loss = 0.0023\n",
      "Batch 60, loss = 0.9972, recon_loss = 0.9970, kl_loss = 0.0003\n",
      "Batch 90, loss = 0.9571, recon_loss = 0.9571, kl_loss = 0.0000\n",
      "Batch 120, loss = 0.5696, recon_loss = 0.5695, kl_loss = 0.0001\n",
      "Batch 150, loss = 159.7499, recon_loss = 159.7458, kl_loss = 0.0041\n",
      "Batch 180, loss = 147.8540, recon_loss = 147.8482, kl_loss = 0.0058\n",
      "Batch 210, loss = 28.9645, recon_loss = 28.9607, kl_loss = 0.0039\n",
      "Average loss: 49.4031\n",
      "Epoch: 41\n",
      "Batch 30, loss = 8.7359, recon_loss = 8.7336, kl_loss = 0.0022\n",
      "Batch 60, loss = 0.9812, recon_loss = 0.9808, kl_loss = 0.0004\n",
      "Batch 90, loss = 0.9548, recon_loss = 0.9548, kl_loss = 0.0000\n",
      "Batch 120, loss = 0.5670, recon_loss = 0.5670, kl_loss = 0.0000\n",
      "Batch 150, loss = 159.8624, recon_loss = 159.8604, kl_loss = 0.0020\n",
      "Batch 180, loss = 147.7299, recon_loss = 147.7227, kl_loss = 0.0072\n",
      "Batch 210, loss = 29.0608, recon_loss = 29.0544, kl_loss = 0.0064\n",
      "Average loss: 49.6276\n",
      "Epoch: 42\n",
      "Batch 30, loss = 8.6466, recon_loss = 8.6439, kl_loss = 0.0028\n",
      "Batch 60, loss = 0.9902, recon_loss = 0.9896, kl_loss = 0.0006\n",
      "Batch 90, loss = 0.9607, recon_loss = 0.9606, kl_loss = 0.0000\n",
      "Batch 120, loss = 0.5720, recon_loss = 0.5720, kl_loss = 0.0001\n",
      "Batch 150, loss = 160.7217, recon_loss = 160.7152, kl_loss = 0.0065\n",
      "Batch 180, loss = 149.4352, recon_loss = 149.4232, kl_loss = 0.0119\n",
      "Batch 210, loss = 29.5140, recon_loss = 29.5035, kl_loss = 0.0106\n",
      "Average loss: 50.1060\n",
      "Epoch: 43\n",
      "Batch 30, loss = 8.2306, recon_loss = 8.2275, kl_loss = 0.0032\n",
      "Batch 60, loss = 0.9853, recon_loss = 0.9848, kl_loss = 0.0005\n",
      "Batch 90, loss = 0.9621, recon_loss = 0.9620, kl_loss = 0.0000\n",
      "Batch 120, loss = 0.5726, recon_loss = 0.5726, kl_loss = 0.0000\n",
      "Batch 150, loss = 160.8743, recon_loss = 160.8705, kl_loss = 0.0039\n",
      "Batch 180, loss = 150.3784, recon_loss = 150.3693, kl_loss = 0.0092\n",
      "Batch 210, loss = 29.7737, recon_loss = 29.7680, kl_loss = 0.0057\n",
      "Average loss: 50.2287\n",
      "Epoch: 44\n",
      "Batch 30, loss = 7.9760, recon_loss = 7.9738, kl_loss = 0.0022\n",
      "Batch 60, loss = 0.9710, recon_loss = 0.9706, kl_loss = 0.0003\n",
      "Batch 90, loss = 0.9634, recon_loss = 0.9634, kl_loss = 0.0000\n",
      "Batch 120, loss = 0.5714, recon_loss = 0.5714, kl_loss = 0.0000\n",
      "Batch 150, loss = 160.6280, recon_loss = 160.6222, kl_loss = 0.0058\n",
      "Batch 180, loss = 150.0961, recon_loss = 150.0898, kl_loss = 0.0063\n",
      "Batch 210, loss = 29.6162, recon_loss = 29.6111, kl_loss = 0.0051\n",
      "Average loss: 49.8688\n",
      "Epoch: 45\n",
      "Batch 30, loss = 8.1121, recon_loss = 8.1101, kl_loss = 0.0020\n",
      "Batch 60, loss = 0.9281, recon_loss = 0.9278, kl_loss = 0.0003\n",
      "Batch 90, loss = 0.9573, recon_loss = 0.9573, kl_loss = 0.0000\n",
      "Batch 120, loss = 0.5779, recon_loss = 0.5779, kl_loss = 0.0000\n",
      "Batch 150, loss = 160.4570, recon_loss = 160.4529, kl_loss = 0.0040\n",
      "Batch 180, loss = 150.2168, recon_loss = 150.2105, kl_loss = 0.0063\n",
      "Batch 210, loss = 29.6823, recon_loss = 29.6788, kl_loss = 0.0035\n",
      "Average loss: 50.0359\n",
      "Epoch: 46\n",
      "Batch 30, loss = 8.1654, recon_loss = 8.1639, kl_loss = 0.0015\n",
      "Batch 60, loss = 0.9742, recon_loss = 0.9740, kl_loss = 0.0001\n",
      "Batch 90, loss = 0.9613, recon_loss = 0.9612, kl_loss = 0.0000\n",
      "Batch 120, loss = 0.5726, recon_loss = 0.5726, kl_loss = 0.0000\n",
      "Batch 150, loss = 160.6261, recon_loss = 160.6210, kl_loss = 0.0050\n",
      "Batch 180, loss = 150.3544, recon_loss = 150.3471, kl_loss = 0.0073\n",
      "Batch 210, loss = 29.4513, recon_loss = 29.4456, kl_loss = 0.0056\n",
      "Average loss: 49.7957\n",
      "Epoch: 47\n",
      "Batch 30, loss = 8.1655, recon_loss = 8.1638, kl_loss = 0.0016\n",
      "Batch 60, loss = 0.9248, recon_loss = 0.9244, kl_loss = 0.0004\n",
      "Batch 90, loss = 0.9552, recon_loss = 0.9552, kl_loss = 0.0000\n",
      "Batch 120, loss = 0.5761, recon_loss = 0.5759, kl_loss = 0.0002\n",
      "Batch 150, loss = 160.6365, recon_loss = 160.6284, kl_loss = 0.0081\n",
      "Batch 180, loss = 150.5176, recon_loss = 150.5111, kl_loss = 0.0065\n",
      "Batch 210, loss = 29.7667, recon_loss = 29.7599, kl_loss = 0.0068\n",
      "Average loss: 50.2519\n",
      "Epoch: 48\n",
      "Batch 30, loss = 7.9356, recon_loss = 7.9330, kl_loss = 0.0026\n",
      "Batch 60, loss = 0.9441, recon_loss = 0.9438, kl_loss = 0.0003\n",
      "Batch 90, loss = 0.9604, recon_loss = 0.9604, kl_loss = 0.0000\n",
      "Batch 120, loss = 0.5785, recon_loss = 0.5785, kl_loss = 0.0000\n",
      "Batch 150, loss = 160.9948, recon_loss = 160.9884, kl_loss = 0.0063\n",
      "Batch 180, loss = 150.9237, recon_loss = 150.9194, kl_loss = 0.0044\n",
      "Batch 210, loss = 29.7274, recon_loss = 29.7252, kl_loss = 0.0022\n",
      "Average loss: 50.1317\n",
      "Epoch: 49\n",
      "Batch 30, loss = 7.8233, recon_loss = 7.8226, kl_loss = 0.0007\n",
      "Batch 60, loss = 0.9078, recon_loss = 0.9076, kl_loss = 0.0002\n",
      "Batch 90, loss = 0.9559, recon_loss = 0.9559, kl_loss = 0.0000\n",
      "Batch 120, loss = 0.5757, recon_loss = 0.5757, kl_loss = 0.0000\n",
      "Batch 150, loss = 160.9333, recon_loss = 160.9308, kl_loss = 0.0025\n",
      "Batch 180, loss = 151.2360, recon_loss = 151.2318, kl_loss = 0.0042\n",
      "Batch 210, loss = 30.0083, recon_loss = 30.0049, kl_loss = 0.0034\n",
      "Average loss: 50.3548\n",
      "Epoch: 50\n",
      "Batch 30, loss = 7.8102, recon_loss = 7.8095, kl_loss = 0.0006\n",
      "Batch 60, loss = 0.9447, recon_loss = 0.9445, kl_loss = 0.0002\n",
      "Batch 90, loss = 0.9651, recon_loss = 0.9651, kl_loss = 0.0000\n",
      "Batch 120, loss = 0.5770, recon_loss = 0.5770, kl_loss = 0.0000\n",
      "Batch 150, loss = 161.1281, recon_loss = 161.1261, kl_loss = 0.0021\n",
      "Batch 180, loss = 151.6842, recon_loss = 151.6801, kl_loss = 0.0042\n",
      "Batch 210, loss = 30.2572, recon_loss = 30.2549, kl_loss = 0.0024\n",
      "Average loss: 50.3480\n",
      "Epoch: 51\n",
      "Batch 30, loss = 7.6143, recon_loss = 7.6136, kl_loss = 0.0008\n",
      "Batch 60, loss = 0.8782, recon_loss = 0.8781, kl_loss = 0.0001\n",
      "Batch 90, loss = 0.9547, recon_loss = 0.9547, kl_loss = 0.0000\n",
      "Batch 120, loss = 0.5770, recon_loss = 0.5769, kl_loss = 0.0000\n",
      "Batch 150, loss = 160.6825, recon_loss = 160.6808, kl_loss = 0.0018\n",
      "Batch 180, loss = 150.8122, recon_loss = 150.8087, kl_loss = 0.0035\n",
      "Batch 210, loss = 30.2125, recon_loss = 30.2109, kl_loss = 0.0016\n",
      "Average loss: 50.0292\n",
      "Epoch: 52\n",
      "Batch 30, loss = 7.7549, recon_loss = 7.7538, kl_loss = 0.0011\n",
      "Batch 60, loss = 0.9094, recon_loss = 0.9092, kl_loss = 0.0002\n",
      "Batch 90, loss = 0.9655, recon_loss = 0.9654, kl_loss = 0.0000\n",
      "Batch 120, loss = 0.5815, recon_loss = 0.5814, kl_loss = 0.0000\n",
      "Batch 150, loss = 161.2636, recon_loss = 161.2592, kl_loss = 0.0045\n",
      "Batch 180, loss = 152.0283, recon_loss = 152.0223, kl_loss = 0.0060\n",
      "Batch 210, loss = 30.4738, recon_loss = 30.4710, kl_loss = 0.0028\n",
      "Average loss: 50.5887\n",
      "Epoch: 53\n",
      "Batch 30, loss = 7.4099, recon_loss = 7.4089, kl_loss = 0.0010\n",
      "Batch 60, loss = 0.9024, recon_loss = 0.9023, kl_loss = 0.0001\n",
      "Batch 90, loss = 0.9596, recon_loss = 0.9596, kl_loss = 0.0000\n",
      "Batch 120, loss = 0.5783, recon_loss = 0.5782, kl_loss = 0.0000\n",
      "Batch 150, loss = 161.0809, recon_loss = 161.0781, kl_loss = 0.0028\n",
      "Batch 180, loss = 152.1241, recon_loss = 152.1225, kl_loss = 0.0017\n",
      "Batch 210, loss = 30.6795, recon_loss = 30.6786, kl_loss = 0.0009\n",
      "Average loss: 50.4006\n",
      "Epoch: 54\n",
      "Batch 30, loss = 7.4036, recon_loss = 7.4032, kl_loss = 0.0003\n",
      "Batch 60, loss = 0.9167, recon_loss = 0.9166, kl_loss = 0.0000\n",
      "Batch 90, loss = 0.9593, recon_loss = 0.9593, kl_loss = 0.0000\n",
      "Batch 120, loss = 0.5801, recon_loss = 0.5801, kl_loss = 0.0000\n",
      "Batch 150, loss = 160.8280, recon_loss = 160.8264, kl_loss = 0.0016\n",
      "Batch 180, loss = 151.4253, recon_loss = 151.4234, kl_loss = 0.0019\n",
      "Batch 210, loss = 30.1790, recon_loss = 30.1778, kl_loss = 0.0012\n",
      "Average loss: 49.8778\n",
      "Epoch: 55\n",
      "Batch 30, loss = 7.8053, recon_loss = 7.8041, kl_loss = 0.0011\n",
      "Batch 60, loss = 0.9135, recon_loss = 0.9135, kl_loss = 0.0001\n",
      "Batch 90, loss = 0.9569, recon_loss = 0.9569, kl_loss = 0.0000\n",
      "Batch 120, loss = 0.5818, recon_loss = 0.5817, kl_loss = 0.0000\n",
      "Batch 150, loss = 161.1383, recon_loss = 161.1349, kl_loss = 0.0034\n",
      "Batch 180, loss = 151.9823, recon_loss = 151.9806, kl_loss = 0.0017\n",
      "Batch 210, loss = 30.3986, recon_loss = 30.3976, kl_loss = 0.0010\n",
      "Average loss: 50.5887\n",
      "Epoch: 56\n",
      "Batch 30, loss = 7.4095, recon_loss = 7.4084, kl_loss = 0.0012\n",
      "Batch 60, loss = 0.8815, recon_loss = 0.8814, kl_loss = 0.0001\n"
     ]
    }
   ],
   "source": [
    "loss_arr = vrae.fit(train_dataset)\n",
    "\n",
    "#If the model has to be saved, with the learnt parameters use:\n",
    "# vrae.fit(dataset, save = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(loss_arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the model to be fetched later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vrae.save('vrae.pth')\n",
    "\n",
    "# To load a presaved model, execute:\n",
    "# vrae.load('vrae.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vrae.is_fitted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform the input timeseries to encoded latent vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "z_run = vrae.transform(test_dataset)\n",
    "z_run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_run.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reconstruct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "reconstruction = vrae.reconstruct(test_dataset)\n",
    "reconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_DF.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstruction.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
